Logging to /Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire

 ---------------- Iteration 0 ----------------
Obtaining samples...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------
| Time/Buffer | 0.0229       |
| Train/Value | -0.020606112 |
------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 1 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-----------------------------------------
| Itr                     | 0           |
| Time/Actor_Time         | 0.633       |
| Time/B_Format_Time      | 0.4         |
| Time/B_Original_Form... | 0.388       |
| Time/Buffer             | 0.0203      |
| Time/Critic_Time        | 0           |
| Train/Action_abs_mean   | 0.31793946  |
| Train/Action_magnitu... | 1.9178588   |
| Train/Action_magnitude  | 1.5664182   |
| Train/Action_max        | 0.5919974   |
| Train/Action_std        | 1.1157523   |
| Train/Entropy           | 1.4041041   |
| Train/Entropy_Loss      | -0.0014     |
| Train/Entropy_loss      | -0.0014     |
| Train/Grad_norm_actor   | 0.0         |
| Train/LogProb           | -2.8880122  |
| Train/Loss              | -0.14904751 |
| Train/PolicyClip        | 0.004796916 |
| Train/Policy_loss       | -0.16318662 |
| Train/Ratio             | 0.999563    |
| Train/Return            | 0.10290401  |
| Train/V                 | -0.0668928  |
| Train/Value             | -0.0668928  |
| Train/control_penalty   | 1.5543227   |
| Train/policy_loss       | -0.16318662 |
| Train/recon_loss        | 0.0         |
| train/batch_reward      | 0.0116      |
-----------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 1              |
| Time/Actor_Time         | 0.52           |
| Time/B_Format_Time      | 0.523          |
| Time/B_Original_Form... | 0.397          |
| Time/Buffer             | 0.0136         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.28377533     |
| Train/Action_magnitu... | 1.8638715      |
| Train/Action_magnitude  | 1.5421432      |
| Train/Action_max        | 0.5806268      |
| Train/Action_std        | 0.9051422      |
| Train/Entropy           | 1.1597762      |
| Train/Entropy_Loss      | -0.00116       |
| Train/Entropy_loss      | -0.00116       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -2.6484678     |
| Train/Loss              | -0.029524561   |
| Train/PolicyClip        | -0.00070599787 |
| Train/Policy_loss       | -0.0413561     |
| Train/Ratio             | 1.0009421      |
| Train/Return            | 0.01630178     |
| Train/V                 | -0.025211658   |
| Train/Value             | -0.025211658   |
| Train/control_penalty   | 1.2991318      |
| Train/policy_loss       | -0.0413561     |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.00305        |
--------------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 2              |
| Time/Actor_Time         | 0.426          |
| Time/B_Format_Time      | 0.386          |
| Time/B_Original_Form... | 0.548          |
| Time/Buffer             | 0.0212         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.27175054     |
| Train/Action_magnitu... | 1.5690669      |
| Train/Action_magnitude  | 1.2775186      |
| Train/Action_max        | 0.4219463      |
| Train/Action_std        | 0.7454387      |
| Train/Entropy           | 1.031704       |
| Train/Entropy_Loss      | -0.00103       |
| Train/Entropy_loss      | -0.00103       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -2.4481883     |
| Train/Loss              | 0.0031422041   |
| Train/PolicyClip        | -4.4619435e-05 |
| Train/Policy_loss       | -0.006367769   |
| Train/Ratio             | 0.9978867      |
| Train/Return            | -0.028204126   |
| Train/V                 | -0.035002235   |
| Train/Value             | -0.035002235   |
| Train/control_penalty   | 1.0541677      |
| Train/policy_loss       | -0.006367769   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0009         |
--------------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 3              |
| Time/Actor_Time         | 0.421          |
| Time/B_Format_Time      | 0.445          |
| Time/B_Original_Form... | 0.493          |
| Time/Buffer             | 0.0242         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.20088771     |
| Train/Action_magnitu... | 1.3635428      |
| Train/Action_magnitude  | 1.0970746      |
| Train/Action_max        | 0.31981596     |
| Train/Action_std        | 0.70421296     |
| Train/Entropy           | 1.0030189      |
| Train/Entropy_Loss      | -0.001         |
| Train/Entropy_loss      | -0.001         |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -2.2489052     |
| Train/Loss              | 0.008458007    |
| Train/PolicyClip        | -0.00012874462 |
| Train/Policy_loss       | -6.615471e-05  |
| Train/Ratio             | 1.0026394      |
| Train/Return            | -0.014903222   |
| Train/V                 | -0.015306238   |
| Train/Value             | -0.015306238   |
| Train/control_penalty   | 0.95271814     |
| Train/policy_loss       | -6.615471e-05  |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0002         |
--------------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 4              |
| Time/Actor_Time         | 0.457          |
| Time/B_Format_Time      | 0.607          |
| Time/B_Original_Form... | 0.487          |
| Time/Buffer             | 0.0124         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.15903938     |
| Train/Action_magnitu... | 1.2235459      |
| Train/Action_magnitude  | 0.97788894     |
| Train/Action_max        | 0.3040213      |
| Train/Action_std        | 0.6624017      |
| Train/Entropy           | 0.9514798      |
| Train/Entropy_Loss      | -0.000951      |
| Train/Entropy_loss      | -0.000951      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -2.11032       |
| Train/Loss              | -0.040966682   |
| Train/PolicyClip        | -0.00026692482 |
| Train/Policy_loss       | -0.048897866   |
| Train/Ratio             | 1.0016005      |
| Train/Return            | 0.027523413    |
| Train/V                 | -0.020386407   |
| Train/Value             | -0.020386407   |
| Train/control_penalty   | 0.8882665      |
| Train/policy_loss       | -0.048897866   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.00285        |
--------------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 5             |
| Time/Actor_Time         | 0.419         |
| Time/B_Format_Time      | 0.39          |
| Time/B_Original_Form... | 0.405         |
| Time/Buffer             | 0.0132        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.19174848    |
| Train/Action_magnitu... | 1.371678      |
| Train/Action_magnitude  | 1.1025689     |
| Train/Action_max        | 0.46769717    |
| Train/Action_std        | 0.7740494     |
| Train/Entropy           | 1.0931885     |
| Train/Entropy_Loss      | -0.00109      |
| Train/Entropy_loss      | -0.00109      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -2.3543522    |
| Train/Loss              | -0.18183163   |
| Train/PolicyClip        | -0.0021563473 |
| Train/Policy_loss       | -0.19107936   |
| Train/Ratio             | 1.0022051     |
| Train/Return            | 0.39425546    |
| Train/V                 | 0.20543742    |
| Train/Value             | 0.20543742    |
| Train/control_penalty   | 1.034093      |
| Train/policy_loss       | -0.19107936   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.01555       |
-------------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 6              |
| Time/Actor_Time         | 0.436          |
| Time/B_Format_Time      | 0.409          |
| Time/B_Original_Form... | 0.415          |
| Time/Buffer             | 0.0223         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.21853592     |
| Train/Action_magnitu... | 1.3173771      |
| Train/Action_magnitude  | 1.0640038      |
| Train/Action_max        | 0.3907824      |
| Train/Action_std        | 0.77451885     |
| Train/Entropy           | 1.0751119      |
| Train/Entropy_Loss      | -0.00108       |
| Train/Entropy_loss      | -0.00108       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -2.1888933     |
| Train/Loss              | -0.084292635   |
| Train/PolicyClip        | -0.00029904488 |
| Train/Policy_loss       | -0.09378147    |
| Train/Ratio             | 1.0022686      |
| Train/Return            | 0.46565956     |
| Train/V                 | 0.37390074     |
| Train/Value             | 0.37390074     |
| Train/control_penalty   | 1.0563943      |
| Train/policy_loss       | -0.09378147    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0145         |
--------------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 7              |
| Time/Actor_Time         | 0.426          |
| Time/B_Format_Time      | 0.445          |
| Time/B_Original_Form... | 0.446          |
| Time/Buffer             | 0.0181         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.20734894     |
| Train/Action_magnitu... | 1.2389879      |
| Train/Action_magnitude  | 0.9919369      |
| Train/Action_max        | 0.37877062     |
| Train/Action_std        | 0.7323911      |
| Train/Entropy           | 1.0464882      |
| Train/Entropy_Loss      | -0.00105       |
| Train/Entropy_loss      | -0.00105       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -2.1297054     |
| Train/Loss              | 0.014164997    |
| Train/PolicyClip        | -0.00027053626 |
| Train/Policy_loss       | 0.0053403703   |
| Train/Ratio             | 1.0021678      |
| Train/Return            | 0.3005894      |
| Train/V                 | 0.30754757     |
| Train/Value             | 0.30754757     |
| Train/control_penalty   | 0.9871115      |
| Train/policy_loss       | 0.0053403703   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0063         |
--------------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 8              |
| Time/Actor_Time         | 0.437          |
| Time/B_Format_Time      | 0.466          |
| Time/B_Original_Form... | 0.457          |
| Time/Buffer             | 0.0209         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.19117315     |
| Train/Action_magnitu... | 1.1677833      |
| Train/Action_magnitude  | 0.93405604     |
| Train/Action_max        | 0.36023614     |
| Train/Action_std        | 0.6772623      |
| Train/Entropy           | 0.9730671      |
| Train/Entropy_Loss      | -0.000973      |
| Train/Entropy_loss      | -0.000973      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -2.0198247     |
| Train/Loss              | -0.046966158   |
| Train/PolicyClip        | -0.00017925241 |
| Train/Policy_loss       | -0.055136073   |
| Train/Ratio             | 1.0009983      |
| Train/Return            | 0.24399707     |
| Train/V                 | 0.190865       |
| Train/Value             | 0.190865       |
| Train/control_penalty   | 0.91429836     |
| Train/policy_loss       | -0.055136073   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0077         |
--------------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-----------------------------------------
| Itr                     | 9           |
| Time/Actor_Time         | 0.422       |
| Time/B_Format_Time      | 0.436       |
| Time/B_Original_Form... | 0.439       |
| Time/Buffer             | 0.02        |
| Time/Critic_Time        | 0           |
| Train/Action_abs_mean   | 0.20973423  |
| Train/Action_magnitu... | 1.148779    |
| Train/Action_magnitude  | 0.9193792   |
| Train/Action_max        | 0.36201024  |
| Train/Action_std        | 0.6434622   |
| Train/Entropy           | 0.9227847   |
| Train/Entropy_Loss      | -0.000923   |
| Train/Entropy_loss      | -0.000923   |
| Train/Grad_norm_actor   | 0.0         |
| Train/LogProb           | -1.9464531  |
| Train/Loss              | -0.13048495 |
| Train/PolicyClip        | 0.000645027 |
| Train/Policy_loss       | -0.13845335 |
| Train/Ratio             | 1.003214    |
| Train/Return            | 0.3426961   |
| Train/V                 | 0.20594446  |
| Train/Value             | 0.20594446  |
| Train/control_penalty   | 0.8891184   |
| Train/policy_loss       | -0.13845335 |
| Train/recon_loss        | 0.0         |
| train/batch_reward      | 0.0144      |
-----------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 10            |
| Time/Actor_Time         | 0.425         |
| Time/B_Format_Time      | 0.437         |
| Time/B_Original_Form... | 0.431         |
| Time/Buffer             | 0.0251        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.26173228    |
| Train/Action_magnitu... | 1.2062095     |
| Train/Action_magnitude  | 0.9625705     |
| Train/Action_max        | 0.41301954    |
| Train/Action_std        | 0.6726291     |
| Train/Entropy           | 0.9606866     |
| Train/Entropy_Loss      | -0.000961     |
| Train/Entropy_loss      | -0.000961     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.9976244    |
| Train/Loss              | -0.19479467   |
| Train/PolicyClip        | -0.0008867168 |
| Train/Policy_loss       | -0.20332487   |
| Train/Ratio             | 1.0038396     |
| Train/Return            | 0.6859166     |
| Train/V                 | 0.4862957     |
| Train/Value             | 0.4862957     |
| Train/control_penalty   | 0.9490889     |
| Train/policy_loss       | -0.20332487   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0224        |
-------------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 11            |
| Time/Actor_Time         | 0.549         |
| Time/B_Format_Time      | 0.493         |
| Time/B_Original_Form... | 0.428         |
| Time/Buffer             | 0.0258        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.3085894     |
| Train/Action_magnitu... | 1.28552       |
| Train/Action_magnitude  | 1.0310553     |
| Train/Action_max        | 0.5089925     |
| Train/Action_std        | 0.66799015    |
| Train/Entropy           | 0.9490517     |
| Train/Entropy_Loss      | -0.000949     |
| Train/Entropy_loss      | -0.000949     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -2.0834312    |
| Train/Loss              | -0.3103573    |
| Train/PolicyClip        | -0.0047668004 |
| Train/Policy_loss       | -0.31924242   |
| Train/Ratio             | 1.0033153     |
| Train/Return            | 1.2195476     |
| Train/V                 | 0.9029999     |
| Train/Value             | 0.9029999     |
| Train/control_penalty   | 0.98341745    |
| Train/policy_loss       | -0.31924242   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.03625       |
-------------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 12           |
| Time/Actor_Time         | 0.419        |
| Time/B_Format_Time      | 0.435        |
| Time/B_Original_Form... | 0.444        |
| Time/Buffer             | 0.0246       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.26568007   |
| Train/Action_magnitu... | 1.1766652    |
| Train/Action_magnitude  | 0.94063914   |
| Train/Action_max        | 0.45379052   |
| Train/Action_std        | 0.62960505   |
| Train/Entropy           | 0.89237833   |
| Train/Entropy_Loss      | -0.000892    |
| Train/Entropy_loss      | -0.000892    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -1.9048656   |
| Train/Loss              | -0.23997481  |
| Train/PolicyClip        | -0.002159499 |
| Train/Policy_loss       | -0.24809714  |
| Train/Ratio             | 1.0018795    |
| Train/Return            | 1.2325847    |
| Train/V                 | 0.9881545    |
| Train/Value             | 0.9881545    |
| Train/control_penalty   | 0.9014708    |
| Train/policy_loss       | -0.24809714  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.03275      |
------------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 13            |
| Time/Actor_Time         | 0.418         |
| Time/B_Format_Time      | 0.435         |
| Time/B_Original_Form... | 0.446         |
| Time/Buffer             | 0.0232        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.30028832    |
| Train/Action_magnitu... | 1.1647696     |
| Train/Action_magnitude  | 0.93225163    |
| Train/Action_max        | 0.43953007    |
| Train/Action_std        | 0.6408956     |
| Train/Entropy           | 0.8805133     |
| Train/Entropy_Loss      | -0.000881     |
| Train/Entropy_loss      | -0.000881     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.8145041    |
| Train/Loss              | -0.31708738   |
| Train/PolicyClip        | -0.0033301632 |
| Train/Policy_loss       | -0.3256434    |
| Train/Ratio             | 0.9999939     |
| Train/Return            | 1.5724099     |
| Train/V                 | 1.2466966     |
| Train/Value             | 1.2466966     |
| Train/control_penalty   | 0.9436511     |
| Train/policy_loss       | -0.3256434    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.03975       |
-------------------------------------------

 ---------------- Iteration 15 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 14             |
| Time/Actor_Time         | 0.593          |
| Time/B_Format_Time      | 0.492          |
| Time/B_Original_Form... | 0.459          |
| Time/Buffer             | 0.0273         |
| Time/Critic_Time        | 9.54e-07       |
| Train/Action_abs_mean   | 0.28613693     |
| Train/Action_magnitu... | 1.2421495      |
| Train/Action_magnitude  | 0.9956342      |
| Train/Action_max        | 0.5408509      |
| Train/Action_std        | 0.68418825     |
| Train/Entropy           | 0.9567373      |
| Train/Entropy_Loss      | -0.000957      |
| Train/Entropy_loss      | -0.000957      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -1.9479375     |
| Train/Loss              | -0.2243976     |
| Train/PolicyClip        | -0.00021386625 |
| Train/Policy_loss       | -0.2334023     |
| Train/Ratio             | 1.0012527      |
| Train/Return            | 1.593498       |
| Train/V                 | 1.3601195      |
| Train/Value             | 1.3601195      |
| Train/control_penalty   | 0.99614424     |
| Train/policy_loss       | -0.2334023     |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.03805        |
--------------------------------------------

 ---------------- Iteration 16 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 15            |
| Time/Actor_Time         | 0.427         |
| Time/B_Format_Time      | 0.45          |
| Time/B_Original_Form... | 0.438         |
| Time/Buffer             | 0.0276        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.26962957    |
| Train/Action_magnitu... | 1.2407695     |
| Train/Action_magnitude  | 0.9967599     |
| Train/Action_max        | 0.55392444    |
| Train/Action_std        | 0.67691565    |
| Train/Entropy           | 0.9281838     |
| Train/Entropy_Loss      | -0.000928     |
| Train/Entropy_loss      | -0.000928     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.9478937    |
| Train/Loss              | -0.08752449   |
| Train/PolicyClip        | -0.0004964552 |
| Train/Policy_loss       | -0.096390836  |
| Train/Ratio             | 1.0003406     |
| Train/Return            | 1.6347692     |
| Train/V                 | 1.5401565     |
| Train/Value             | 1.5401565     |
| Train/control_penalty   | 0.97945315    |
| Train/policy_loss       | -0.096390836  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.03655       |
-------------------------------------------

 ---------------- Iteration 17 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 16            |
| Time/Actor_Time         | 0.455         |
| Time/B_Format_Time      | 0.452         |
| Time/B_Original_Form... | 0.466         |
| Time/Buffer             | 0.0321        |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.23772697    |
| Train/Action_magnitu... | 1.1741756     |
| Train/Action_magnitude  | 0.9411467     |
| Train/Action_max        | 0.47497997    |
| Train/Action_std        | 0.6519473     |
| Train/Entropy           | 0.9107643     |
| Train/Entropy_Loss      | -0.000911     |
| Train/Entropy_loss      | -0.000911     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.8526535    |
| Train/Loss              | 0.01854024    |
| Train/PolicyClip        | -0.0006525197 |
| Train/Policy_loss       | 0.010253491   |
| Train/Ratio             | 0.9991536     |
| Train/Return            | 1.4489851     |
| Train/V                 | 1.4614841     |
| Train/Value             | 1.4614841     |
| Train/control_penalty   | 0.9197516     |
| Train/policy_loss       | 0.010253491   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0285        |
-------------------------------------------

 ---------------- Iteration 18 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 17            |
| Time/Actor_Time         | 0.453         |
| Time/B_Format_Time      | 0.46          |
| Time/B_Original_Form... | 0.429         |
| Time/Buffer             | 0.0512        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.24856238    |
| Train/Action_magnitu... | 1.077722      |
| Train/Action_magnitude  | 0.86305916    |
| Train/Action_max        | 0.3834387     |
| Train/Action_std        | 0.6004875     |
| Train/Entropy           | 0.80824417    |
| Train/Entropy_Loss      | -0.000808     |
| Train/Entropy_loss      | -0.000808     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.6486219    |
| Train/Loss              | 0.016944034   |
| Train/PolicyClip        | -0.0011772064 |
| Train/Policy_loss       | 0.009070327   |
| Train/Ratio             | 0.99962354    |
| Train/Return            | 1.3560283     |
| Train/V                 | 1.3676367     |
| Train/Value             | 1.3676367     |
| Train/control_penalty   | 0.86819524    |
| Train/policy_loss       | 0.009070327   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.02695       |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 18             |
| Time/Actor_Time         | 0.37           |
| Time/B_Format_Time      | 0.358          |
| Time/B_Original_Form... | 0.364          |
| Time/Buffer             | 0.0338         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.2878727      |
| Train/Action_magnitu... | 1.1090682      |
| Train/Action_magnitude  | 0.8902084      |
| Train/Action_max        | 0.3906223      |
| Train/Action_std        | 0.5837398      |
| Train/Entropy           | 0.7716373      |
| Train/Entropy_Loss      | -0.000772      |
| Train/Entropy_loss      | -0.000772      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -1.6131735     |
| Train/Loss              | -0.0044875825  |
| Train/PolicyClip        | -0.00022197356 |
| Train/Policy_loss       | -0.012530145   |
| Train/Ratio             | 0.99952734     |
| Train/Return            | 1.4036319      |
| Train/V                 | 1.3911866      |
| Train/Value             | 1.3911866      |
| Train/control_penalty   | 0.88142        |
| Train/policy_loss       | -0.012530145   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.03315        |
--------------------------------------------

 ---------------- Iteration 20 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 19             |
| Time/Actor_Time         | 0.371          |
| Time/B_Format_Time      | 0.364          |
| Time/B_Original_Form... | 0.37           |
| Time/Buffer             | 0.034          |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.32962775     |
| Train/Action_magnitu... | 1.1787809      |
| Train/Action_magnitude  | 0.95291173     |
| Train/Action_max        | 0.4793164      |
| Train/Action_std        | 0.60806423     |
| Train/Entropy           | 0.80887836     |
| Train/Entropy_Loss      | -0.000809      |
| Train/Entropy_loss      | -0.000809      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -1.6623896     |
| Train/Loss              | -0.05324165    |
| Train/PolicyClip        | -0.00024809685 |
| Train/Policy_loss       | -0.06191099    |
| Train/Ratio             | 1.0015062      |
| Train/Return            | 1.5220523      |
| Train/V                 | 1.463115       |
| Train/Value             | 1.463115       |
| Train/control_penalty   | 0.94782156     |
| Train/policy_loss       | -0.06191099    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0397         |
--------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 21 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 20            |
| Time/Actor_Time         | 0.367         |
| Time/B_Format_Time      | 0.352         |
| Time/B_Original_Form... | 0.387         |
| Time/Buffer             | 0.0289        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36740917    |
| Train/Action_magnitu... | 1.2503372     |
| Train/Action_magnitude  | 1.0108907     |
| Train/Action_max        | 0.52883565    |
| Train/Action_std        | 0.6080791     |
| Train/Entropy           | 0.82023954    |
| Train/Entropy_Loss      | -0.00082      |
| Train/Entropy_loss      | -0.00082      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.7366494    |
| Train/Loss              | -0.19694445   |
| Train/PolicyClip        | -0.0024365177 |
| Train/Policy_loss       | -0.20601778   |
| Train/Ratio             | 0.9994256     |
| Train/Return            | 1.8799208     |
| Train/V                 | 1.6732386     |
| Train/Value             | 1.6732386     |
| Train/control_penalty   | 0.98935604    |
| Train/policy_loss       | -0.20601778   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0558        |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 21           |
| Time/Actor_Time         | 0.38         |
| Time/B_Format_Time      | 0.377        |
| Time/B_Original_Form... | 0.365        |
| Time/Buffer             | 0.0253       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.35866922   |
| Train/Action_magnitu... | 1.2120368    |
| Train/Action_magnitude  | 0.97041154   |
| Train/Action_max        | 0.5095751    |
| Train/Action_std        | 0.58766526   |
| Train/Entropy           | 0.79544514   |
| Train/Entropy_Loss      | -0.000795    |
| Train/Entropy_loss      | -0.000795    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -1.7468623   |
| Train/Loss              | -0.17533879  |
| Train/PolicyClip        | -0.005083465 |
| Train/Policy_loss       | -0.18409438  |
| Train/Ratio             | 1.0007226    |
| Train/Return            | 1.8410813    |
| Train/V                 | 1.6557776    |
| Train/Value             | 1.6557776    |
| Train/control_penalty   | 0.9551031    |
| Train/policy_loss       | -0.18409438  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.05385      |
------------------------------------------

 ---------------- Iteration 23 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 22             |
| Time/Actor_Time         | 0.366          |
| Time/B_Format_Time      | 0.355          |
| Time/B_Original_Form... | 0.357          |
| Time/Buffer             | 0.0234         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.32407865     |
| Train/Action_magnitu... | 1.1589369      |
| Train/Action_magnitude  | 0.92687255     |
| Train/Action_max        | 0.43421572     |
| Train/Action_std        | 0.56777096     |
| Train/Entropy           | 0.7700275      |
| Train/Entropy_Loss      | -0.00077       |
| Train/Entropy_loss      | -0.00077       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -1.6525396     |
| Train/Loss              | -0.09383298    |
| Train/PolicyClip        | -0.00067138975 |
| Train/Policy_loss       | -0.101888895   |
| Train/Ratio             | 1.0008483      |
| Train/Return            | 1.6910449      |
| Train/V                 | 1.5913785      |
| Train/Value             | 1.5913785      |
| Train/control_penalty   | 0.88259435     |
| Train/policy_loss       | -0.101888895   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0463         |
--------------------------------------------

 ---------------- Iteration 24 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 23             |
| Time/Actor_Time         | 0.359          |
| Time/B_Format_Time      | 0.34           |
| Time/B_Original_Form... | 0.342          |
| Time/Buffer             | 0.0242         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.3529584      |
| Train/Action_magnitu... | 1.1336545      |
| Train/Action_magnitude  | 0.90870315     |
| Train/Action_max        | 0.41698653     |
| Train/Action_std        | 0.55247253     |
| Train/Entropy           | 0.73149574     |
| Train/Entropy_Loss      | -0.000731      |
| Train/Entropy_loss      | -0.000731      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -1.5460231     |
| Train/Loss              | -0.09909144    |
| Train/PolicyClip        | -0.00035267597 |
| Train/Policy_loss       | -0.107372716   |
| Train/Ratio             | 1.0011355      |
| Train/Return            | 1.6969208      |
| Train/V                 | 1.5920614      |
| Train/Value             | 1.5920614      |
| Train/control_penalty   | 0.90127754     |
| Train/policy_loss       | -0.107372716   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.04685        |
--------------------------------------------

 ---------------- Iteration 25 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 24           |
| Time/Actor_Time         | 0.348        |
| Time/B_Format_Time      | 0.353        |
| Time/B_Original_Form... | 0.356        |
| Time/Buffer             | 0.0267       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37391055   |
| Train/Action_magnitu... | 1.1625912    |
| Train/Action_magnitude  | 0.93106866   |
| Train/Action_max        | 0.41573316   |
| Train/Action_std        | 0.54843855   |
| Train/Entropy           | 0.73139817   |
| Train/Entropy_Loss      | -0.000731    |
| Train/Entropy_loss      | -0.000731    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -1.5492735   |
| Train/Loss              | -0.09734564  |
| Train/PolicyClip        | 0.0004681354 |
| Train/Policy_loss       | -0.105853915 |
| Train/Ratio             | 1.0028522    |
| Train/Return            | 1.8477553    |
| Train/V                 | 1.7365955    |
| Train/Value             | 1.7365955    |
| Train/control_penalty   | 0.9239676    |
| Train/policy_loss       | -0.105853915 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.05195      |
------------------------------------------

 ---------------- Iteration 26 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 25            |
| Time/Actor_Time         | 0.356         |
| Time/B_Format_Time      | 0.341         |
| Time/B_Original_Form... | 0.344         |
| Time/Buffer             | 0.0253        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.40693867    |
| Train/Action_magnitu... | 1.2082554     |
| Train/Action_magnitude  | 0.9612324     |
| Train/Action_max        | 0.43268716    |
| Train/Action_std        | 0.5514995     |
| Train/Entropy           | 0.7553639     |
| Train/Entropy_Loss      | -0.000755     |
| Train/Entropy_loss      | -0.000755     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.5616035    |
| Train/Loss              | -0.05999062   |
| Train/PolicyClip        | -0.0004279942 |
| Train/Policy_loss       | -0.068617776  |
| Train/Ratio             | 1.0008069     |
| Train/Return            | 1.845369      |
| Train/V                 | 1.7697414     |
| Train/Value             | 1.7697414     |
| Train/control_penalty   | 0.938252      |
| Train/policy_loss       | -0.068617776  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.04745       |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 26            |
| Time/Actor_Time         | 0.354         |
| Time/B_Format_Time      | 0.357         |
| Time/B_Original_Form... | 0.356         |
| Time/Buffer             | 0.0225        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.41590348    |
| Train/Action_magnitu... | 1.2125956     |
| Train/Action_magnitude  | 0.95837325    |
| Train/Action_max        | 0.40781984    |
| Train/Action_std        | 0.5515882     |
| Train/Entropy           | 0.7636215     |
| Train/Entropy_Loss      | -0.000764     |
| Train/Entropy_loss      | -0.000764     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.5667305    |
| Train/Loss              | -0.14047982   |
| Train/PolicyClip        | -0.0007396218 |
| Train/Policy_loss       | -0.14928351   |
| Train/Ratio             | 1.0001093     |
| Train/Return            | 1.9554948     |
| Train/V                 | 1.8078744     |
| Train/Value             | 1.8078744     |
| Train/control_penalty   | 0.95673186    |
| Train/policy_loss       | -0.14928351   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05585       |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 27             |
| Time/Actor_Time         | 0.354          |
| Time/B_Format_Time      | 0.352          |
| Time/B_Original_Form... | 0.35           |
| Time/Buffer             | 0.0264         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.39734232     |
| Train/Action_magnitu... | 1.1605395      |
| Train/Action_magnitude  | 0.9178704      |
| Train/Action_max        | 0.39910474     |
| Train/Action_std        | 0.5305568      |
| Train/Entropy           | 0.72512287     |
| Train/Entropy_Loss      | -0.000725      |
| Train/Entropy_loss      | -0.000725      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -1.4730335     |
| Train/Loss              | -0.087492175   |
| Train/PolicyClip        | -0.00022354245 |
| Train/Policy_loss       | -0.09599468    |
| Train/Ratio             | 1.0010711      |
| Train/Return            | 2.0790966      |
| Train/V                 | 1.9864668      |
| Train/Value             | 1.9864668      |
| Train/control_penalty   | 0.9227627      |
| Train/policy_loss       | -0.09599468    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0598         |
--------------------------------------------

 ---------------- Iteration 29 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 28            |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.334         |
| Time/B_Original_Form... | 0.34          |
| Time/Buffer             | 0.0318        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3896877     |
| Train/Action_magnitu... | 1.1239183     |
| Train/Action_magnitude  | 0.89146775    |
| Train/Action_max        | 0.43283755    |
| Train/Action_std        | 0.5132263     |
| Train/Entropy           | 0.6932576     |
| Train/Entropy_Loss      | -0.000693     |
| Train/Entropy_loss      | -0.000693     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.4068532    |
| Train/Loss              | -0.16411093   |
| Train/PolicyClip        | -0.0023459862 |
| Train/Policy_loss       | -0.17240019   |
| Train/Ratio             | 1.0020919     |
| Train/Return            | 1.9910697     |
| Train/V                 | 1.8222476     |
| Train/Value             | 1.8222476     |
| Train/control_penalty   | 0.8982521     |
| Train/policy_loss       | -0.17240019   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05865       |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 29            |
| Time/Actor_Time         | 0.483         |
| Time/B_Format_Time      | 0.526         |
| Time/B_Original_Form... | 0.473         |
| Time/Buffer             | 0.0532        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3913013     |
| Train/Action_magnitu... | 1.1067796     |
| Train/Action_magnitude  | 0.8773715     |
| Train/Action_max        | 0.43010616    |
| Train/Action_std        | 0.5037407     |
| Train/Entropy           | 0.67475945    |
| Train/Entropy_Loss      | -0.000675     |
| Train/Entropy_loss      | -0.000675     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.4239132    |
| Train/Loss              | -0.080152646  |
| Train/PolicyClip        | -0.0012367828 |
| Train/Policy_loss       | -0.08829238   |
| Train/Ratio             | 1.0003998     |
| Train/Return            | 1.8559152     |
| Train/V                 | 1.770952      |
| Train/Value             | 1.770952      |
| Train/control_penalty   | 0.8814503     |
| Train/policy_loss       | -0.08829238   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05235       |
-------------------------------------------

 ---------------- Iteration 31 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 30           |
| Time/Actor_Time         | 0.42         |
| Time/B_Format_Time      | 0.405        |
| Time/B_Original_Form... | 0.407        |
| Time/Buffer             | 0.0301       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37852174   |
| Train/Action_magnitu... | 1.0813763    |
| Train/Action_magnitude  | 0.85560906   |
| Train/Action_max        | 0.3621463    |
| Train/Action_std        | 0.48951596   |
| Train/Entropy           | 0.6460639    |
| Train/Entropy_Loss      | -0.000646    |
| Train/Entropy_loss      | -0.000646    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -1.3688191   |
| Train/Loss              | -0.16531129  |
| Train/PolicyClip        | -0.002236239 |
| Train/Policy_loss       | -0.17325835  |
| Train/Ratio             | 0.9994265    |
| Train/Return            | 1.8368422    |
| Train/V                 | 1.6644477    |
| Train/Value             | 1.6644477    |
| Train/control_penalty   | 0.859313     |
| Train/policy_loss       | -0.17325835  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.05285      |
------------------------------------------

 ---------------- Iteration 32 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 31            |
| Time/Actor_Time         | 0.42          |
| Time/B_Format_Time      | 0.423         |
| Time/B_Original_Form... | 0.464         |
| Time/Buffer             | 0.0287        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37401125    |
| Train/Action_magnitu... | 1.0740342     |
| Train/Action_magnitude  | 0.8497496     |
| Train/Action_max        | 0.3416458     |
| Train/Action_std        | 0.47827035    |
| Train/Entropy           | 0.62136817    |
| Train/Entropy_Loss      | -0.000621     |
| Train/Entropy_loss      | -0.000621     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.3211725    |
| Train/Loss              | -0.14808749   |
| Train/PolicyClip        | -0.0013920725 |
| Train/Policy_loss       | -0.15588652   |
| Train/Ratio             | 1.0011108     |
| Train/Return            | 1.8130102     |
| Train/V                 | 1.6595514     |
| Train/Value             | 1.6595514     |
| Train/control_penalty   | 0.8420395     |
| Train/policy_loss       | -0.15588652   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05115       |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-----------------------------------------
| Itr                     | 32          |
| Time/Actor_Time         | 0.437       |
| Time/B_Format_Time      | 0.545       |
| Time/B_Original_Form... | 0.407       |
| Time/Buffer             | 0.0296      |
| Time/Critic_Time        | 1.19e-06    |
| Train/Action_abs_mean   | 0.39145738  |
| Train/Action_magnitu... | 1.0738425   |
| Train/Action_magnitude  | 0.84805506  |
| Train/Action_max        | 0.38975984  |
| Train/Action_std        | 0.46533048  |
| Train/Entropy           | 0.5916973   |
| Train/Entropy_Loss      | -0.000592   |
| Train/Entropy_loss      | -0.000592   |
| Train/Grad_norm_actor   | 0.0         |
| Train/LogProb           | -1.2762711  |
| Train/Loss              | -0.17164016 |
| Train/PolicyClip        | 0.001014158 |
| Train/Policy_loss       | -0.1794571  |
| Train/Ratio             | 1.002476    |
| Train/Return            | 1.6955521   |
| Train/V                 | 1.5092511   |
| Train/Value             | 1.5092511   |
| Train/control_penalty   | 0.8408629   |
| Train/policy_loss       | -0.1794571  |
| Train/recon_loss        | 0.0         |
| train/batch_reward      | 0.0486      |
-----------------------------------------

 ---------------- Iteration 34 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 33            |
| Time/Actor_Time         | 0.698         |
| Time/B_Format_Time      | 1.1           |
| Time/B_Original_Form... | 1.27          |
| Time/Buffer             | 0.0431        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36805853    |
| Train/Action_magnitu... | 1.0118123     |
| Train/Action_magnitude  | 0.8011887     |
| Train/Action_max        | 0.36463198    |
| Train/Action_std        | 0.4383249     |
| Train/Entropy           | 0.53209895    |
| Train/Entropy_Loss      | -0.000532     |
| Train/Entropy_loss      | -0.000532     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.146237     |
| Train/Loss              | -0.22588293   |
| Train/PolicyClip        | -0.0015257822 |
| Train/Policy_loss       | -0.23328437   |
| Train/Ratio             | 1.0025578     |
| Train/Return            | 1.8327625     |
| Train/V                 | 1.602185      |
| Train/Value             | 1.602185      |
| Train/control_penalty   | 0.7933546     |
| Train/policy_loss       | -0.23328437   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05265       |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 34            |
| Time/Actor_Time         | 0.697         |
| Time/B_Format_Time      | 0.562         |
| Time/B_Original_Form... | 0.615         |
| Time/Buffer             | 0.0286        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37841818    |
| Train/Action_magnitu... | 0.99425524    |
| Train/Action_magnitude  | 0.7868959     |
| Train/Action_max        | 0.3535187     |
| Train/Action_std        | 0.41444317    |
| Train/Entropy           | 0.47055185    |
| Train/Entropy_Loss      | -0.000471     |
| Train/Entropy_loss      | -0.000471     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.0622475    |
| Train/Loss              | -0.24016967   |
| Train/PolicyClip        | -0.0038405636 |
| Train/Policy_loss       | -0.24755776   |
| Train/Ratio             | 0.998457      |
| Train/Return            | 1.9658918     |
| Train/V                 | 1.7159433     |
| Train/Value             | 1.7159433     |
| Train/control_penalty   | 0.7858642     |
| Train/policy_loss       | -0.24755776   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0572        |
-------------------------------------------

 ---------------- Iteration 36 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 35            |
| Time/Actor_Time         | 0.37          |
| Time/B_Format_Time      | 0.366         |
| Time/B_Original_Form... | 0.369         |
| Time/Buffer             | 0.03          |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.40134335    |
| Train/Action_magnitu... | 1.0225635     |
| Train/Action_magnitude  | 0.80821526    |
| Train/Action_max        | 0.39027506    |
| Train/Action_std        | 0.40049177    |
| Train/Entropy           | 0.43783897    |
| Train/Entropy_Loss      | -0.000438     |
| Train/Entropy_loss      | -0.000438     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.9587906    |
| Train/Loss              | -0.22084418   |
| Train/PolicyClip        | -0.0013219367 |
| Train/Policy_loss       | -0.22839683   |
| Train/Ratio             | 1.0034963     |
| Train/Return            | 2.1206002     |
| Train/V                 | 1.8912656     |
| Train/Value             | 1.8912656     |
| Train/control_penalty   | 0.7990495     |
| Train/policy_loss       | -0.22839683   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0589        |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 36             |
| Time/Actor_Time         | 0.365          |
| Time/B_Format_Time      | 0.367          |
| Time/B_Original_Form... | 0.362          |
| Time/Buffer             | 0.0219         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.40347916     |
| Train/Action_magnitu... | 1.0009657      |
| Train/Action_magnitude  | 0.79202276     |
| Train/Action_max        | 0.39291105     |
| Train/Action_std        | 0.3988424      |
| Train/Entropy           | 0.4081177      |
| Train/Entropy_Loss      | -0.000408      |
| Train/Entropy_loss      | -0.000408      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -0.8326604     |
| Train/Loss              | -0.058049604   |
| Train/PolicyClip        | -0.00027676698 |
| Train/Policy_loss       | -0.0657419     |
| Train/Ratio             | 0.99798894     |
| Train/Return            | 2.309092       |
| Train/V                 | 2.2401648      |
| Train/Value             | 2.2401648      |
| Train/control_penalty   | 0.8100414      |
| Train/policy_loss       | -0.0657419     |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.057          |
--------------------------------------------

 ---------------- Iteration 38 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 37             |
| Time/Actor_Time         | 0.35           |
| Time/B_Format_Time      | 0.354          |
| Time/B_Original_Form... | 0.359          |
| Time/Buffer             | 0.0258         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.41133565     |
| Train/Action_magnitu... | 1.0606438      |
| Train/Action_magnitude  | 0.8414824      |
| Train/Action_max        | 0.41039726     |
| Train/Action_std        | 0.4278869      |
| Train/Entropy           | 0.45792186     |
| Train/Entropy_Loss      | -0.000458      |
| Train/Entropy_loss      | -0.000458      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -0.9286672     |
| Train/Loss              | -0.00033225492 |
| Train/PolicyClip        | 0.00080314034  |
| Train/Policy_loss       | -0.008268333   |
| Train/Ratio             | 0.99916416     |
| Train/Return            | 2.1435742      |
| Train/V                 | 2.1305153      |
| Train/Value             | 2.1305153      |
| Train/control_penalty   | 0.8394         |
| Train/policy_loss       | -0.008268333   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.05835        |
--------------------------------------------

 ---------------- Iteration 39 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 38           |
| Time/Actor_Time         | 0.357        |
| Time/B_Format_Time      | 0.343        |
| Time/B_Original_Form... | 0.346        |
| Time/Buffer             | 0.0354       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.43090048   |
| Train/Action_magnitu... | 1.1275493    |
| Train/Action_magnitude  | 0.9000705    |
| Train/Action_max        | 0.4801478    |
| Train/Action_std        | 0.44277525   |
| Train/Entropy           | 0.48612374   |
| Train/Entropy_Loss      | -0.000486    |
| Train/Entropy_loss      | -0.000486    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -1.0451677   |
| Train/Loss              | 0.042017087  |
| Train/PolicyClip        | -0.000991841 |
| Train/Policy_loss       | 0.033551197  |
| Train/Ratio             | 0.9993621    |
| Train/Return            | 2.1799538    |
| Train/V                 | 2.2162094    |
| Train/Value             | 2.2162094    |
| Train/control_penalty   | 0.89520156   |
| Train/policy_loss       | 0.033551197  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06         |
------------------------------------------

 ---------------- Iteration 40 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 39            |
| Time/Actor_Time         | 0.363         |
| Time/B_Format_Time      | 0.363         |
| Time/B_Original_Form... | 0.364         |
| Time/Buffer             | 0.0325        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4280514     |
| Train/Action_magnitu... | 1.1193141     |
| Train/Action_magnitude  | 0.89360076    |
| Train/Action_max        | 0.44550136    |
| Train/Action_std        | 0.4465058     |
| Train/Entropy           | 0.51015514    |
| Train/Entropy_Loss      | -0.00051      |
| Train/Entropy_loss      | -0.00051      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -1.0483438    |
| Train/Loss              | 0.05791364    |
| Train/PolicyClip        | -0.0008537279 |
| Train/Policy_loss       | 0.049534578   |
| Train/Ratio             | 1.0003443     |
| Train/Return            | 2.209827      |
| Train/V                 | 2.257399      |
| Train/Value             | 2.257399      |
| Train/control_penalty   | 0.88892156    |
| Train/policy_loss       | 0.049534578   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0606        |
-------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 41 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 40           |
| Time/Actor_Time         | 0.366        |
| Time/B_Format_Time      | 0.356        |
| Time/B_Original_Form... | 0.362        |
| Time/Buffer             | 0.0267       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.40878236   |
| Train/Action_magnitu... | 1.0888228    |
| Train/Action_magnitude  | 0.8669173    |
| Train/Action_max        | 0.3923534    |
| Train/Action_std        | 0.448844     |
| Train/Entropy           | 0.5208652    |
| Train/Entropy_Loss      | -0.000521    |
| Train/Entropy_loss      | -0.000521    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -1.0503542   |
| Train/Loss              | -0.02012682  |
| Train/PolicyClip        | 0.0010933571 |
| Train/Policy_loss       | -0.028226139 |
| Train/Ratio             | 1.0014589    |
| Train/Return            | 2.0737114    |
| Train/V                 | 2.0465837    |
| Train/Value             | 2.0465837    |
| Train/control_penalty   | 0.8620185    |
| Train/policy_loss       | -0.028226139 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0586       |
------------------------------------------

 ---------------- Iteration 42 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 41             |
| Time/Actor_Time         | 0.364          |
| Time/B_Format_Time      | 0.51           |
| Time/B_Original_Form... | 0.392          |
| Time/Buffer             | 0.0303         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.40222716     |
| Train/Action_magnitu... | 1.0328985      |
| Train/Action_magnitude  | 0.8207329      |
| Train/Action_max        | 0.3752596      |
| Train/Action_std        | 0.4184487      |
| Train/Entropy           | 0.44048008     |
| Train/Entropy_Loss      | -0.00044       |
| Train/Entropy_loss      | -0.00044       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -0.92707753    |
| Train/Loss              | -0.050288126   |
| Train/PolicyClip        | -0.00039485368 |
| Train/Policy_loss       | -0.05816054    |
| Train/Ratio             | 1.0019441      |
| Train/Return            | 2.1403613      |
| Train/V                 | 2.0812464      |
| Train/Value             | 2.0812464      |
| Train/control_penalty   | 0.83128905     |
| Train/policy_loss       | -0.05816054    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0561         |
--------------------------------------------

 ---------------- Iteration 43 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 42           |
| Time/Actor_Time         | 0.373        |
| Time/B_Format_Time      | 0.398        |
| Time/B_Original_Form... | 0.381        |
| Time/Buffer             | 0.0224       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.4032051    |
| Train/Action_magnitu... | 1.0359808    |
| Train/Action_magnitude  | 0.82553166   |
| Train/Action_max        | 0.44393378   |
| Train/Action_std        | 0.41038066   |
| Train/Entropy           | 0.41550776   |
| Train/Entropy_Loss      | -0.000416    |
| Train/Entropy_loss      | -0.000416    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.85906357  |
| Train/Loss              | -0.042810343 |
| Train/PolicyClip        | 0.0004921794 |
| Train/Policy_loss       | -0.050581954 |
| Train/Ratio             | 1.0016167    |
| Train/Return            | 2.351993     |
| Train/V                 | 2.301791     |
| Train/Value             | 2.301791     |
| Train/control_penalty   | 0.8187117    |
| Train/policy_loss       | -0.050581954 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.05315      |
------------------------------------------

 ---------------- Iteration 44 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 43           |
| Time/Actor_Time         | 0.369        |
| Time/B_Format_Time      | 0.362        |
| Time/B_Original_Form... | 0.36         |
| Time/Buffer             | 0.0231       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.40234166   |
| Train/Action_magnitu... | 1.0426207    |
| Train/Action_magnitude  | 0.829363     |
| Train/Action_max        | 0.4824438    |
| Train/Action_std        | 0.41382286   |
| Train/Entropy           | 0.4186745    |
| Train/Entropy_Loss      | -0.000419    |
| Train/Entropy_loss      | -0.000419    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.9105045   |
| Train/Loss              | -0.060169    |
| Train/PolicyClip        | 0.0004222083 |
| Train/Policy_loss       | -0.06802352  |
| Train/Ratio             | 0.9987597    |
| Train/Return            | 2.5777185    |
| Train/V                 | 2.5022533    |
| Train/Value             | 2.5022533    |
| Train/control_penalty   | 0.82731944   |
| Train/policy_loss       | -0.06802352  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0568       |
------------------------------------------

 ---------------- Iteration 45 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 44             |
| Time/Actor_Time         | 0.35           |
| Time/B_Format_Time      | 0.362          |
| Time/B_Original_Form... | 0.352          |
| Time/Buffer             | 0.0244         |
| Time/Critic_Time        | 9.54e-07       |
| Train/Action_abs_mean   | 0.3920646      |
| Train/Action_magnitu... | 1.0281086      |
| Train/Action_magnitude  | 0.8210045      |
| Train/Action_max        | 0.47042984     |
| Train/Action_std        | 0.40990835     |
| Train/Entropy           | 0.41780245     |
| Train/Entropy_Loss      | -0.000418      |
| Train/Entropy_loss      | -0.000418      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -0.8925639     |
| Train/Loss              | -0.1050972     |
| Train/PolicyClip        | -0.00071356393 |
| Train/Policy_loss       | -0.11278243    |
| Train/Ratio             | 1.0017767      |
| Train/Return            | 2.5081239      |
| Train/V                 | 2.3972256      |
| Train/Value             | 2.3972256      |
| Train/control_penalty   | 0.81030387     |
| Train/policy_loss       | -0.11278243    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.05785        |
--------------------------------------------

 ---------------- Iteration 46 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 45             |
| Time/Actor_Time         | 0.347          |
| Time/B_Format_Time      | 0.35           |
| Time/B_Original_Form... | 0.352          |
| Time/Buffer             | 0.022          |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.3979602      |
| Train/Action_magnitu... | 1.0145304      |
| Train/Action_magnitude  | 0.80754304     |
| Train/Action_max        | 0.45845        |
| Train/Action_std        | 0.39893842     |
| Train/Entropy           | 0.39894733     |
| Train/Entropy_Loss      | -0.000399      |
| Train/Entropy_loss      | -0.000399      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -0.860233      |
| Train/Loss              | -0.08096859    |
| Train/PolicyClip        | -0.00052532856 |
| Train/Policy_loss       | -0.08863868    |
| Train/Ratio             | 1.0003408      |
| Train/Return            | 2.2389872      |
| Train/V                 | 2.1524725      |
| Train/Value             | 2.1524725      |
| Train/control_penalty   | 0.80690414     |
| Train/policy_loss       | -0.08863868    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.05665        |
--------------------------------------------

 ---------------- Iteration 47 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 46             |
| Time/Actor_Time         | 0.351          |
| Time/B_Format_Time      | 0.348          |
| Time/B_Original_Form... | 0.35           |
| Time/Buffer             | 0.0314         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.39847264     |
| Train/Action_magnitu... | 0.9849205      |
| Train/Action_magnitude  | 0.78128076     |
| Train/Action_max        | 0.41649318     |
| Train/Action_std        | 0.37546498     |
| Train/Entropy           | 0.3377573      |
| Train/Entropy_Loss      | -0.000338      |
| Train/Entropy_loss      | -0.000338      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -0.76723975    |
| Train/Loss              | -0.08198337    |
| Train/PolicyClip        | -0.00027241188 |
| Train/Policy_loss       | -0.089515      |
| Train/Ratio             | 1.0018901      |
| Train/Return            | 2.0239446      |
| Train/V                 | 1.9333391      |
| Train/Value             | 1.9333391      |
| Train/control_penalty   | 0.7869387      |
| Train/policy_loss       | -0.089515      |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0551         |
--------------------------------------------

 ---------------- Iteration 48 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 47           |
| Time/Actor_Time         | 0.355        |
| Time/B_Format_Time      | 0.325        |
| Time/B_Original_Form... | 0.327        |
| Time/Buffer             | 0.0255       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39179134   |
| Train/Action_magnitu... | 0.96008074   |
| Train/Action_magnitude  | 0.7633096    |
| Train/Action_max        | 0.39013106   |
| Train/Action_std        | 0.3592438    |
| Train/Entropy           | 0.29026565   |
| Train/Entropy_Loss      | -0.00029     |
| Train/Entropy_loss      | -0.00029     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.62213063  |
| Train/Loss              | -0.05870486  |
| Train/PolicyClip        | 9.093064e-05 |
| Train/Policy_loss       | -0.06610334  |
| Train/Ratio             | 1.0006787    |
| Train/Return            | 2.054002     |
| Train/V                 | 1.9867234    |
| Train/Value             | 1.9867234    |
| Train/control_penalty   | 0.7688745    |
| Train/policy_loss       | -0.06610334  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.05575      |
------------------------------------------

 ---------------- Iteration 49 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 48            |
| Time/Actor_Time         | 0.354         |
| Time/B_Format_Time      | 0.346         |
| Time/B_Original_Form... | 0.35          |
| Time/Buffer             | 0.0278        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3828549     |
| Train/Action_magnitu... | 0.941854      |
| Train/Action_magnitude  | 0.7470128     |
| Train/Action_max        | 0.36054668    |
| Train/Action_std        | 0.34619567    |
| Train/Entropy           | 0.24989969    |
| Train/Entropy_Loss      | -0.00025      |
| Train/Entropy_loss      | -0.00025      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.5525633    |
| Train/Loss              | -0.07533273   |
| Train/PolicyClip        | -0.0005443304 |
| Train/Policy_loss       | -0.08262661   |
| Train/Ratio             | 0.9993538     |
| Train/Return            | 2.1384032     |
| Train/V                 | 2.0586162     |
| Train/Value             | 2.0586162     |
| Train/control_penalty   | 0.7543782     |
| Train/policy_loss       | -0.08262661   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0595        |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 49            |
| Time/Actor_Time         | 0.358         |
| Time/B_Format_Time      | 0.366         |
| Time/B_Original_Form... | 0.362         |
| Time/Buffer             | 0.194         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37652126    |
| Train/Action_magnitu... | 0.9491998     |
| Train/Action_magnitude  | 0.7488126     |
| Train/Action_max        | 0.34613138    |
| Train/Action_std        | 0.34123978    |
| Train/Entropy           | 0.23680776    |
| Train/Entropy_Loss      | -0.000237     |
| Train/Entropy_loss      | -0.000237     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.5202737    |
| Train/Loss              | -0.041633327  |
| Train/PolicyClip        | -0.0003131369 |
| Train/Policy_loss       | -0.04878244   |
| Train/Ratio             | 0.99934685    |
| Train/Return            | 2.3869717     |
| Train/V                 | 2.338955      |
| Train/Value             | 2.338955      |
| Train/control_penalty   | 0.7385924     |
| Train/policy_loss       | -0.04878244   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06145       |
-------------------------------------------

 ---------------- Iteration 51 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 50            |
| Time/Actor_Time         | 0.348         |
| Time/B_Format_Time      | 0.343         |
| Time/B_Original_Form... | 0.348         |
| Time/Buffer             | 0.0351        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.39541152    |
| Train/Action_magnitu... | 0.9568486     |
| Train/Action_magnitude  | 0.75175685    |
| Train/Action_max        | 0.33547506    |
| Train/Action_std        | 0.34539202    |
| Train/Entropy           | 0.25552696    |
| Train/Entropy_Loss      | -0.000256     |
| Train/Entropy_loss      | -0.000256     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.52172536   |
| Train/Loss              | 0.029561687   |
| Train/PolicyClip        | -0.0034810342 |
| Train/Policy_loss       | 0.02220704    |
| Train/Ratio             | 0.99630564    |
| Train/Return            | 2.3666232     |
| Train/V                 | 2.3838544     |
| Train/Value             | 2.3838544     |
| Train/control_penalty   | 0.7610175     |
| Train/policy_loss       | 0.02220704    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0583        |
-------------------------------------------

 ---------------- Iteration 52 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 51           |
| Time/Actor_Time         | 0.35         |
| Time/B_Format_Time      | 0.342        |
| Time/B_Original_Form... | 0.341        |
| Time/Buffer             | 0.0294       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.40374324   |
| Train/Action_magnitu... | 1.0068965    |
| Train/Action_magnitude  | 0.7889663    |
| Train/Action_max        | 0.36385027   |
| Train/Action_std        | 0.36281264   |
| Train/Entropy           | 0.3073938    |
| Train/Entropy_Loss      | -0.000307    |
| Train/Entropy_loss      | -0.000307    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.6279465   |
| Train/Loss              | 0.033164088  |
| Train/PolicyClip        | -0.002082343 |
| Train/Policy_loss       | 0.025706988  |
| Train/Ratio             | 0.9996488    |
| Train/Return            | 2.3232365    |
| Train/V                 | 2.3442893    |
| Train/Value             | 2.3442893    |
| Train/control_penalty   | 0.77644944   |
| Train/policy_loss       | 0.025706988  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0579       |
------------------------------------------

 ---------------- Iteration 53 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 52            |
| Time/Actor_Time         | 0.354         |
| Time/B_Format_Time      | 0.34          |
| Time/B_Original_Form... | 0.343         |
| Time/Buffer             | 0.0259        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.42299697    |
| Train/Action_magnitu... | 1.0313993     |
| Train/Action_magnitude  | 0.8102746     |
| Train/Action_max        | 0.388148      |
| Train/Action_std        | 0.37845072    |
| Train/Entropy           | 0.35529894    |
| Train/Entropy_Loss      | -0.000355     |
| Train/Entropy_loss      | -0.000355     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.6807479    |
| Train/Loss              | 0.026664212   |
| Train/PolicyClip        | -0.0011249587 |
| Train/Policy_loss       | 0.018850366   |
| Train/Ratio             | 0.9979147     |
| Train/Return            | 2.1339023     |
| Train/V                 | 2.155628      |
| Train/Value             | 2.155628      |
| Train/control_penalty   | 0.8169146     |
| Train/policy_loss       | 0.018850366   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0571        |
-------------------------------------------

 ---------------- Iteration 54 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 53             |
| Time/Actor_Time         | 0.353          |
| Time/B_Format_Time      | 0.34           |
| Time/B_Original_Form... | 0.342          |
| Time/Buffer             | 0.0268         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.42390558     |
| Train/Action_magnitu... | 1.0414858      |
| Train/Action_magnitude  | 0.8222731      |
| Train/Action_max        | 0.42053896     |
| Train/Action_std        | 0.37323076     |
| Train/Entropy           | 0.33526123     |
| Train/Entropy_Loss      | -0.000335      |
| Train/Entropy_loss      | -0.000335      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -0.70525116    |
| Train/Loss              | -0.036017746   |
| Train/PolicyClip        | -0.00034729822 |
| Train/Policy_loss       | -0.043871045   |
| Train/Ratio             | 1.0002363      |
| Train/Return            | 2.050387       |
| Train/V                 | 2.00637        |
| Train/Value             | 2.00637        |
| Train/control_penalty   | 0.8188561      |
| Train/policy_loss       | -0.043871045   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.05835        |
--------------------------------------------

 ---------------- Iteration 55 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 54             |
| Time/Actor_Time         | 0.36           |
| Time/B_Format_Time      | 0.357          |
| Time/B_Original_Form... | 0.352          |
| Time/Buffer             | 0.0196         |
| Time/Critic_Time        | 9.54e-07       |
| Train/Action_abs_mean   | 0.4144509      |
| Train/Action_magnitu... | 1.03589        |
| Train/Action_magnitude  | 0.8179785      |
| Train/Action_max        | 0.45008838     |
| Train/Action_std        | 0.36953866     |
| Train/Entropy           | 0.3176452      |
| Train/Entropy_Loss      | -0.000318      |
| Train/Entropy_loss      | -0.000318      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -0.67339754    |
| Train/Loss              | -0.060555793   |
| Train/PolicyClip        | -0.00055503135 |
| Train/Policy_loss       | -0.06834912    |
| Train/Ratio             | 0.99828476     |
| Train/Return            | 2.1266491      |
| Train/V                 | 2.0552568      |
| Train/Value             | 2.0552568      |
| Train/control_penalty   | 0.811098       |
| Train/policy_loss       | -0.06834912    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.05955        |
--------------------------------------------

 ---------------- Iteration 56 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 55            |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.356         |
| Time/B_Original_Form... | 0.358         |
| Time/Buffer             | 0.027         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.42925343    |
| Train/Action_magnitu... | 1.07004       |
| Train/Action_magnitude  | 0.8472844     |
| Train/Action_max        | 0.4901731     |
| Train/Action_std        | 0.37267208    |
| Train/Entropy           | 0.32639697    |
| Train/Entropy_Loss      | -0.000326     |
| Train/Entropy_loss      | -0.000326     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.6925402    |
| Train/Loss              | -0.062021494  |
| Train/PolicyClip        | 0.00013668729 |
| Train/Policy_loss       | -0.07013841   |
| Train/Ratio             | 1.0008276     |
| Train/Return            | 2.462532      |
| Train/V                 | 2.3952255     |
| Train/Value             | 2.3952255     |
| Train/control_penalty   | 0.84433115    |
| Train/policy_loss       | -0.07013841   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07005       |
-------------------------------------------

 ---------------- Iteration 57 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-----------------------------------------
| Itr                     | 56          |
| Time/Actor_Time         | 0.356       |
| Time/B_Format_Time      | 0.336       |
| Time/B_Original_Form... | 0.339       |
| Time/Buffer             | 0.0245      |
| Time/Critic_Time        | 0           |
| Train/Action_abs_mean   | 0.4370188   |
| Train/Action_magnitu... | 1.1087078   |
| Train/Action_magnitude  | 0.8750635   |
| Train/Action_max        | 0.5318855   |
| Train/Action_std        | 0.38699132  |
| Train/Entropy           | 0.35796437  |
| Train/Entropy_Loss      | -0.000358   |
| Train/Entropy_loss      | -0.000358   |
| Train/Grad_norm_actor   | 0.0         |
| Train/LogProb           | -0.7799521  |
| Train/Loss              | -0.14034876 |
| Train/PolicyClip        | 0.000133484 |
| Train/Policy_loss       | -0.14860322 |
| Train/Ratio             | 1.0023168   |
| Train/Return            | 2.512665    |
| Train/V                 | 2.360146    |
| Train/Value             | 2.360146    |
| Train/control_penalty   | 0.8612418   |
| Train/policy_loss       | -0.14860322 |
| Train/recon_loss        | 0.0         |
| train/batch_reward      | 0.0784      |
-----------------------------------------

 ---------------- Iteration 58 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 57            |
| Time/Actor_Time         | 0.351         |
| Time/B_Format_Time      | 0.343         |
| Time/B_Original_Form... | 0.343         |
| Time/Buffer             | 0.0313        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.44258273    |
| Train/Action_magnitu... | 1.08184       |
| Train/Action_magnitude  | 0.85372305    |
| Train/Action_max        | 0.51316875    |
| Train/Action_std        | 0.3799102     |
| Train/Entropy           | 0.33827785    |
| Train/Entropy_Loss      | -0.000338     |
| Train/Entropy_loss      | -0.000338     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.7170157    |
| Train/Loss              | -0.103758655  |
| Train/PolicyClip        | 0.00017193546 |
| Train/Policy_loss       | -0.11199569   |
| Train/Ratio             | 1.0026736     |
| Train/Return            | 2.3798738     |
| Train/V                 | 2.2699182     |
| Train/Value             | 2.2699182     |
| Train/control_penalty   | 0.8575311     |
| Train/policy_loss       | -0.11199569   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0724        |
-------------------------------------------

 ---------------- Iteration 59 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 58           |
| Time/Actor_Time         | 0.356        |
| Time/B_Format_Time      | 0.35         |
| Time/B_Original_Form... | 0.35         |
| Time/Buffer             | 0.0259       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.44848925   |
| Train/Action_magnitu... | 1.0727785    |
| Train/Action_magnitude  | 0.847855     |
| Train/Action_max        | 0.491887     |
| Train/Action_std        | 0.36687377   |
| Train/Entropy           | 0.31538573   |
| Train/Entropy_Loss      | -0.000315    |
| Train/Entropy_loss      | -0.000315    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.6511659   |
| Train/Loss              | -0.07377218  |
| Train/PolicyClip        | 0.0003693686 |
| Train/Policy_loss       | -0.081985556 |
| Train/Ratio             | 1.0009105    |
| Train/Return            | 2.1361842    |
| Train/V                 | 2.0556397    |
| Train/Value             | 2.0556397    |
| Train/control_penalty   | 0.85287595   |
| Train/policy_loss       | -0.081985556 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06785      |
------------------------------------------

 ---------------- Iteration 60 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 59            |
| Time/Actor_Time         | 0.366         |
| Time/B_Format_Time      | 0.355         |
| Time/B_Original_Form... | 0.359         |
| Time/Buffer             | 0.0301        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.43238398    |
| Train/Action_magnitu... | 1.0444202     |
| Train/Action_magnitude  | 0.82634765    |
| Train/Action_max        | 0.48711962    |
| Train/Action_std        | 0.35170844    |
| Train/Entropy           | 0.27285004    |
| Train/Entropy_Loss      | -0.000273     |
| Train/Entropy_loss      | -0.000273     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.5958128    |
| Train/Loss              | -0.08530037   |
| Train/PolicyClip        | -0.0005180585 |
| Train/Policy_loss       | -0.09318561   |
| Train/Ratio             | 0.99922776    |
| Train/Return            | 1.8592826     |
| Train/V                 | 1.7651924     |
| Train/Value             | 1.7651924     |
| Train/control_penalty   | 0.8158091     |
| Train/policy_loss       | -0.09318561   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0643        |
-------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 61 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 60            |
| Time/Actor_Time         | 0.364         |
| Time/B_Format_Time      | 0.347         |
| Time/B_Original_Form... | 0.356         |
| Time/Buffer             | 0.0332        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.42706466    |
| Train/Action_magnitu... | 1.0135214     |
| Train/Action_magnitude  | 0.8022122     |
| Train/Action_max        | 0.45856476    |
| Train/Action_std        | 0.33998793    |
| Train/Entropy           | 0.24535635    |
| Train/Entropy_Loss      | -0.000245     |
| Train/Entropy_loss      | -0.000245     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.5103177    |
| Train/Loss              | -0.038510304  |
| Train/PolicyClip        | -0.0009172247 |
| Train/Policy_loss       | -0.046228252  |
| Train/Ratio             | 0.9996169     |
| Train/Return            | 1.6173271     |
| Train/V                 | 1.5700341     |
| Train/Value             | 1.5700341     |
| Train/control_penalty   | 0.7963304     |
| Train/policy_loss       | -0.046228252  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0551        |
-------------------------------------------

 ---------------- Iteration 62 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 61            |
| Time/Actor_Time         | 0.361         |
| Time/B_Format_Time      | 0.356         |
| Time/B_Original_Form... | 0.346         |
| Time/Buffer             | 0.0264        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.41556895    |
| Train/Action_magnitu... | 0.9811797     |
| Train/Action_magnitude  | 0.77766615    |
| Train/Action_max        | 0.42515758    |
| Train/Action_std        | 0.3234208     |
| Train/Entropy           | 0.19806746    |
| Train/Entropy_Loss      | -0.000198     |
| Train/Entropy_loss      | -0.000198     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.41456747   |
| Train/Loss              | -0.05736375   |
| Train/PolicyClip        | -4.923052e-05 |
| Train/Policy_loss       | -0.064822756  |
| Train/Ratio             | 1.0013345     |
| Train/Return            | 1.693636      |
| Train/V                 | 1.6304728     |
| Train/Value             | 1.6304728     |
| Train/control_penalty   | 0.7657073     |
| Train/policy_loss       | -0.064822756  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05355       |
-------------------------------------------

 ---------------- Iteration 63 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 62            |
| Time/Actor_Time         | 0.342         |
| Time/B_Format_Time      | 0.351         |
| Time/B_Original_Form... | 0.344         |
| Time/Buffer             | 0.0256        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.424174      |
| Train/Action_magnitu... | 0.97439015    |
| Train/Action_magnitude  | 0.771451      |
| Train/Action_max        | 0.46151894    |
| Train/Action_std        | 0.31128532    |
| Train/Entropy           | 0.15230165    |
| Train/Entropy_Loss      | -0.000152     |
| Train/Entropy_loss      | -0.000152     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.37021944   |
| Train/Loss              | -0.095922515  |
| Train/PolicyClip        | 0.00039167394 |
| Train/Policy_loss       | -0.10353572   |
| Train/Ratio             | 1.0003623     |
| Train/Return            | 1.8941895     |
| Train/V                 | 1.7891384     |
| Train/Value             | 1.7891384     |
| Train/control_penalty   | 0.7765513     |
| Train/policy_loss       | -0.10353572   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0592        |
-------------------------------------------

 ---------------- Iteration 64 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 63            |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.346         |
| Time/B_Original_Form... | 0.349         |
| Time/Buffer             | 0.0299        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.427208      |
| Train/Action_magnitu... | 1.0064304     |
| Train/Action_magnitude  | 0.7996089     |
| Train/Action_max        | 0.5286422     |
| Train/Action_std        | 0.3220525     |
| Train/Entropy           | 0.17718183    |
| Train/Entropy_Loss      | -0.000177     |
| Train/Entropy_loss      | -0.000177     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.39631993   |
| Train/Loss              | -0.16436136   |
| Train/PolicyClip        | 0.00024859657 |
| Train/Policy_loss       | -0.17211884   |
| Train/Ratio             | 1.0033913     |
| Train/Return            | 1.977082      |
| Train/V                 | 1.8068948     |
| Train/Value             | 1.8068948     |
| Train/control_penalty   | 0.79346615    |
| Train/policy_loss       | -0.17211884   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06545       |
-------------------------------------------

 ---------------- Iteration 65 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 64           |
| Time/Actor_Time         | 0.353        |
| Time/B_Format_Time      | 0.345        |
| Time/B_Original_Form... | 0.344        |
| Time/Buffer             | 0.0284       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.42162895   |
| Train/Action_magnitu... | 0.99529904   |
| Train/Action_magnitude  | 0.7904016    |
| Train/Action_max        | 0.49625802   |
| Train/Action_std        | 0.3201318    |
| Train/Entropy           | 0.18046115   |
| Train/Entropy_Loss      | -0.00018     |
| Train/Entropy_loss      | -0.00018     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.44628364  |
| Train/Loss              | -0.15328926  |
| Train/PolicyClip        | 0.0004668518 |
| Train/Policy_loss       | -0.16089189  |
| Train/Ratio             | 1.002328     |
| Train/Return            | 1.9202279    |
| Train/V                 | 1.7528684    |
| Train/Value             | 1.7528684    |
| Train/control_penalty   | 0.77830964   |
| Train/policy_loss       | -0.16089189  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06865      |
------------------------------------------

 ---------------- Iteration 66 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-----------------------------------------
| Itr                     | 65          |
| Time/Actor_Time         | 0.356       |
| Time/B_Format_Time      | 0.331       |
| Time/B_Original_Form... | 0.328       |
| Time/Buffer             | 0.0258      |
| Time/Critic_Time        | 9.54e-07    |
| Train/Action_abs_mean   | 0.42253315  |
| Train/Action_magnitu... | 0.9871093   |
| Train/Action_magnitude  | 0.7786861   |
| Train/Action_max        | 0.45269883  |
| Train/Action_std        | 0.3133243   |
| Train/Entropy           | 0.16275959  |
| Train/Entropy_Loss      | -0.000163   |
| Train/Entropy_loss      | -0.000163   |
| Train/Grad_norm_actor   | 0.0         |
| Train/LogProb           | -0.38842747 |
| Train/Loss              | -0.11016576 |
| Train/PolicyClip        | 0.003896558 |
| Train/Policy_loss       | -0.11770179 |
| Train/Ratio             | 1.004155    |
| Train/Return            | 2.0110817   |
| Train/V                 | 1.8847773   |
| Train/Value             | 1.8847773   |
| Train/control_penalty   | 0.7698787   |
| Train/policy_loss       | -0.11770179 |
| Train/recon_loss        | 0.0         |
| train/batch_reward      | 0.0633      |
-----------------------------------------

 ---------------- Iteration 67 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 66           |
| Time/Actor_Time         | 0.349        |
| Time/B_Format_Time      | 0.342        |
| Time/B_Original_Form... | 0.344        |
| Time/Buffer             | 0.0226       |
| Time/Critic_Time        | 1.19e-06     |
| Train/Action_abs_mean   | 0.43441167   |
| Train/Action_magnitu... | 0.99984044   |
| Train/Action_magnitude  | 0.7872942    |
| Train/Action_max        | 0.4675108    |
| Train/Action_std        | 0.30487528   |
| Train/Entropy           | 0.13456713   |
| Train/Entropy_Loss      | -0.000135    |
| Train/Entropy_loss      | -0.000135    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.32362223  |
| Train/Loss              | -0.017785225 |
| Train/PolicyClip        | 0.001166244  |
| Train/Policy_loss       | -0.025506722 |
| Train/Ratio             | 0.99733204   |
| Train/Return            | 2.1080806    |
| Train/V                 | 2.0767245    |
| Train/Value             | 2.0767245    |
| Train/control_penalty   | 0.78560644   |
| Train/policy_loss       | -0.025506722 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0543       |
------------------------------------------

 ---------------- Iteration 68 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 67            |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.348         |
| Time/B_Original_Form... | 0.349         |
| Time/Buffer             | 0.0228        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.43905517    |
| Train/Action_magnitu... | 0.9979702     |
| Train/Action_magnitude  | 0.7826438     |
| Train/Action_max        | 0.4733567     |
| Train/Action_std        | 0.29950386    |
| Train/Entropy           | 0.12348018    |
| Train/Entropy_Loss      | -0.000123     |
| Train/Entropy_loss      | -0.000123     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.23841098   |
| Train/Loss              | -0.0106845535 |
| Train/PolicyClip        | 0.00022308006 |
| Train/Policy_loss       | -0.018346881  |
| Train/Ratio             | 1.0002182     |
| Train/Return            | 1.966266      |
| Train/V                 | 1.9491563     |
| Train/Value             | 1.9491563     |
| Train/control_penalty   | 0.7785808     |
| Train/policy_loss       | -0.018346881  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.04645       |
-------------------------------------------

 ---------------- Iteration 69 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 68           |
| Time/Actor_Time         | 0.359        |
| Time/B_Format_Time      | 0.342        |
| Time/B_Original_Form... | 0.344        |
| Time/Buffer             | 0.0232       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.44251117   |
| Train/Action_magnitu... | 0.99516565   |
| Train/Action_magnitude  | 0.7796043    |
| Train/Action_max        | 0.47358096   |
| Train/Action_std        | 0.29386818   |
| Train/Entropy           | 0.09932326   |
| Train/Entropy_Loss      | -9.93e-05    |
| Train/Entropy_loss      | -9.93e-05    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.27369696  |
| Train/Loss              | -0.022942793 |
| Train/PolicyClip        | 0.0001937151 |
| Train/Policy_loss       | -0.030666456 |
| Train/Ratio             | 1.0005474    |
| Train/Return            | 1.9000984    |
| Train/V                 | 1.8689137    |
| Train/Value             | 1.8689137    |
| Train/control_penalty   | 0.7822988    |
| Train/policy_loss       | -0.030666456 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.047        |
------------------------------------------

 ---------------- Iteration 70 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 69            |
| Time/Actor_Time         | 0.344         |
| Time/B_Format_Time      | 0.337         |
| Time/B_Original_Form... | 0.35          |
| Time/Buffer             | 0.0412        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.42782587    |
| Train/Action_magnitu... | 0.9753958     |
| Train/Action_magnitude  | 0.7630901     |
| Train/Action_max        | 0.4312263     |
| Train/Action_std        | 0.2930024     |
| Train/Entropy           | 0.10014318    |
| Train/Entropy_Loss      | -0.0001       |
| Train/Entropy_loss      | -0.0001       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.21062092   |
| Train/Loss              | 0.011765119   |
| Train/PolicyClip        | -9.491866e-05 |
| Train/Policy_loss       | 0.004248005   |
| Train/Ratio             | 1.0004553     |
| Train/Return            | 2.0479088     |
| Train/V                 | 2.0472665     |
| Train/Value             | 2.0472665     |
| Train/control_penalty   | 0.7617257     |
| Train/policy_loss       | 0.004248005   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05485       |
-------------------------------------------

 ---------------- Iteration 71 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 70           |
| Time/Actor_Time         | 0.358        |
| Time/B_Format_Time      | 0.334        |
| Time/B_Original_Form... | 0.339        |
| Time/Buffer             | 0.0314       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.41677788   |
| Train/Action_magnitu... | 0.95601887   |
| Train/Action_magnitude  | 0.7480997    |
| Train/Action_max        | 0.4349255    |
| Train/Action_std        | 0.29998717   |
| Train/Entropy           | 0.11763146   |
| Train/Entropy_Loss      | -0.000118    |
| Train/Entropy_loss      | -0.000118    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.2580013   |
| Train/Loss              | -0.038371716 |
| Train/PolicyClip        | 0.0021317285 |
| Train/Policy_loss       | -0.045757666 |
| Train/Ratio             | 1.0006189    |
| Train/Return            | 2.2092867    |
| Train/V                 | 2.1598425    |
| Train/Value             | 2.1598425    |
| Train/control_penalty   | 0.75035816   |
| Train/policy_loss       | -0.045757666 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06245      |
------------------------------------------

 ---------------- Iteration 72 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 71           |
| Time/Actor_Time         | 0.339        |
| Time/B_Format_Time      | 0.325        |
| Time/B_Original_Form... | 0.325        |
| Time/Buffer             | 0.0346       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.4238566    |
| Train/Action_magnitu... | 0.9702032    |
| Train/Action_magnitude  | 0.7583023    |
| Train/Action_max        | 0.4390977    |
| Train/Action_std        | 0.3026498    |
| Train/Entropy           | 0.1320555    |
| Train/Entropy_Loss      | -0.000132    |
| Train/Entropy_loss      | -0.000132    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.27504042  |
| Train/Loss              | -0.03611189  |
| Train/PolicyClip        | 0.0010543849 |
| Train/Policy_loss       | -0.04361793  |
| Train/Ratio             | 1.0012864    |
| Train/Return            | 2.224543     |
| Train/V                 | 2.1802657    |
| Train/Value             | 2.1802657    |
| Train/control_penalty   | 0.7638093    |
| Train/policy_loss       | -0.04361793  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0657       |
------------------------------------------

 ---------------- Iteration 73 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 72            |
| Time/Actor_Time         | 0.378         |
| Time/B_Format_Time      | 0.34          |
| Time/B_Original_Form... | 0.338         |
| Time/Buffer             | 0.0271        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.43617505    |
| Train/Action_magnitu... | 1.0097287     |
| Train/Action_magnitude  | 0.7895716     |
| Train/Action_max        | 0.49952227    |
| Train/Action_std        | 0.31003767    |
| Train/Entropy           | 0.14665897    |
| Train/Entropy_Loss      | -0.000147     |
| Train/Entropy_loss      | -0.000147     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.31014818   |
| Train/Loss              | -0.030023672  |
| Train/PolicyClip        | 0.00026863904 |
| Train/Policy_loss       | -0.037783287  |
| Train/Ratio             | 1.0004514     |
| Train/Return            | 2.2541966     |
| Train/V                 | 2.217128      |
| Train/Value             | 2.217128      |
| Train/control_penalty   | 0.7906274     |
| Train/policy_loss       | -0.037783287  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06575       |
-------------------------------------------

 ---------------- Iteration 74 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 73            |
| Time/Actor_Time         | 0.358         |
| Time/B_Format_Time      | 0.346         |
| Time/B_Original_Form... | 0.346         |
| Time/Buffer             | 0.0294        |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.43911535    |
| Train/Action_magnitu... | 1.0140653     |
| Train/Action_magnitude  | 0.79540604    |
| Train/Action_max        | 0.5113869     |
| Train/Action_std        | 0.30756104    |
| Train/Entropy           | 0.13419305    |
| Train/Entropy_Loss      | -0.000134     |
| Train/Entropy_loss      | -0.000134     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.2933399    |
| Train/Loss              | -0.04351864   |
| Train/PolicyClip        | 0.00011504612 |
| Train/Policy_loss       | -0.051253084  |
| Train/Ratio             | 1.0008566     |
| Train/Return            | 2.1246526     |
| Train/V                 | 2.0739653     |
| Train/Value             | 2.0739653     |
| Train/control_penalty   | 0.78686374    |
| Train/policy_loss       | -0.051253084  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0616        |
-------------------------------------------

 ---------------- Iteration 75 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 74            |
| Time/Actor_Time         | 0.361         |
| Time/B_Format_Time      | 0.344         |
| Time/B_Original_Form... | 0.339         |
| Time/Buffer             | 0.0239        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4418788     |
| Train/Action_magnitu... | 1.0081203     |
| Train/Action_magnitude  | 0.7916813     |
| Train/Action_max        | 0.48716494    |
| Train/Action_std        | 0.3057769     |
| Train/Entropy           | 0.12468018    |
| Train/Entropy_Loss      | -0.000125     |
| Train/Entropy_loss      | -0.000125     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.32002604   |
| Train/Loss              | -0.09541874   |
| Train/PolicyClip        | -0.0001981653 |
| Train/Policy_loss       | -0.10317188   |
| Train/Ratio             | 1.002317      |
| Train/Return            | 1.9120729     |
| Train/V                 | 1.8113359     |
| Train/Value             | 1.8113359     |
| Train/control_penalty   | 0.78778195    |
| Train/policy_loss       | -0.10317188   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0609        |
-------------------------------------------

 ---------------- Iteration 76 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 75             |
| Time/Actor_Time         | 0.357          |
| Time/B_Format_Time      | 0.342          |
| Time/B_Original_Form... | 0.342          |
| Time/Buffer             | 0.643          |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.4258542      |
| Train/Action_magnitu... | 0.9933219      |
| Train/Action_magnitude  | 0.7799995      |
| Train/Action_max        | 0.46122798     |
| Train/Action_std        | 0.30032235     |
| Train/Entropy           | 0.095479384    |
| Train/Entropy_Loss      | -9.55e-05      |
| Train/Entropy_loss      | -9.55e-05      |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | -0.24589339    |
| Train/Loss              | -0.10094452    |
| Train/PolicyClip        | -0.00017764836 |
| Train/Policy_loss       | -0.10860657    |
| Train/Ratio             | 1.0032805      |
| Train/Return            | 1.7311792      |
| Train/V                 | 1.6246386      |
| Train/Value             | 1.6246386      |
| Train/control_penalty   | 0.77575284     |
| Train/policy_loss       | -0.10860657    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0597         |
--------------------------------------------

 ---------------- Iteration 77 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-----------------------------------------
| Itr                     | 76          |
| Time/Actor_Time         | 0.351       |
| Time/B_Format_Time      | 0.352       |
| Time/B_Original_Form... | 0.35        |
| Time/Buffer             | 0.0283      |
| Time/Critic_Time        | 0           |
| Train/Action_abs_mean   | 0.41274223  |
| Train/Action_magnitu... | 0.9641846   |
| Train/Action_magnitude  | 0.75455403  |
| Train/Action_max        | 0.46215224  |
| Train/Action_std        | 0.28242397  |
| Train/Entropy           | 0.02424194  |
| Train/Entropy_Loss      | -2.42e-05   |
| Train/Entropy_loss      | -2.42e-05   |
| Train/Grad_norm_actor   | 0.0         |
| Train/LogProb           | -0.17312893 |
| Train/Loss              | -0.14501697 |
| Train/PolicyClip        | 0.00279256  |
| Train/Policy_loss       | -0.15242642 |
| Train/Ratio             | 1.0054069   |
| Train/Return            | 1.7659945   |
| Train/V                 | 1.6023222   |
| Train/Value             | 1.6023222   |
| Train/control_penalty   | 0.74336946  |
| Train/policy_loss       | -0.15242642 |
| Train/recon_loss        | 0.0         |
| train/batch_reward      | 0.0594      |
-----------------------------------------

 ---------------- Iteration 78 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 77           |
| Time/Actor_Time         | 0.346        |
| Time/B_Format_Time      | 0.351        |
| Time/B_Original_Form... | 0.355        |
| Time/Buffer             | 0.0231       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.42296353   |
| Train/Action_magnitu... | 0.96618223   |
| Train/Action_magnitude  | 0.7539956    |
| Train/Action_max        | 0.48937038   |
| Train/Action_std        | 0.27910385   |
| Train/Entropy           | 0.006813095  |
| Train/Entropy_Loss      | -6.81e-06    |
| Train/Entropy_loss      | -6.81e-06    |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | -0.05421115  |
| Train/Loss              | -0.17205074  |
| Train/PolicyClip        | 0.0014786337 |
| Train/Policy_loss       | -0.17958531  |
| Train/Ratio             | 1.0042354    |
| Train/Return            | 2.0784636    |
| Train/V                 | 1.8956295    |
| Train/Value             | 1.8956295    |
| Train/control_penalty   | 0.75413704   |
| Train/policy_loss       | -0.17958531  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0633       |
------------------------------------------

 ---------------- Iteration 79 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 78            |
| Time/Actor_Time         | 0.363         |
| Time/B_Format_Time      | 0.343         |
| Time/B_Original_Form... | 0.344         |
| Time/Buffer             | 0.0213        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.39792123    |
| Train/Action_magnitu... | 0.9443833     |
| Train/Action_magnitude  | 0.7355175     |
| Train/Action_max        | 0.45768017    |
| Train/Action_std        | 0.28233263    |
| Train/Entropy           | 0.022186866   |
| Train/Entropy_Loss      | -2.22e-05     |
| Train/Entropy_loss      | -2.22e-05     |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.13924947   |
| Train/Loss              | -0.21165785   |
| Train/PolicyClip        | 0.00060524076 |
| Train/Policy_loss       | -0.21881579   |
| Train/Ratio             | 1.0032376     |
| Train/Return            | 2.288961      |
| Train/V                 | 2.054263      |
| Train/Value             | 2.054263      |
| Train/control_penalty   | 0.7180128     |
| Train/policy_loss       | -0.21881579   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0722        |
-------------------------------------------

 ---------------- Iteration 80 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 79            |
| Time/Actor_Time         | 0.356         |
| Time/B_Format_Time      | 0.356         |
| Time/B_Original_Form... | 0.357         |
| Time/Buffer             | 0.0267        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.39217418    |
| Train/Action_magnitu... | 0.88229257    |
| Train/Action_magnitude  | 0.68756765    |
| Train/Action_max        | 0.35396242    |
| Train/Action_std        | 0.2633609     |
| Train/Entropy           | -0.009948247  |
| Train/Entropy_Loss      | 9.95e-06      |
| Train/Entropy_loss      | 9.95e-06      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.12659661   |
| Train/Loss              | -0.14570911   |
| Train/PolicyClip        | 0.00029578453 |
| Train/Policy_loss       | -0.15264887   |
| Train/Ratio             | 0.9981634     |
| Train/Return            | 2.1850688     |
| Train/V                 | 2.006657      |
| Train/Value             | 2.006657      |
| Train/control_penalty   | 0.6929801     |
| Train/policy_loss       | -0.15264887   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06775       |
-------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 81 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 80            |
| Time/Actor_Time         | 0.362         |
| Time/B_Format_Time      | 0.34          |
| Time/B_Original_Form... | 0.339         |
| Time/Buffer             | 0.0241        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.40040585    |
| Train/Action_magnitu... | 0.8887268     |
| Train/Action_magnitude  | 0.69228923    |
| Train/Action_max        | 0.34653237    |
| Train/Action_std        | 0.2510621     |
| Train/Entropy           | -0.053392034  |
| Train/Entropy_Loss      | 5.34e-05      |
| Train/Entropy_loss      | 5.34e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.0831725     |
| Train/Loss              | -0.071316294  |
| Train/PolicyClip        | 0.00026098485 |
| Train/Policy_loss       | -0.07836118   |
| Train/Ratio             | 1.0011575     |
| Train/Return            | 2.2192223     |
| Train/V                 | 2.1398509     |
| Train/Value             | 2.1398509     |
| Train/control_penalty   | 0.6991497     |
| Train/policy_loss       | -0.07836118   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06475       |
-------------------------------------------

 ---------------- Iteration 82 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 81           |
| Time/Actor_Time         | 0.352        |
| Time/B_Format_Time      | 0.341        |
| Time/B_Original_Form... | 0.338        |
| Time/Buffer             | 0.0263       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39891556   |
| Train/Action_magnitu... | 0.8849126    |
| Train/Action_magnitude  | 0.6921802    |
| Train/Action_max        | 0.35250443   |
| Train/Action_std        | 0.2388095    |
| Train/Entropy           | -0.10098461  |
| Train/Entropy_Loss      | 0.000101     |
| Train/Entropy_loss      | 0.000101     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.13278218   |
| Train/Loss              | 0.02166873   |
| Train/PolicyClip        | 0.0008761695 |
| Train/Policy_loss       | 0.014599659  |
| Train/Ratio             | 1.0005889    |
| Train/Return            | 2.1802       |
| Train/V                 | 2.1958976    |
| Train/Value             | 2.1958976    |
| Train/control_penalty   | 0.6968088    |
| Train/policy_loss       | 0.014599659  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0621       |
------------------------------------------

 ---------------- Iteration 83 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 82            |
| Time/Actor_Time         | 0.36          |
| Time/B_Format_Time      | 0.344         |
| Time/B_Original_Form... | 0.344         |
| Time/Buffer             | 0.0246        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.39144135    |
| Train/Action_magnitu... | 0.86624753    |
| Train/Action_magnitude  | 0.6797562     |
| Train/Action_max        | 0.35907993    |
| Train/Action_std        | 0.24289551    |
| Train/Entropy           | -0.092721224  |
| Train/Entropy_Loss      | 9.27e-05      |
| Train/Entropy_loss      | 9.27e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.18779473    |
| Train/Loss              | 0.03527847    |
| Train/PolicyClip        | 1.0804572e-05 |
| Train/Policy_loss       | 0.028280195   |
| Train/Ratio             | 0.99723005    |
| Train/Return            | 1.8014767     |
| Train/V                 | 1.8321677     |
| Train/Value             | 1.8321677     |
| Train/control_penalty   | 0.6905552     |
| Train/policy_loss       | 0.028280195   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0532        |
-------------------------------------------

 ---------------- Iteration 84 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 83            |
| Time/Actor_Time         | 0.351         |
| Time/B_Format_Time      | 0.341         |
| Time/B_Original_Form... | 0.342         |
| Time/Buffer             | 0.0277        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.38848057    |
| Train/Action_magnitu... | 0.88195       |
| Train/Action_magnitude  | 0.6915517     |
| Train/Action_max        | 0.37061277    |
| Train/Action_std        | 0.25565517    |
| Train/Entropy           | -0.044015467  |
| Train/Entropy_Loss      | 4.4e-05       |
| Train/Entropy_loss      | 4.4e-05       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.13479668    |
| Train/Loss              | 0.06523194    |
| Train/PolicyClip        | 3.9603092e-05 |
| Train/Policy_loss       | 0.058248065   |
| Train/Ratio             | 0.9975585     |
| Train/Return            | 1.9746027     |
| Train/V                 | 2.0347931     |
| Train/Value             | 2.0347931     |
| Train/control_penalty   | 0.6939864     |
| Train/policy_loss       | 0.058248065   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0556        |
-------------------------------------------

 ---------------- Iteration 85 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 84            |
| Time/Actor_Time         | 0.355         |
| Time/B_Format_Time      | 0.326         |
| Time/B_Original_Form... | 0.327         |
| Time/Buffer             | 0.0235        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.3866073     |
| Train/Action_magnitu... | 0.87989026    |
| Train/Action_magnitude  | 0.6903916     |
| Train/Action_max        | 0.35236537    |
| Train/Action_std        | 0.25085646    |
| Train/Entropy           | -0.054117598  |
| Train/Entropy_Loss      | 5.41e-05      |
| Train/Entropy_loss      | 5.41e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.08478521    |
| Train/Loss              | 0.048344478   |
| Train/PolicyClip        | -0.0005007559 |
| Train/Policy_loss       | 0.041435722   |
| Train/Ratio             | 1.0013884     |
| Train/Return            | 2.212197      |
| Train/V                 | 2.2535813     |
| Train/Value             | 2.2535813     |
| Train/control_penalty   | 0.68546396    |
| Train/policy_loss       | 0.041435722   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0594        |
-------------------------------------------

 ---------------- Iteration 86 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 85             |
| Time/Actor_Time         | 0.357          |
| Time/B_Format_Time      | 0.338          |
| Time/B_Original_Form... | 0.339          |
| Time/Buffer             | 0.0223         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.42788404     |
| Train/Action_magnitu... | 0.92918855     |
| Train/Action_magnitude  | 0.72460115     |
| Train/Action_max        | 0.36715347     |
| Train/Action_std        | 0.24900019     |
| Train/Entropy           | -0.052892882   |
| Train/Entropy_Loss      | 5.29e-05       |
| Train/Entropy_loss      | 5.29e-05       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.06838597     |
| Train/Loss              | -0.027099174   |
| Train/PolicyClip        | -0.00018794305 |
| Train/Policy_loss       | -0.03450492    |
| Train/Ratio             | 0.9968406      |
| Train/Return            | 2.297957       |
| Train/V                 | 2.2606084      |
| Train/Value             | 2.2606084      |
| Train/control_penalty   | 0.73528546     |
| Train/policy_loss       | -0.03450492    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0625         |
--------------------------------------------

 ---------------- Iteration 87 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 86            |
| Time/Actor_Time         | 0.358         |
| Time/B_Format_Time      | 0.345         |
| Time/B_Original_Form... | 0.342         |
| Time/Buffer             | 0.0217        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.4444563     |
| Train/Action_magnitu... | 0.9726797     |
| Train/Action_magnitude  | 0.7558431     |
| Train/Action_max        | 0.3819443     |
| Train/Action_std        | 0.251212      |
| Train/Entropy           | -0.043660615  |
| Train/Entropy_Loss      | 4.37e-05      |
| Train/Entropy_loss      | 4.37e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.03900885    |
| Train/Loss              | -0.09067267   |
| Train/PolicyClip        | -0.0008128459 |
| Train/Policy_loss       | -0.09823586   |
| Train/Ratio             | 0.9990748     |
| Train/Return            | 2.2701185     |
| Train/V                 | 2.174035      |
| Train/Value             | 2.174035      |
| Train/control_penalty   | 0.7519529     |
| Train/policy_loss       | -0.09823586   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0639        |
-------------------------------------------

 ---------------- Iteration 88 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 87            |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.344         |
| Time/B_Original_Form... | 0.345         |
| Time/Buffer             | 0.0245        |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.45048764    |
| Train/Action_magnitu... | 0.9710484     |
| Train/Action_magnitude  | 0.7561512     |
| Train/Action_max        | 0.37443328    |
| Train/Action_std        | 0.25309113    |
| Train/Entropy           | -0.026567666  |
| Train/Entropy_Loss      | 2.66e-05      |
| Train/Entropy_loss      | 2.66e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.041797478   |
| Train/Loss              | -0.023775391  |
| Train/PolicyClip        | -0.0010522429 |
| Train/Policy_loss       | -0.031406917  |
| Train/Ratio             | 0.99863166    |
| Train/Return            | 2.4349728     |
| Train/V                 | 2.4059105     |
| Train/Value             | 2.4059105     |
| Train/control_penalty   | 0.7604956     |
| Train/policy_loss       | -0.031406917  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06495       |
-------------------------------------------

 ---------------- Iteration 89 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 88             |
| Time/Actor_Time         | 0.358          |
| Time/B_Format_Time      | 0.325          |
| Time/B_Original_Form... | 0.326          |
| Time/Buffer             | 0.0231         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.44542676     |
| Train/Action_magnitu... | 0.9741615      |
| Train/Action_magnitude  | 0.76286274     |
| Train/Action_max        | 0.36573622     |
| Train/Action_std        | 0.2568946      |
| Train/Entropy           | -0.014580643   |
| Train/Entropy_Loss      | 1.46e-05       |
| Train/Entropy_loss      | 1.46e-05       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.024170026    |
| Train/Loss              | 0.02479844     |
| Train/PolicyClip        | -0.00079497596 |
| Train/Policy_loss       | 0.017118102    |
| Train/Ratio             | 0.99688214     |
| Train/Return            | 2.4967043      |
| Train/V                 | 2.5154355      |
| Train/Value             | 2.5154355      |
| Train/control_penalty   | 0.76657575     |
| Train/policy_loss       | 0.017118102    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0681         |
--------------------------------------------

 ---------------- Iteration 90 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 89            |
| Time/Actor_Time         | 0.355         |
| Time/B_Format_Time      | 0.335         |
| Time/B_Original_Form... | 0.338         |
| Time/Buffer             | 0.0232        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4396209     |
| Train/Action_magnitu... | 0.9776048     |
| Train/Action_magnitude  | 0.76319283    |
| Train/Action_max        | 0.3794993     |
| Train/Action_std        | 0.26132125    |
| Train/Entropy           | -0.00519123   |
| Train/Entropy_Loss      | 5.19e-06      |
| Train/Entropy_loss      | 5.19e-06      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | -0.014130439  |
| Train/Loss              | 0.009532789   |
| Train/PolicyClip        | 0.00014115483 |
| Train/Policy_loss       | 0.0019363915  |
| Train/Ratio             | 0.99932706    |
| Train/Return            | 2.4017215     |
| Train/V                 | 2.4054856     |
| Train/Value             | 2.4054856     |
| Train/control_penalty   | 0.7591206     |
| Train/policy_loss       | 0.0019363915  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06675       |
-------------------------------------------

 ---------------- Iteration 91 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 90            |
| Time/Actor_Time         | 0.352         |
| Time/B_Format_Time      | 0.344         |
| Time/B_Original_Form... | 0.345         |
| Time/Buffer             | 0.0207        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.42054376    |
| Train/Action_magnitu... | 0.9456135     |
| Train/Action_magnitude  | 0.7348133     |
| Train/Action_max        | 0.37934098    |
| Train/Action_std        | 0.25307152    |
| Train/Entropy           | -0.032267287  |
| Train/Entropy_Loss      | 3.23e-05      |
| Train/Entropy_loss      | 3.23e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.05366496    |
| Train/Loss              | 0.06659355    |
| Train/PolicyClip        | -0.0005992033 |
| Train/Policy_loss       | 0.059298027   |
| Train/Ratio             | 0.995854      |
| Train/Return            | 2.4257002     |
| Train/V                 | 2.4823594     |
| Train/Value             | 2.4823594     |
| Train/control_penalty   | 0.7263256     |
| Train/policy_loss       | 0.059298027   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06295       |
-------------------------------------------

 ---------------- Iteration 92 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 91            |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.35          |
| Time/B_Original_Form... | 0.349         |
| Time/Buffer             | 0.0241        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.41838056    |
| Train/Action_magnitu... | 0.92464495    |
| Train/Action_magnitude  | 0.7199377     |
| Train/Action_max        | 0.35491964    |
| Train/Action_std        | 0.2451127     |
| Train/Entropy           | -0.055386107  |
| Train/Entropy_Loss      | 5.54e-05      |
| Train/Entropy_loss      | 5.54e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.09119689    |
| Train/Loss              | 0.047733735   |
| Train/PolicyClip        | 0.00018852486 |
| Train/Policy_loss       | 0.040421244   |
| Train/Ratio             | 0.9982598     |
| Train/Return            | 2.3057287     |
| Train/V                 | 2.3467774     |
| Train/Value             | 2.3467774     |
| Train/control_penalty   | 0.7257106     |
| Train/policy_loss       | 0.040421244   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0604        |
-------------------------------------------

 ---------------- Iteration 93 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 92            |
| Time/Actor_Time         | 0.345         |
| Time/B_Format_Time      | 0.345         |
| Time/B_Original_Form... | 0.35          |
| Time/Buffer             | 0.0209        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.40783706    |
| Train/Action_magnitu... | 0.8865811     |
| Train/Action_magnitude  | 0.6920375     |
| Train/Action_max        | 0.364122      |
| Train/Action_std        | 0.23941174    |
| Train/Entropy           | -0.08325527   |
| Train/Entropy_Loss      | 8.33e-05      |
| Train/Entropy_loss      | 8.33e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.14362168    |
| Train/Loss              | 0.028812721   |
| Train/PolicyClip        | 3.9882558e-05 |
| Train/Policy_loss       | 0.021688491   |
| Train/Ratio             | 0.99962306    |
| Train/Return            | 2.1496081     |
| Train/V                 | 2.1733525     |
| Train/Value             | 2.1733525     |
| Train/control_penalty   | 0.70409757    |
| Train/policy_loss       | 0.021688491   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0525        |
-------------------------------------------

 ---------------- Iteration 94 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 93            |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.345         |
| Time/B_Original_Form... | 0.35          |
| Time/Buffer             | 0.0202        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.38920784    |
| Train/Action_magnitu... | 0.883598      |
| Train/Action_magnitude  | 0.6889999     |
| Train/Action_max        | 0.3822245     |
| Train/Action_std        | 0.23822393    |
| Train/Entropy           | -0.103019945  |
| Train/Entropy_Loss      | 0.000103      |
| Train/Entropy_loss      | 0.000103      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.20849991    |
| Train/Loss              | 0.05751565    |
| Train/PolicyClip        | -0.0015987712 |
| Train/Policy_loss       | 0.05067742    |
| Train/Ratio             | 0.9962859     |
| Train/Return            | 1.9335793     |
| Train/V                 | 1.985233      |
| Train/Value             | 1.985233      |
| Train/control_penalty   | 0.67352146    |
| Train/policy_loss       | 0.05067742    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.04385       |
-------------------------------------------

 ---------------- Iteration 95 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 94             |
| Time/Actor_Time         | 0.355          |
| Time/B_Format_Time      | 0.35           |
| Time/B_Original_Form... | 0.361          |
| Time/Buffer             | 0.0348         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.39748922     |
| Train/Action_magnitu... | 0.87915653     |
| Train/Action_magnitude  | 0.6847871      |
| Train/Action_max        | 0.3951784      |
| Train/Action_std        | 0.24317981     |
| Train/Entropy           | -0.084485166   |
| Train/Entropy_Loss      | 8.45e-05       |
| Train/Entropy_loss      | 8.45e-05       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.17240764     |
| Train/Loss              | 0.042529173    |
| Train/PolicyClip        | -9.4283365e-05 |
| Train/Policy_loss       | 0.03555711     |
| Train/Ratio             | 0.99812794     |
| Train/Return            | 1.9487082      |
| Train/V                 | 1.9857812      |
| Train/Value             | 1.9857812      |
| Train/control_penalty   | 0.68875784     |
| Train/policy_loss       | 0.03555711     |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.04905        |
--------------------------------------------

 ---------------- Iteration 96 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 95            |
| Time/Actor_Time         | 0.353         |
| Time/B_Format_Time      | 0.343         |
| Time/B_Original_Form... | 0.347         |
| Time/Buffer             | 0.0313        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3966632     |
| Train/Action_magnitu... | 0.8892538     |
| Train/Action_magnitude  | 0.69468457    |
| Train/Action_max        | 0.36220703    |
| Train/Action_std        | 0.24641179    |
| Train/Entropy           | -0.058066938  |
| Train/Entropy_Loss      | 5.81e-05      |
| Train/Entropy_loss      | 5.81e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.0752775     |
| Train/Loss              | -0.026759507  |
| Train/PolicyClip        | 0.00049061794 |
| Train/Policy_loss       | -0.03371096   |
| Train/Ratio             | 1.000628      |
| Train/Return            | 1.8645319     |
| Train/V                 | 1.8311658     |
| Train/Value             | 1.8311658     |
| Train/control_penalty   | 0.68933874    |
| Train/policy_loss       | -0.03371096   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05665       |
-------------------------------------------

 ---------------- Iteration 97 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 96            |
| Time/Actor_Time         | 0.362         |
| Time/B_Format_Time      | 0.329         |
| Time/B_Original_Form... | 0.333         |
| Time/Buffer             | 0.0342        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4084637     |
| Train/Action_magnitu... | 0.90657073    |
| Train/Action_magnitude  | 0.70725125    |
| Train/Action_max        | 0.35604498    |
| Train/Action_std        | 0.2510678     |
| Train/Entropy           | -0.033942964  |
| Train/Entropy_Loss      | 3.39e-05      |
| Train/Entropy_loss      | 3.39e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.00095773506 |
| Train/Loss              | -0.14162631   |
| Train/PolicyClip        | -0.0004619039 |
| Train/Policy_loss       | -0.14871708   |
| Train/Ratio             | 1.0036271     |
| Train/Return            | 1.7698708     |
| Train/V                 | 1.6239096     |
| Train/Value             | 1.6239096     |
| Train/control_penalty   | 0.70568216    |
| Train/policy_loss       | -0.14871708   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0622        |
-------------------------------------------

 ---------------- Iteration 98 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 97            |
| Time/Actor_Time         | 0.349         |
| Time/B_Format_Time      | 0.334         |
| Time/B_Original_Form... | 0.327         |
| Time/Buffer             | 0.033         |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.43205494    |
| Train/Action_magnitu... | 0.94655263    |
| Train/Action_magnitude  | 0.733791      |
| Train/Action_max        | 0.37430924    |
| Train/Action_std        | 0.24855232    |
| Train/Entropy           | -0.053572346  |
| Train/Entropy_Loss      | 5.36e-05      |
| Train/Entropy_loss      | 5.36e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.030742917   |
| Train/Loss              | -0.21136707   |
| Train/PolicyClip        | -0.0011451412 |
| Train/Policy_loss       | -0.21875064   |
| Train/Ratio             | 1.0024406     |
| Train/Return            | 1.8807061     |
| Train/V                 | 1.6620286     |
| Train/Value             | 1.6620286     |
| Train/control_penalty   | 0.7329996     |
| Train/policy_loss       | -0.21875064   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0695        |
-------------------------------------------

 ---------------- Iteration 99 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 98             |
| Time/Actor_Time         | 0.348          |
| Time/B_Format_Time      | 0.338          |
| Time/B_Original_Form... | 0.339          |
| Time/Buffer             | 0.0386         |
| Time/Critic_Time        | 1.19e-06       |
| Train/Action_abs_mean   | 0.4372119      |
| Train/Action_magnitu... | 0.95662034     |
| Train/Action_magnitude  | 0.7377881      |
| Train/Action_max        | 0.35461137     |
| Train/Action_std        | 0.24245982     |
| Train/Entropy           | -0.06769537    |
| Train/Entropy_Loss      | 6.77e-05       |
| Train/Entropy_loss      | 6.77e-05       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.07565674     |
| Train/Loss              | -0.16690458    |
| Train/PolicyClip        | -0.00097091123 |
| Train/Policy_loss       | -0.17426805    |
| Train/Ratio             | 1.0026133      |
| Train/Return            | 2.1662378      |
| Train/V                 | 1.994197       |
| Train/Value             | 1.994197       |
| Train/control_penalty   | 0.7295771      |
| Train/policy_loss       | -0.17426805    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0727         |
--------------------------------------------

 ---------------- Iteration 100 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 99           |
| Time/Actor_Time         | 0.364        |
| Time/B_Format_Time      | 0.335        |
| Time/B_Original_Form... | 0.341        |
| Time/Buffer             | 0.0253       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.4298993    |
| Train/Action_magnitu... | 0.9558367    |
| Train/Action_magnitude  | 0.7404454    |
| Train/Action_max        | 0.36154306   |
| Train/Action_std        | 0.2566685    |
| Train/Entropy           | -0.034147523 |
| Train/Entropy_Loss      | 3.41e-05     |
| Train/Entropy_loss      | 3.41e-05     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.039613616  |
| Train/Loss              | -0.025502019 |
| Train/PolicyClip        | 0.0051389765 |
| Train/Policy_loss       | -0.032964904 |
| Train/Ratio             | 1.0005798    |
| Train/Return            | 2.5030618    |
| Train/V                 | 2.437602     |
| Train/Value             | 2.437602     |
| Train/control_penalty   | 0.74287385   |
| Train/policy_loss       | -0.032964904 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0771       |
------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 101 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 100           |
| Time/Actor_Time         | 0.363         |
| Time/B_Format_Time      | 0.366         |
| Time/B_Original_Form... | 0.37          |
| Time/Buffer             | 0.024         |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.44711718    |
| Train/Action_magnitu... | 0.9537799     |
| Train/Action_magnitude  | 0.74221873    |
| Train/Action_max        | 0.4128684     |
| Train/Action_std        | 0.25071853    |
| Train/Entropy           | -0.057646215  |
| Train/Entropy_Loss      | 5.76e-05      |
| Train/Entropy_loss      | 5.76e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.0852502     |
| Train/Loss              | -0.005902739  |
| Train/PolicyClip        | 0.00038547037 |
| Train/Policy_loss       | -0.013543076  |
| Train/Ratio             | 0.9982812     |
| Train/Return            | 2.4916134     |
| Train/V                 | 2.4749124     |
| Train/Value             | 2.4749124     |
| Train/control_penalty   | 0.75826913    |
| Train/policy_loss       | -0.013543076  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06915       |
-------------------------------------------

 ---------------- Iteration 102 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 101           |
| Time/Actor_Time         | 0.355         |
| Time/B_Format_Time      | 0.335         |
| Time/B_Original_Form... | 0.335         |
| Time/Buffer             | 0.0274        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4384911     |
| Train/Action_magnitu... | 0.950649      |
| Train/Action_magnitude  | 0.7399592     |
| Train/Action_max        | 0.43825737    |
| Train/Action_std        | 0.23572382    |
| Train/Entropy           | -0.11402196   |
| Train/Entropy_Loss      | 0.000114      |
| Train/Entropy_loss      | 0.000114      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.1912097     |
| Train/Loss              | 0.015331315   |
| Train/PolicyClip        | 0.00026170013 |
| Train/Policy_loss       | 0.007840235   |
| Train/Ratio             | 0.99980235    |
| Train/Return            | 2.1368425     |
| Train/V                 | 2.1460698     |
| Train/Value             | 2.1460698     |
| Train/control_penalty   | 0.7377059     |
| Train/policy_loss       | 0.007840235   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0619        |
-------------------------------------------

 ---------------- Iteration 103 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 102           |
| Time/Actor_Time         | 0.353         |
| Time/B_Format_Time      | 0.335         |
| Time/B_Original_Form... | 0.338         |
| Time/Buffer             | 0.0347        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.43000215    |
| Train/Action_magnitu... | 0.9401302     |
| Train/Action_magnitude  | 0.7344688     |
| Train/Action_max        | 0.41251498    |
| Train/Action_std        | 0.2316226     |
| Train/Entropy           | -0.12683642   |
| Train/Entropy_Loss      | 0.000127      |
| Train/Entropy_loss      | 0.000127      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.25294468    |
| Train/Loss              | 0.05005018    |
| Train/PolicyClip        | 0.00012086399 |
| Train/Policy_loss       | 0.04261629    |
| Train/Ratio             | 0.99836457    |
| Train/Return            | 1.7587142     |
| Train/V                 | 1.8028965     |
| Train/Value             | 1.8028965     |
| Train/control_penalty   | 0.73070574    |
| Train/policy_loss       | 0.04261629    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05545       |
-------------------------------------------

 ---------------- Iteration 104 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 103           |
| Time/Actor_Time         | 0.35          |
| Time/B_Format_Time      | 0.323         |
| Time/B_Original_Form... | 0.321         |
| Time/Buffer             | 0.037         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.43068793    |
| Train/Action_magnitu... | 0.9393941     |
| Train/Action_magnitude  | 0.7351102     |
| Train/Action_max        | 0.36869898    |
| Train/Action_std        | 0.23774877    |
| Train/Entropy           | -0.09977991   |
| Train/Entropy_Loss      | 9.98e-05      |
| Train/Entropy_loss      | 9.98e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.22751558    |
| Train/Loss              | 0.098066136   |
| Train/PolicyClip        | -0.0002887659 |
| Train/Policy_loss       | 0.09063115    |
| Train/Ratio             | 0.9967982     |
| Train/Return            | 1.8042803     |
| Train/V                 | 1.8966997     |
| Train/Value             | 1.8966997     |
| Train/control_penalty   | 0.7335206     |
| Train/policy_loss       | 0.09063115    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0581        |
-------------------------------------------

 ---------------- Iteration 105 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 104           |
| Time/Actor_Time         | 0.358         |
| Time/B_Format_Time      | 0.324         |
| Time/B_Original_Form... | 0.328         |
| Time/Buffer             | 0.0333        |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.43194145    |
| Train/Action_magnitu... | 0.9425047     |
| Train/Action_magnitude  | 0.73946595    |
| Train/Action_max        | 0.38303033    |
| Train/Action_std        | 0.24543513    |
| Train/Entropy           | -0.08396499   |
| Train/Entropy_Loss      | 8.4e-05       |
| Train/Entropy_loss      | 8.4e-05       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.17282763    |
| Train/Loss              | 0.10408147    |
| Train/PolicyClip        | -0.0007602456 |
| Train/Policy_loss       | 0.09656207    |
| Train/Ratio             | 0.99388987    |
| Train/Return            | 2.0675924     |
| Train/V                 | 2.165778      |
| Train/Value             | 2.165778      |
| Train/control_penalty   | 0.74354225    |
| Train/policy_loss       | 0.09656207    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0667        |
-------------------------------------------

 ---------------- Iteration 106 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 105            |
| Time/Actor_Time         | 0.355          |
| Time/B_Format_Time      | 0.324          |
| Time/B_Original_Form... | 0.34           |
| Time/Buffer             | 0.0321         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.43693736     |
| Train/Action_magnitu... | 0.9648777      |
| Train/Action_magnitude  | 0.7587465      |
| Train/Action_max        | 0.41217643     |
| Train/Action_std        | 0.2586806      |
| Train/Entropy           | -0.036437567   |
| Train/Entropy_Loss      | 3.64e-05       |
| Train/Entropy_loss      | 3.64e-05       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.10099779     |
| Train/Loss              | 0.07706321     |
| Train/PolicyClip        | -0.00036132144 |
| Train/Policy_loss       | 0.06940173     |
| Train/Ratio             | 0.9970009      |
| Train/Return            | 2.0941253      |
| Train/V                 | 2.1646616      |
| Train/Value             | 2.1646616      |
| Train/control_penalty   | 0.76250374     |
| Train/policy_loss       | 0.06940173     |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.06655        |
--------------------------------------------

 ---------------- Iteration 107 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 106           |
| Time/Actor_Time         | 0.356         |
| Time/B_Format_Time      | 0.342         |
| Time/B_Original_Form... | 0.344         |
| Time/Buffer             | 0.0284        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.42086416    |
| Train/Action_magnitu... | 0.94183594    |
| Train/Action_magnitude  | 0.7397221     |
| Train/Action_max        | 0.37789628    |
| Train/Action_std        | 0.25216678    |
| Train/Entropy           | -0.056315236  |
| Train/Entropy_Loss      | 5.63e-05      |
| Train/Entropy_loss      | 5.63e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.05539781    |
| Train/Loss              | 0.016325947   |
| Train/PolicyClip        | 0.00015852993 |
| Train/Policy_loss       | 0.008894545   |
| Train/Ratio             | 0.99653906    |
| Train/Return            | 2.1381862     |
| Train/V                 | 2.142112      |
| Train/Value             | 2.142112      |
| Train/control_penalty   | 0.7375088     |
| Train/policy_loss       | 0.008894545   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06925       |
-------------------------------------------

 ---------------- Iteration 108 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 107           |
| Time/Actor_Time         | 0.358         |
| Time/B_Format_Time      | 0.364         |
| Time/B_Original_Form... | 0.375         |
| Time/Buffer             | 0.025         |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.43638226    |
| Train/Action_magnitu... | 0.95072       |
| Train/Action_magnitude  | 0.74417794    |
| Train/Action_max        | 0.39851058    |
| Train/Action_std        | 0.23482841    |
| Train/Entropy           | -0.114694394  |
| Train/Entropy_Loss      | 0.000115      |
| Train/Entropy_loss      | 0.000115      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.18320365    |
| Train/Loss              | -0.06379716   |
| Train/PolicyClip        | -0.0002931086 |
| Train/Policy_loss       | -0.07136832   |
| Train/Ratio             | 1.0008196     |
| Train/Return            | 2.1505623     |
| Train/V                 | 2.0809367     |
| Train/Value             | 2.0809367     |
| Train/control_penalty   | 0.7456468     |
| Train/policy_loss       | -0.07136832   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0685        |
-------------------------------------------

 ---------------- Iteration 109 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 108           |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.339         |
| Time/B_Original_Form... | 0.34          |
| Time/Buffer             | 0.0259        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4454326     |
| Train/Action_magnitu... | 0.957833      |
| Train/Action_magnitude  | 0.74447197    |
| Train/Action_max        | 0.41675347    |
| Train/Action_std        | 0.23439993    |
| Train/Entropy           | -0.11189188   |
| Train/Entropy_Loss      | 0.000112      |
| Train/Entropy_loss      | 0.000112      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.21771404    |
| Train/Loss              | 0.04160696    |
| Train/PolicyClip        | -9.275213e-05 |
| Train/Policy_loss       | 0.034039028   |
| Train/Ratio             | 0.99941164    |
| Train/Return            | 2.34708       |
| Train/V                 | 2.3831408     |
| Train/Value             | 2.3831408     |
| Train/control_penalty   | 0.7456038     |
| Train/policy_loss       | 0.034039028   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06635       |
-------------------------------------------

 ---------------- Iteration 110 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 109          |
| Time/Actor_Time         | 0.353        |
| Time/B_Format_Time      | 0.339        |
| Time/B_Original_Form... | 0.344        |
| Time/Buffer             | 0.0326       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.43804467   |
| Train/Action_magnitu... | 0.9463966    |
| Train/Action_magnitude  | 0.73233014   |
| Train/Action_max        | 0.38533068   |
| Train/Action_std        | 0.22683193   |
| Train/Entropy           | -0.13177352  |
| Train/Entropy_Loss      | 0.000132     |
| Train/Entropy_loss      | 0.000132     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.21754482   |
| Train/Loss              | -0.04272646  |
| Train/PolicyClip        | 0.0001395562 |
| Train/Policy_loss       | -0.05015353  |
| Train/Ratio             | 1.0012368    |
| Train/Return            | 2.0991259    |
| Train/V                 | 2.050949     |
| Train/Value             | 2.050949     |
| Train/control_penalty   | 0.7295296    |
| Train/policy_loss       | -0.05015353  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06595      |
------------------------------------------

 ---------------- Iteration 111 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 110           |
| Time/Actor_Time         | 0.452         |
| Time/B_Format_Time      | 0.402         |
| Time/B_Original_Form... | 0.4           |
| Time/Buffer             | 0.0357        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.44613183    |
| Train/Action_magnitu... | 0.95678943    |
| Train/Action_magnitude  | 0.74238616    |
| Train/Action_max        | 0.4304855     |
| Train/Action_std        | 0.22248897    |
| Train/Entropy           | -0.15974821   |
| Train/Entropy_Loss      | 0.00016       |
| Train/Entropy_loss      | 0.00016       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.26397523    |
| Train/Loss              | -0.102400355  |
| Train/PolicyClip        | 0.00042681483 |
| Train/Policy_loss       | -0.10998442   |
| Train/Ratio             | 1.0003196     |
| Train/Return            | 2.012589      |
| Train/V                 | 1.9018484     |
| Train/Value             | 1.9018484     |
| Train/control_penalty   | 0.742432      |
| Train/policy_loss       | -0.10998442   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0706        |
-------------------------------------------

 ---------------- Iteration 112 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 111          |
| Time/Actor_Time         | 0.521        |
| Time/B_Format_Time      | 0.497        |
| Time/B_Original_Form... | 0.503        |
| Time/Buffer             | 0.0409       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.45264238   |
| Train/Action_magnitu... | 0.95431286   |
| Train/Action_magnitude  | 0.7450453    |
| Train/Action_max        | 0.41320792   |
| Train/Action_std        | 0.22350669   |
| Train/Entropy           | -0.1553792   |
| Train/Entropy_Loss      | 0.000155     |
| Train/Entropy_loss      | 0.000155     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.25739306   |
| Train/Loss              | -0.08706891  |
| Train/PolicyClip        | 0.0014508923 |
| Train/Policy_loss       | -0.09476202  |
| Train/Ratio             | 0.9993377    |
| Train/Return            | 2.2308972    |
| Train/V                 | 2.1203258    |
| Train/Value             | 2.1203258    |
| Train/control_penalty   | 0.7537728    |
| Train/policy_loss       | -0.09476202  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0748       |
------------------------------------------

 ---------------- Iteration 113 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 112          |
| Time/Actor_Time         | 0.446        |
| Time/B_Format_Time      | 0.399        |
| Time/B_Original_Form... | 0.401        |
| Time/Buffer             | 0.0465       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.4410535    |
| Train/Action_magnitu... | 0.9601088    |
| Train/Action_magnitude  | 0.74854064   |
| Train/Action_max        | 0.39430904   |
| Train/Action_std        | 0.23168907   |
| Train/Entropy           | -0.12714371  |
| Train/Entropy_Loss      | 0.000127     |
| Train/Entropy_loss      | 0.000127     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.17316978   |
| Train/Loss              | -0.03765322  |
| Train/PolicyClip        | 0.0020094903 |
| Train/Policy_loss       | -0.045219954 |
| Train/Ratio             | 1.0016928    |
| Train/Return            | 2.334432     |
| Train/V                 | 2.2781012    |
| Train/Value             | 2.2781012    |
| Train/control_penalty   | 0.74395925   |
| Train/policy_loss       | -0.045219954 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07875      |
------------------------------------------

 ---------------- Iteration 114 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 113           |
| Time/Actor_Time         | 0.468         |
| Time/B_Format_Time      | 0.482         |
| Time/B_Original_Form... | 0.468         |
| Time/Buffer             | 0.0478        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.41801235    |
| Train/Action_magnitu... | 0.9185895     |
| Train/Action_magnitude  | 0.7189951     |
| Train/Action_max        | 0.3725065     |
| Train/Action_std        | 0.22919062    |
| Train/Entropy           | -0.13065538   |
| Train/Entropy_Loss      | 0.000131      |
| Train/Entropy_loss      | 0.000131      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.24322662    |
| Train/Loss              | 0.013974654   |
| Train/PolicyClip        | 0.00019392764 |
| Train/Policy_loss       | 0.0066645676  |
| Train/Ratio             | 0.9997041     |
| Train/Return            | 2.4481497     |
| Train/V                 | 2.4560714     |
| Train/Value             | 2.4560714     |
| Train/control_penalty   | 0.7179431     |
| Train/policy_loss       | 0.0066645676  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0806        |
-------------------------------------------

 ---------------- Iteration 115 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 114            |
| Time/Actor_Time         | 0.499          |
| Time/B_Format_Time      | 0.483          |
| Time/B_Original_Form... | 0.488          |
| Time/Buffer             | 0.0417         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.44067436     |
| Train/Action_magnitu... | 0.9563513      |
| Train/Action_magnitude  | 0.7469319      |
| Train/Action_max        | 0.43134508     |
| Train/Action_std        | 0.23114526     |
| Train/Entropy           | -0.1310602     |
| Train/Entropy_Loss      | 0.000131       |
| Train/Entropy_loss      | 0.000131       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.23510757     |
| Train/Loss              | -0.00021088682 |
| Train/PolicyClip        | 0.00022073793  |
| Train/Policy_loss       | -0.007830122   |
| Train/Ratio             | 0.9997002      |
| Train/Return            | 2.3761084      |
| Train/V                 | 2.368745       |
| Train/Value             | 2.368745       |
| Train/control_penalty   | 0.74881744     |
| Train/policy_loss       | -0.007830122   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0758         |
--------------------------------------------

 ---------------- Iteration 116 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 115           |
| Time/Actor_Time         | 0.48          |
| Time/B_Format_Time      | 0.47          |
| Time/B_Original_Form... | 0.469         |
| Time/Buffer             | 0.0457        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.44396377    |
| Train/Action_magnitu... | 0.9518791     |
| Train/Action_magnitude  | 0.74635017    |
| Train/Action_max        | 0.44016513    |
| Train/Action_std        | 0.22050148    |
| Train/Entropy           | -0.17341289   |
| Train/Entropy_Loss      | 0.000173      |
| Train/Entropy_loss      | 0.000173      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.29418182    |
| Train/Loss              | 0.021234255   |
| Train/PolicyClip        | 6.8513764e-05 |
| Train/Policy_loss       | 0.0135998875  |
| Train/Ratio             | 0.99935496    |
| Train/Return            | 2.395765      |
| Train/V                 | 2.40966       |
| Train/Value             | 2.40966       |
| Train/control_penalty   | 0.7460954     |
| Train/policy_loss       | 0.0135998875  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07485       |
-------------------------------------------

 ---------------- Iteration 117 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 116           |
| Time/Actor_Time         | 0.441         |
| Time/B_Format_Time      | 0.406         |
| Time/B_Original_Form... | 0.412         |
| Time/Buffer             | 0.0528        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.40505537    |
| Train/Action_magnitu... | 0.88477635    |
| Train/Action_magnitude  | 0.69591874    |
| Train/Action_max        | 0.38250566    |
| Train/Action_std        | 0.21548572    |
| Train/Entropy           | -0.18101159   |
| Train/Entropy_Loss      | 0.000181      |
| Train/Entropy_loss      | 0.000181      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.34012362    |
| Train/Loss              | 0.026667146   |
| Train/PolicyClip        | 5.3521406e-05 |
| Train/Policy_loss       | 0.019516837   |
| Train/Ratio             | 0.99969655    |
| Train/Return            | 2.295201      |
| Train/V                 | 2.3166878     |
| Train/Value             | 2.3166878     |
| Train/control_penalty   | 0.6969298     |
| Train/policy_loss       | 0.019516837   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0779        |
-------------------------------------------

 ---------------- Iteration 118 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 117          |
| Time/Actor_Time         | 0.45         |
| Time/B_Format_Time      | 0.418        |
| Time/B_Original_Form... | 0.417        |
| Time/Buffer             | 0.0512       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.4016005    |
| Train/Action_magnitu... | 0.8644409    |
| Train/Action_magnitude  | 0.67826974   |
| Train/Action_max        | 0.33338606   |
| Train/Action_std        | 0.21499734   |
| Train/Entropy           | -0.17519484  |
| Train/Entropy_Loss      | 0.000175     |
| Train/Entropy_loss      | 0.000175     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.2900825    |
| Train/Loss              | -0.008680756 |
| Train/PolicyClip        | 0.0006612744 |
| Train/Policy_loss       | -0.015734894 |
| Train/Ratio             | 0.99820477   |
| Train/Return            | 2.0216002    |
| Train/V                 | 2.0063434    |
| Train/Value             | 2.0063434    |
| Train/control_penalty   | 0.68789434   |
| Train/policy_loss       | -0.015734894 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0724       |
------------------------------------------

 ---------------- Iteration 119 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 118            |
| Time/Actor_Time         | 0.482          |
| Time/B_Format_Time      | 0.465          |
| Time/B_Original_Form... | 0.484          |
| Time/Buffer             | 0.0562         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.38066432     |
| Train/Action_magnitu... | 0.84418476     |
| Train/Action_magnitude  | 0.66217405     |
| Train/Action_max        | 0.31365716     |
| Train/Action_std        | 0.21247451     |
| Train/Entropy           | -0.1787397     |
| Train/Entropy_Loss      | 0.000179       |
| Train/Entropy_loss      | 0.000179       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.35521308     |
| Train/Loss              | 0.009232269    |
| Train/PolicyClip        | -0.00059877336 |
| Train/Policy_loss       | 0.0025156166   |
| Train/Ratio             | 1.0010464      |
| Train/Return            | 2.137138       |
| Train/V                 | 2.1406157      |
| Train/Value             | 2.1406157      |
| Train/control_penalty   | 0.65379125     |
| Train/policy_loss       | 0.0025156166   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.06455        |
--------------------------------------------

 ---------------- Iteration 120 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-----------------------------------------
| Itr                     | 119         |
| Time/Actor_Time         | 0.527       |
| Time/B_Format_Time      | 0.543       |
| Time/B_Original_Form... | 0.558       |
| Time/Buffer             | 0.046       |
| Time/Critic_Time        | 1.19e-06    |
| Train/Action_abs_mean   | 0.36571434  |
| Train/Action_magnitu... | 0.8132024   |
| Train/Action_magnitude  | 0.63645196  |
| Train/Action_max        | 0.28521982  |
| Train/Action_std        | 0.2098334   |
| Train/Entropy           | -0.1822049  |
| Train/Entropy_Loss      | 0.000182    |
| Train/Entropy_loss      | 0.000182    |
| Train/Grad_norm_actor   | 0.0         |
| Train/LogProb           | 0.25563198  |
| Train/Loss              | 0.015837364 |
| Train/PolicyClip        | 0.00380898  |
| Train/Policy_loss       | 0.009340191 |
| Train/Ratio             | 1.0007185   |
| Train/Return            | 2.4190106   |
| Train/V                 | 2.4003975   |
| Train/Value             | 2.4003975   |
| Train/control_penalty   | 0.63149685  |
| Train/policy_loss       | 0.009340191 |
| Train/recon_loss        | 0.0         |
| train/batch_reward      | 0.0648      |
-----------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 121 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 120            |
| Time/Actor_Time         | 0.592          |
| Time/B_Format_Time      | 0.617          |
| Time/B_Original_Form... | 0.623          |
| Time/Buffer             | 0.0351         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.3765875      |
| Train/Action_magnitu... | 0.83365154     |
| Train/Action_magnitude  | 0.65252393     |
| Train/Action_max        | 0.2966242      |
| Train/Action_std        | 0.21605547     |
| Train/Entropy           | -0.16048634    |
| Train/Entropy_Loss      | 0.00016        |
| Train/Entropy_loss      | 0.00016        |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.30585548     |
| Train/Loss              | -0.027605757   |
| Train/PolicyClip        | -0.00013074087 |
| Train/Policy_loss       | -0.03424635    |
| Train/Ratio             | 1.000366       |
| Train/Return            | 2.2974052      |
| Train/V                 | 2.2646184      |
| Train/Value             | 2.2646184      |
| Train/control_penalty   | 0.6480109      |
| Train/policy_loss       | -0.03424635    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0633         |
--------------------------------------------

 ---------------- Iteration 122 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 121           |
| Time/Actor_Time         | 0.455         |
| Time/B_Format_Time      | 0.436         |
| Time/B_Original_Form... | 0.435         |
| Time/Buffer             | 0.0349        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.39565614    |
| Train/Action_magnitu... | 0.85425675    |
| Train/Action_magnitude  | 0.6678776     |
| Train/Action_max        | 0.28768694    |
| Train/Action_std        | 0.21858023    |
| Train/Entropy           | -0.15424274   |
| Train/Entropy_Loss      | 0.000154      |
| Train/Entropy_loss      | 0.000154      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.287181      |
| Train/Loss              | -0.0009075585 |
| Train/PolicyClip        | 0.00045300447 |
| Train/Policy_loss       | -0.007767923  |
| Train/Ratio             | 0.99911994    |
| Train/Return            | 2.4324555     |
| Train/V                 | 2.4259064     |
| Train/Value             | 2.4259064     |
| Train/control_penalty   | 0.6706122     |
| Train/policy_loss       | -0.007767923  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06815       |
-------------------------------------------

 ---------------- Iteration 123 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 122           |
| Time/Actor_Time         | 0.41          |
| Time/B_Format_Time      | 0.405         |
| Time/B_Original_Form... | 0.401         |
| Time/Buffer             | 0.0423        |
| Time/Critic_Time        | 2.15e-06      |
| Train/Action_abs_mean   | 0.38767064    |
| Train/Action_magnitu... | 0.8562847     |
| Train/Action_magnitude  | 0.67012715    |
| Train/Action_max        | 0.29699412    |
| Train/Action_std        | 0.21410315    |
| Train/Entropy           | -0.17558354   |
| Train/Entropy_Loss      | 0.000176      |
| Train/Entropy_loss      | 0.000176      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.2851681     |
| Train/Loss              | -0.05988815   |
| Train/PolicyClip        | 0.00079975574 |
| Train/Policy_loss       | -0.06663662   |
| Train/Ratio             | 0.99963456    |
| Train/Return            | 2.4751074     |
| Train/V                 | 2.4058917     |
| Train/Value             | 2.4058917     |
| Train/control_penalty   | 0.6572891     |
| Train/policy_loss       | -0.06663662   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07395       |
-------------------------------------------

 ---------------- Iteration 124 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 123          |
| Time/Actor_Time         | 0.434        |
| Time/B_Format_Time      | 0.412        |
| Time/B_Original_Form... | 0.405        |
| Time/Buffer             | 0.0358       |
| Time/Critic_Time        | 1.19e-06     |
| Train/Action_abs_mean   | 0.37886542   |
| Train/Action_magnitu... | 0.822407     |
| Train/Action_magnitude  | 0.640221     |
| Train/Action_max        | 0.29073578   |
| Train/Action_std        | 0.21252798   |
| Train/Entropy           | -0.17143159  |
| Train/Entropy_Loss      | 0.000171     |
| Train/Entropy_loss      | 0.000171     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.32267645   |
| Train/Loss              | -0.08888937  |
| Train/PolicyClip        | 0.0018848131 |
| Train/Policy_loss       | -0.095480815 |
| Train/Ratio             | 1.0026517    |
| Train/Return            | 2.305885     |
| Train/V                 | 2.211101     |
| Train/Value             | 2.211101     |
| Train/control_penalty   | 0.6420018    |
| Train/policy_loss       | -0.095480815 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0711       |
------------------------------------------

 ---------------- Iteration 125 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 124          |
| Time/Actor_Time         | 0.431        |
| Time/B_Format_Time      | 0.4          |
| Time/B_Original_Form... | 0.397        |
| Time/Buffer             | 0.0359       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.40535033   |
| Train/Action_magnitu... | 0.88275564   |
| Train/Action_magnitude  | 0.6858393    |
| Train/Action_max        | 0.36729005   |
| Train/Action_std        | 0.21277842   |
| Train/Entropy           | -0.19258416  |
| Train/Entropy_Loss      | 0.000193     |
| Train/Entropy_loss      | 0.000193     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.3384582    |
| Train/Loss              | -0.144785    |
| Train/PolicyClip        | 0.0002481466 |
| Train/Policy_loss       | -0.15184112  |
| Train/Ratio             | 1.003823     |
| Train/Return            | 2.3678548    |
| Train/V                 | 2.2144468    |
| Train/Value             | 2.2144468    |
| Train/control_penalty   | 0.6863529    |
| Train/policy_loss       | -0.15184112  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.074        |
------------------------------------------

 ---------------- Iteration 126 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 125          |
| Time/Actor_Time         | 0.416        |
| Time/B_Format_Time      | 0.404        |
| Time/B_Original_Form... | 0.398        |
| Time/Buffer             | 0.0324       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.4040311    |
| Train/Action_magnitu... | 0.8824183    |
| Train/Action_magnitude  | 0.68486005   |
| Train/Action_max        | 0.3653501    |
| Train/Action_std        | 0.20903815   |
| Train/Entropy           | -0.20580645  |
| Train/Entropy_Loss      | 0.000206     |
| Train/Entropy_loss      | 0.000206     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.38793588   |
| Train/Loss              | -0.114383444 |
| Train/PolicyClip        | 0.002649119  |
| Train/Policy_loss       | -0.121462464 |
| Train/Ratio             | 1.0015423    |
| Train/Return            | 2.330077     |
| Train/V                 | 2.202406     |
| Train/Value             | 2.202406     |
| Train/control_penalty   | 0.68732136   |
| Train/policy_loss       | -0.121462464 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0698       |
------------------------------------------

 ---------------- Iteration 127 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 126            |
| Time/Actor_Time         | 0.429          |
| Time/B_Format_Time      | 0.4            |
| Time/B_Original_Form... | 0.397          |
| Time/Buffer             | 0.0348         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.400772       |
| Train/Action_magnitu... | 0.8726187      |
| Train/Action_magnitude  | 0.6743797      |
| Train/Action_max        | 0.35887107     |
| Train/Action_std        | 0.19455974     |
| Train/Entropy           | -0.27068788    |
| Train/Entropy_Loss      | 0.000271       |
| Train/Entropy_loss      | 0.000271       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.4638756      |
| Train/Loss              | -0.06996161    |
| Train/PolicyClip        | -0.00034798568 |
| Train/Policy_loss       | -0.07693722    |
| Train/Ratio             | 1.0012268      |
| Train/Return            | 2.5645611      |
| Train/V                 | 2.488572       |
| Train/Value             | 2.488572       |
| Train/control_penalty   | 0.6704929      |
| Train/policy_loss       | -0.07693722    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.07035        |
--------------------------------------------

 ---------------- Iteration 128 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 127          |
| Time/Actor_Time         | 0.428        |
| Time/B_Format_Time      | 0.401        |
| Time/B_Original_Form... | 0.396        |
| Time/Buffer             | 0.0327       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37205654   |
| Train/Action_magnitu... | 0.8198317    |
| Train/Action_magnitude  | 0.63643533   |
| Train/Action_max        | 0.30869973   |
| Train/Action_std        | 0.19851598   |
| Train/Entropy           | -0.24514125  |
| Train/Entropy_Loss      | 0.000245     |
| Train/Entropy_loss      | 0.000245     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.5219698    |
| Train/Loss              | 0.009982315  |
| Train/PolicyClip        | 0.0004578052 |
| Train/Policy_loss       | 0.003395837  |
| Train/Ratio             | 0.99733377   |
| Train/Return            | 2.7194905    |
| Train/V                 | 2.7238355    |
| Train/Value             | 2.7238355    |
| Train/control_penalty   | 0.6341337    |
| Train/policy_loss       | 0.003395837  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07415      |
------------------------------------------

 ---------------- Iteration 129 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 128           |
| Time/Actor_Time         | 0.485         |
| Time/B_Format_Time      | 0.444         |
| Time/B_Original_Form... | 0.455         |
| Time/Buffer             | 0.0404        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.35970527    |
| Train/Action_magnitu... | 0.79503006    |
| Train/Action_magnitude  | 0.61403275    |
| Train/Action_max        | 0.2811995     |
| Train/Action_std        | 0.2011754     |
| Train/Entropy           | -0.23000515   |
| Train/Entropy_Loss      | 0.00023       |
| Train/Entropy_loss      | 0.00023       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.49361885    |
| Train/Loss              | -0.008270858  |
| Train/PolicyClip        | 0.00060589926 |
| Train/Policy_loss       | -0.014609459  |
| Train/Ratio             | 1.00091       |
| Train/Return            | 2.5809634     |
| Train/V                 | 2.5671942     |
| Train/Value             | 2.5671942     |
| Train/control_penalty   | 0.61085963    |
| Train/policy_loss       | -0.014609459  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0743        |
-------------------------------------------

 ---------------- Iteration 130 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 129          |
| Time/Actor_Time         | 0.449        |
| Time/B_Format_Time      | 0.41         |
| Time/B_Original_Form... | 0.41         |
| Time/Buffer             | 0.0396       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.36181247   |
| Train/Action_magnitu... | 0.795328     |
| Train/Action_magnitude  | 0.61335737   |
| Train/Action_max        | 0.3007604    |
| Train/Action_std        | 0.19740058   |
| Train/Entropy           | -0.24924697  |
| Train/Entropy_Loss      | 0.000249     |
| Train/Entropy_loss      | 0.000249     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.51201713   |
| Train/Loss              | -0.020602401 |
| Train/PolicyClip        | 0.0006138344 |
| Train/Policy_loss       | -0.026940545 |
| Train/Ratio             | 1.0013587    |
| Train/Return            | 2.4958405    |
| Train/V                 | 2.46877      |
| Train/Value             | 2.46877      |
| Train/control_penalty   | 0.6088897    |
| Train/policy_loss       | -0.026940545 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0736       |
------------------------------------------

 ---------------- Iteration 131 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 130           |
| Time/Actor_Time         | 0.455         |
| Time/B_Format_Time      | 0.441         |
| Time/B_Original_Form... | 0.44          |
| Time/Buffer             | 0.0373        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3736315     |
| Train/Action_magnitu... | 0.8057229     |
| Train/Action_magnitude  | 0.6235083     |
| Train/Action_max        | 0.29819015    |
| Train/Action_std        | 0.19383003    |
| Train/Entropy           | -0.26841524   |
| Train/Entropy_Loss      | 0.000268      |
| Train/Entropy_loss      | 0.000268      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.49390763    |
| Train/Loss              | 0.004048989   |
| Train/PolicyClip        | 0.00034186686 |
| Train/Policy_loss       | -0.0024909026 |
| Train/Ratio             | 0.9983088     |
| Train/Return            | 2.5225837     |
| Train/V                 | 2.5215304     |
| Train/Value             | 2.5215304     |
| Train/control_penalty   | 0.6271477     |
| Train/policy_loss       | -0.0024909026 |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07395       |
-------------------------------------------

 ---------------- Iteration 132 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 131           |
| Time/Actor_Time         | 0.47          |
| Time/B_Format_Time      | 0.46          |
| Time/B_Original_Form... | 0.446         |
| Time/Buffer             | 0.0379        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.38563       |
| Train/Action_magnitu... | 0.83964294    |
| Train/Action_magnitude  | 0.65095407    |
| Train/Action_max        | 0.29921696    |
| Train/Action_std        | 0.1965618     |
| Train/Entropy           | -0.2572523    |
| Train/Entropy_Loss      | 0.000257      |
| Train/Entropy_loss      | 0.000257      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.5028565     |
| Train/Loss              | 0.0024806228  |
| Train/PolicyClip        | 0.00028281094 |
| Train/Policy_loss       | -0.0042817276 |
| Train/Ratio             | 0.99943554    |
| Train/Return            | 2.6529973     |
| Train/V                 | 2.6476033     |
| Train/Value             | 2.6476033     |
| Train/control_penalty   | 0.65050983    |
| Train/policy_loss       | -0.0042817276 |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0747        |
-------------------------------------------

 ---------------- Iteration 133 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 132           |
| Time/Actor_Time         | 0.442         |
| Time/B_Format_Time      | 0.413         |
| Time/B_Original_Form... | 0.406         |
| Time/Buffer             | 0.0323        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4034346     |
| Train/Action_magnitu... | 0.86673796    |
| Train/Action_magnitude  | 0.6690373     |
| Train/Action_max        | 0.32338136    |
| Train/Action_std        | 0.19959377    |
| Train/Entropy           | -0.238669     |
| Train/Entropy_Loss      | 0.000239      |
| Train/Entropy_loss      | 0.000239      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.5001368     |
| Train/Loss              | -0.0016358816 |
| Train/PolicyClip        | 0.00014258773 |
| Train/Policy_loss       | -0.008591112  |
| Train/Ratio             | 1.0008398     |
| Train/Return            | 2.6652448     |
| Train/V                 | 2.6566336     |
| Train/Value             | 2.6566336     |
| Train/control_penalty   | 0.67165613    |
| Train/policy_loss       | -0.008591112  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07385       |
-------------------------------------------

 ---------------- Iteration 134 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
---------------------------------------------
| Itr                     | 133             |
| Time/Actor_Time         | 0.471           |
| Time/B_Format_Time      | 0.471           |
| Time/B_Original_Form... | 0.459           |
| Time/Buffer             | 0.0367          |
| Time/Critic_Time        | 0               |
| Train/Action_abs_mean   | 0.40197837      |
| Train/Action_magnitu... | 0.8689008       |
| Train/Action_magnitude  | 0.6713552       |
| Train/Action_max        | 0.32032543      |
| Train/Action_std        | 0.20178753      |
| Train/Entropy           | -0.22982746     |
| Train/Entropy_Loss      | 0.00023         |
| Train/Entropy_loss      | 0.00023         |
| Train/Grad_norm_actor   | 0.0             |
| Train/LogProb           | 0.4713358       |
| Train/Loss              | 0.03274655      |
| Train/PolicyClip        | -0.000100643825 |
| Train/Policy_loss       | 0.025806412     |
| Train/Ratio             | 0.997633        |
| Train/Return            | 2.5139778       |
| Train/V                 | 2.5420089       |
| Train/Value             | 2.5420089       |
| Train/control_penalty   | 0.67103106      |
| Train/policy_loss       | 0.025806412     |
| Train/recon_loss        | 0.0             |
| train/batch_reward      | 0.06805         |
---------------------------------------------

 ---------------- Iteration 135 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 134           |
| Time/Actor_Time         | 0.443         |
| Time/B_Format_Time      | 0.434         |
| Time/B_Original_Form... | 0.437         |
| Time/Buffer             | 0.0348        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4059666     |
| Train/Action_magnitu... | 0.88058084    |
| Train/Action_magnitude  | 0.6799506     |
| Train/Action_max        | 0.32158276    |
| Train/Action_std        | 0.2107418     |
| Train/Entropy           | -0.1978111    |
| Train/Entropy_Loss      | 0.000198      |
| Train/Entropy_loss      | 0.000198      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.38623622    |
| Train/Loss              | 0.04269713    |
| Train/PolicyClip        | 0.00030925812 |
| Train/Policy_loss       | 0.03568962    |
| Train/Ratio             | 0.9975655     |
| Train/Return            | 2.563191      |
| Train/V                 | 2.5989        |
| Train/Value             | 2.5989        |
| Train/control_penalty   | 0.6809701     |
| Train/policy_loss       | 0.03568962    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07115       |
-------------------------------------------

 ---------------- Iteration 136 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 135           |
| Time/Actor_Time         | 0.434         |
| Time/B_Format_Time      | 0.418         |
| Time/B_Original_Form... | 0.424         |
| Time/Buffer             | 0.0378        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.38331333    |
| Train/Action_magnitu... | 0.8442373     |
| Train/Action_magnitude  | 0.6535682     |
| Train/Action_max        | 0.2745665     |
| Train/Action_std        | 0.21342209    |
| Train/Entropy           | -0.17852972   |
| Train/Entropy_Loss      | 0.000179      |
| Train/Entropy_loss      | 0.000179      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.3443662     |
| Train/Loss              | 0.02311818    |
| Train/PolicyClip        | 3.0438989e-05 |
| Train/Policy_loss       | 0.016405547   |
| Train/Ratio             | 0.9998248     |
| Train/Return            | 2.587827      |
| Train/V                 | 2.6061995     |
| Train/Value             | 2.6061995     |
| Train/control_penalty   | 0.65341026    |
| Train/policy_loss       | 0.016405547   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0747        |
-------------------------------------------

 ---------------- Iteration 137 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 136           |
| Time/Actor_Time         | 0.451         |
| Time/B_Format_Time      | 0.397         |
| Time/B_Original_Form... | 0.4           |
| Time/Buffer             | 0.329         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37328684    |
| Train/Action_magnitu... | 0.8250961     |
| Train/Action_magnitude  | 0.64177245    |
| Train/Action_max        | 0.23589993    |
| Train/Action_std        | 0.21451578    |
| Train/Entropy           | -0.16622365   |
| Train/Entropy_Loss      | 0.000166      |
| Train/Entropy_loss      | 0.000166      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.30978       |
| Train/Loss              | 0.06098169    |
| Train/PolicyClip        | 0.00020873774 |
| Train/Policy_loss       | 0.054388348   |
| Train/Ratio             | 0.9987643     |
| Train/Return            | 2.5612042     |
| Train/V                 | 2.6176822     |
| Train/Value             | 2.6176822     |
| Train/control_penalty   | 0.64271224    |
| Train/policy_loss       | 0.054388348   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0753        |
-------------------------------------------

 ---------------- Iteration 138 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 137          |
| Time/Actor_Time         | 0.442        |
| Time/B_Format_Time      | 0.419        |
| Time/B_Original_Form... | 0.427        |
| Time/Buffer             | 0.0465       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.38609836   |
| Train/Action_magnitu... | 0.8387844    |
| Train/Action_magnitude  | 0.65058666   |
| Train/Action_max        | 0.22578359   |
| Train/Action_std        | 0.21267346   |
| Train/Entropy           | -0.16495194  |
| Train/Entropy_Loss      | 0.000165     |
| Train/Entropy_loss      | 0.000165     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.31247735   |
| Train/Loss              | 0.051035028  |
| Train/PolicyClip        | 0.0003789969 |
| Train/Policy_loss       | 0.04429914   |
| Train/Ratio             | 0.9986538    |
| Train/Return            | 2.7859643    |
| Train/V                 | 2.8323882    |
| Train/Value             | 2.8323882    |
| Train/control_penalty   | 0.65709364   |
| Train/policy_loss       | 0.04429914   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0723       |
------------------------------------------

 ---------------- Iteration 139 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 138           |
| Time/Actor_Time         | 0.448         |
| Time/B_Format_Time      | 0.442         |
| Time/B_Original_Form... | 0.437         |
| Time/Buffer             | 0.0528        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3998448     |
| Train/Action_magnitu... | 0.86817384    |
| Train/Action_magnitude  | 0.67491007    |
| Train/Action_max        | 0.23412974    |
| Train/Action_std        | 0.21383771    |
| Train/Entropy           | -0.15627535   |
| Train/Entropy_Loss      | 0.000156      |
| Train/Entropy_loss      | 0.000156      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.32773247    |
| Train/Loss              | 0.05562658    |
| Train/PolicyClip        | 0.00040047383 |
| Train/Policy_loss       | 0.04870944    |
| Train/Ratio             | 0.9993174     |
| Train/Return            | 2.769538      |
| Train/V                 | 2.820206      |
| Train/Value             | 2.820206      |
| Train/control_penalty   | 0.67608625    |
| Train/policy_loss       | 0.04870944    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0706        |
-------------------------------------------

 ---------------- Iteration 140 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 139            |
| Time/Actor_Time         | 0.569          |
| Time/B_Format_Time      | 0.563          |
| Time/B_Original_Form... | 0.561          |
| Time/Buffer             | 0.047          |
| Time/Critic_Time        | 1.19e-06       |
| Train/Action_abs_mean   | 0.38146484     |
| Train/Action_magnitu... | 0.84142196     |
| Train/Action_magnitude  | 0.656187       |
| Train/Action_max        | 0.25354758     |
| Train/Action_std        | 0.21403994     |
| Train/Entropy           | -0.15829147    |
| Train/Entropy_Loss      | 0.000158       |
| Train/Entropy_loss      | 0.000158       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.34385        |
| Train/Loss              | 0.06660534     |
| Train/PolicyClip        | -0.00027351762 |
| Train/Policy_loss       | 0.059883405    |
| Train/Ratio             | 0.9984969      |
| Train/Return            | 2.7895207      |
| Train/V                 | 2.8511682      |
| Train/Value             | 2.8511682      |
| Train/control_penalty   | 0.6563644      |
| Train/policy_loss       | 0.059883405    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.06755        |
--------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 141 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 140           |
| Time/Actor_Time         | 0.635         |
| Time/B_Format_Time      | 0.571         |
| Time/B_Original_Form... | 0.583         |
| Time/Buffer             | 0.0512        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36351398    |
| Train/Action_magnitu... | 0.79806435    |
| Train/Action_magnitude  | 0.62277067    |
| Train/Action_max        | 0.28861162    |
| Train/Action_std        | 0.21766491    |
| Train/Entropy           | -0.14722869   |
| Train/Entropy_Loss      | 0.000147      |
| Train/Entropy_loss      | 0.000147      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.34286067    |
| Train/Loss              | 0.101043515   |
| Train/PolicyClip        | -0.0012599328 |
| Train/Policy_loss       | 0.094530575   |
| Train/Ratio             | 0.9984059     |
| Train/Return            | 2.6067102     |
| Train/V                 | 2.700441      |
| Train/Value             | 2.700441      |
| Train/control_penalty   | 0.6365709     |
| Train/policy_loss       | 0.094530575   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06015       |
-------------------------------------------

 ---------------- Iteration 142 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 141          |
| Time/Actor_Time         | 0.638        |
| Time/B_Format_Time      | 0.651        |
| Time/B_Original_Form... | 0.63         |
| Time/Buffer             | 0.052        |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3601884    |
| Train/Action_magnitu... | 0.8080794    |
| Train/Action_magnitude  | 0.6262589    |
| Train/Action_max        | 0.30378962   |
| Train/Action_std        | 0.2105976    |
| Train/Entropy           | -0.18596028  |
| Train/Entropy_Loss      | 0.000186     |
| Train/Entropy_loss      | 0.000186     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.29503268   |
| Train/Loss              | 0.035568442  |
| Train/PolicyClip        | 0.0005947758 |
| Train/Policy_loss       | 0.029169561  |
| Train/Ratio             | 0.9974385    |
| Train/Return            | 2.4823112    |
| Train/V                 | 2.5070226    |
| Train/Value             | 2.5070226    |
| Train/control_penalty   | 0.621292     |
| Train/policy_loss       | 0.029169561  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06275      |
------------------------------------------

 ---------------- Iteration 143 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 142           |
| Time/Actor_Time         | 0.535         |
| Time/B_Format_Time      | 0.563         |
| Time/B_Original_Form... | 0.594         |
| Time/Buffer             | 0.0469        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.3627123     |
| Train/Action_magnitu... | 0.8104383     |
| Train/Action_magnitude  | 0.6264481     |
| Train/Action_max        | 0.31821984    |
| Train/Action_std        | 0.21342331    |
| Train/Entropy           | -0.17867133   |
| Train/Entropy_Loss      | 0.000179      |
| Train/Entropy_loss      | 0.000179      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.34312588    |
| Train/Loss              | 0.029279288   |
| Train/PolicyClip        | 7.9590536e-05 |
| Train/Policy_loss       | 0.022837702   |
| Train/Ratio             | 0.99864835    |
| Train/Return            | 2.403741      |
| Train/V                 | 2.4277534     |
| Train/Value             | 2.4277534     |
| Train/control_penalty   | 0.62629163    |
| Train/policy_loss       | 0.022837702   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0651        |
-------------------------------------------

 ---------------- Iteration 144 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 143          |
| Time/Actor_Time         | 0.5          |
| Time/B_Format_Time      | 0.503        |
| Time/B_Original_Form... | 0.534        |
| Time/Buffer             | 0.0531       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3577481    |
| Train/Action_magnitu... | 0.79771614   |
| Train/Action_magnitude  | 0.6208017    |
| Train/Action_max        | 0.3260463    |
| Train/Action_std        | 0.21981172   |
| Train/Entropy           | -0.15975456  |
| Train/Entropy_Loss      | 0.00016      |
| Train/Entropy_loss      | 0.00016      |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.37544543   |
| Train/Loss              | 0.047739554  |
| Train/PolicyClip        | 7.179845e-05 |
| Train/Policy_loss       | 0.041297115  |
| Train/Ratio             | 0.9965503    |
| Train/Return            | 2.4072933    |
| Train/V                 | 2.4486961    |
| Train/Value             | 2.4486961    |
| Train/control_penalty   | 0.6282685    |
| Train/policy_loss       | 0.041297115  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06845      |
------------------------------------------

 ---------------- Iteration 145 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 144            |
| Time/Actor_Time         | 0.552          |
| Time/B_Format_Time      | 0.56           |
| Time/B_Original_Form... | 0.554          |
| Time/Buffer             | 0.0442         |
| Time/Critic_Time        | 7.15e-07       |
| Train/Action_abs_mean   | 0.34462845     |
| Train/Action_magnitu... | 0.79496825     |
| Train/Action_magnitude  | 0.62010396     |
| Train/Action_max        | 0.30863827     |
| Train/Action_std        | 0.24559014     |
| Train/Entropy           | -0.058162462   |
| Train/Entropy_Loss      | 5.82e-05       |
| Train/Entropy_loss      | 5.82e-05       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.27716956     |
| Train/Loss              | 0.045757595    |
| Train/PolicyClip        | -0.00019683967 |
| Train/Policy_loss       | 0.03937532     |
| Train/Ratio             | 0.9966244      |
| Train/Return            | 2.3520534      |
| Train/V                 | 2.3868978      |
| Train/Value             | 2.3868978      |
| Train/control_penalty   | 0.6324113      |
| Train/policy_loss       | 0.03937532     |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.06495        |
--------------------------------------------

 ---------------- Iteration 146 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 145           |
| Time/Actor_Time         | 0.545         |
| Time/B_Format_Time      | 0.53          |
| Time/B_Original_Form... | 0.533         |
| Time/Buffer             | 0.0464        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.33944392    |
| Train/Action_magnitu... | 0.8000586     |
| Train/Action_magnitude  | 0.626704      |
| Train/Action_max        | 0.27821898    |
| Train/Action_std        | 0.24826401    |
| Train/Entropy           | -0.04021534   |
| Train/Entropy_Loss      | 4.02e-05      |
| Train/Entropy_loss      | 4.02e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.1605212     |
| Train/Loss              | 0.087935284   |
| Train/PolicyClip        | -0.0019455317 |
| Train/Policy_loss       | 0.08156879    |
| Train/Ratio             | 0.99746746    |
| Train/Return            | 2.4562767     |
| Train/V                 | 2.5380738     |
| Train/Value             | 2.5380738     |
| Train/control_penalty   | 0.6326274     |
| Train/policy_loss       | 0.08156879    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06795       |
-------------------------------------------

 ---------------- Iteration 147 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 146          |
| Time/Actor_Time         | 0.52         |
| Time/B_Format_Time      | 0.546        |
| Time/B_Original_Form... | 0.548        |
| Time/Buffer             | 0.0466       |
| Time/Critic_Time        | 1.19e-06     |
| Train/Action_abs_mean   | 0.3677164    |
| Train/Action_magnitu... | 0.84248984   |
| Train/Action_magnitude  | 0.65808904   |
| Train/Action_max        | 0.26747355   |
| Train/Action_std        | 0.23821807   |
| Train/Entropy           | -0.07173153  |
| Train/Entropy_Loss      | 7.17e-05     |
| Train/Entropy_loss      | 7.17e-05     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.11616704   |
| Train/Loss              | -0.011094451 |
| Train/PolicyClip        | 0.000207655  |
| Train/Policy_loss       | -0.017716007 |
| Train/Ratio             | 1.000883     |
| Train/Return            | 2.3903348    |
| Train/V                 | 2.3747313    |
| Train/Value             | 2.3747313    |
| Train/control_penalty   | 0.65498245   |
| Train/policy_loss       | -0.017716007 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.071        |
------------------------------------------

 ---------------- Iteration 148 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 147           |
| Time/Actor_Time         | 0.478         |
| Time/B_Format_Time      | 0.469         |
| Time/B_Original_Form... | 0.488         |
| Time/Buffer             | 0.0414        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.39938277    |
| Train/Action_magnitu... | 0.9002603     |
| Train/Action_magnitude  | 0.69764036    |
| Train/Action_max        | 0.29875734    |
| Train/Action_std        | 0.23581846    |
| Train/Entropy           | -0.089697406  |
| Train/Entropy_Loss      | 8.97e-05      |
| Train/Entropy_loss      | 8.97e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.13343339    |
| Train/Loss              | -0.049232073  |
| Train/PolicyClip        | -3.012435e-05 |
| Train/Policy_loss       | -0.056205664  |
| Train/Ratio             | 1.0024388     |
| Train/Return            | 2.293817      |
| Train/V                 | 2.2393274     |
| Train/Value             | 2.2393274     |
| Train/control_penalty   | 0.6883894     |
| Train/policy_loss       | -0.056205664  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07145       |
-------------------------------------------

 ---------------- Iteration 149 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 148            |
| Time/Actor_Time         | 0.55           |
| Time/B_Format_Time      | 0.567          |
| Time/B_Original_Form... | 0.582          |
| Time/Buffer             | 0.0407         |
| Time/Critic_Time        | 9.54e-07       |
| Train/Action_abs_mean   | 0.42490765     |
| Train/Action_magnitu... | 0.93791837     |
| Train/Action_magnitude  | 0.7239988      |
| Train/Action_max        | 0.33624902     |
| Train/Action_std        | 0.23797859     |
| Train/Entropy           | -0.09728155    |
| Train/Entropy_Loss      | 9.73e-05       |
| Train/Entropy_loss      | 9.73e-05       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.12410903     |
| Train/Loss              | -0.07460651    |
| Train/PolicyClip        | -0.00017713125 |
| Train/Policy_loss       | -0.08194369    |
| Train/Ratio             | 1.0048648      |
| Train/Return            | 2.2570446      |
| Train/V                 | 2.1768043      |
| Train/Value             | 2.1768043      |
| Train/control_penalty   | 0.72399        |
| Train/policy_loss       | -0.08194369    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0684         |
--------------------------------------------

 ---------------- Iteration 150 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 149            |
| Time/Actor_Time         | 0.579          |
| Time/B_Format_Time      | 0.568          |
| Time/B_Original_Form... | 0.568          |
| Time/Buffer             | 0.0518         |
| Time/Critic_Time        | 9.54e-07       |
| Train/Action_abs_mean   | 0.4096621      |
| Train/Action_magnitu... | 0.9200621      |
| Train/Action_magnitude  | 0.7112598      |
| Train/Action_max        | 0.3409603      |
| Train/Action_std        | 0.23646614     |
| Train/Entropy           | -0.108925804   |
| Train/Entropy_Loss      | 0.000109       |
| Train/Entropy_loss      | 0.000109       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.15437794     |
| Train/Loss              | -0.068202406   |
| Train/PolicyClip        | -6.9019465e-05 |
| Train/Policy_loss       | -0.07539662    |
| Train/Ratio             | 1.0016277      |
| Train/Return            | 2.1282856      |
| Train/V                 | 2.0547636      |
| Train/Value             | 2.0547636      |
| Train/control_penalty   | 0.70852894     |
| Train/policy_loss       | -0.07539662    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0675         |
--------------------------------------------

 ---------------- Iteration 151 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 150            |
| Time/Actor_Time         | 0.454          |
| Time/B_Format_Time      | 0.429          |
| Time/B_Original_Form... | 0.417          |
| Time/Buffer             | 0.0515         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.40052983     |
| Train/Action_magnitu... | 0.8946576      |
| Train/Action_magnitude  | 0.69233173     |
| Train/Action_max        | 0.30590004     |
| Train/Action_std        | 0.22494075     |
| Train/Entropy           | -0.14908151    |
| Train/Entropy_Loss      | 0.000149       |
| Train/Entropy_loss      | 0.000149       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.23404488     |
| Train/Loss              | -0.07690228    |
| Train/PolicyClip        | -9.0769194e-05 |
| Train/Policy_loss       | -0.08397565    |
| Train/Ratio             | 1.0013562      |
| Train/Return            | 2.0164766      |
| Train/V                 | 1.9340833      |
| Train/Value             | 1.9340833      |
| Train/control_penalty   | 0.69242907     |
| Train/policy_loss       | -0.08397565    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.06805        |
--------------------------------------------

 ---------------- Iteration 152 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 151            |
| Time/Actor_Time         | 0.508          |
| Time/B_Format_Time      | 0.487          |
| Time/B_Original_Form... | 0.498          |
| Time/Buffer             | 0.0509         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.414431       |
| Train/Action_magnitu... | 0.9205087      |
| Train/Action_magnitude  | 0.7087126      |
| Train/Action_max        | 0.29386914     |
| Train/Action_std        | 0.2178939      |
| Train/Entropy           | -0.17229728    |
| Train/Entropy_Loss      | 0.000172       |
| Train/Entropy_loss      | 0.000172       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.2641039      |
| Train/Loss              | -0.11627719    |
| Train/PolicyClip        | -0.00044032207 |
| Train/Policy_loss       | -0.12347592    |
| Train/Ratio             | 1.0029858      |
| Train/Return            | 2.2740624      |
| Train/V                 | 2.1524653      |
| Train/Value             | 2.1524653      |
| Train/control_penalty   | 0.7026435      |
| Train/policy_loss       | -0.12347592    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0748         |
--------------------------------------------

 ---------------- Iteration 153 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 152           |
| Time/Actor_Time         | 0.512         |
| Time/B_Format_Time      | 0.533         |
| Time/B_Original_Form... | 0.534         |
| Time/Buffer             | 0.0423        |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.40966544    |
| Train/Action_magnitu... | 0.91177696    |
| Train/Action_magnitude  | 0.7037288     |
| Train/Action_max        | 0.31283054    |
| Train/Action_std        | 0.20856878    |
| Train/Entropy           | -0.2143362    |
| Train/Entropy_Loss      | 0.000214      |
| Train/Entropy_loss      | 0.000214      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.3221621     |
| Train/Loss              | -0.11625164   |
| Train/PolicyClip        | 5.1418352e-05 |
| Train/Policy_loss       | -0.12342466   |
| Train/Ratio             | 1.0070063     |
| Train/Return            | 2.3326173     |
| Train/V                 | 2.208879      |
| Train/Value             | 2.208879      |
| Train/control_penalty   | 0.6958679     |
| Train/policy_loss       | -0.12342466   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0738        |
-------------------------------------------

 ---------------- Iteration 154 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 153          |
| Time/Actor_Time         | 0.512        |
| Time/B_Format_Time      | 0.542        |
| Time/B_Original_Form... | 0.549        |
| Time/Buffer             | 0.0346       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.4157536    |
| Train/Action_magnitu... | 0.91291726   |
| Train/Action_magnitude  | 0.7045       |
| Train/Action_max        | 0.36870298   |
| Train/Action_std        | 0.21274671   |
| Train/Entropy           | -0.20838596  |
| Train/Entropy_Loss      | 0.000208     |
| Train/Entropy_loss      | 0.000208     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.3988157    |
| Train/Loss              | -0.0927568   |
| Train/PolicyClip        | 0.0005608156 |
| Train/Policy_loss       | -0.09995268  |
| Train/Ratio             | 1.0017481    |
| Train/Return            | 2.5661683    |
| Train/V                 | 2.4669096    |
| Train/Value             | 2.4669096    |
| Train/control_penalty   | 0.6987499    |
| Train/policy_loss       | -0.09995268  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0711       |
------------------------------------------

 ---------------- Iteration 155 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 154           |
| Time/Actor_Time         | 0.504         |
| Time/B_Format_Time      | 0.506         |
| Time/B_Original_Form... | 0.51          |
| Time/Buffer             | 0.0363        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3797861     |
| Train/Action_magnitu... | 0.8438615     |
| Train/Action_magnitude  | 0.6522572     |
| Train/Action_max        | 0.31635466    |
| Train/Action_std        | 0.20587654    |
| Train/Entropy           | -0.2439698    |
| Train/Entropy_Loss      | 0.000244      |
| Train/Entropy_loss      | 0.000244      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.4291998     |
| Train/Loss              | -0.065303646  |
| Train/PolicyClip        | -0.0001907911 |
| Train/Policy_loss       | -0.072025575  |
| Train/Ratio             | 1.0013064     |
| Train/Return            | 2.4495573     |
| Train/V                 | 2.3774896     |
| Train/Value             | 2.3774896     |
| Train/control_penalty   | 0.647796      |
| Train/policy_loss       | -0.072025575  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0686        |
-------------------------------------------

 ---------------- Iteration 156 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 155          |
| Time/Actor_Time         | 0.512        |
| Time/B_Format_Time      | 0.509        |
| Time/B_Original_Form... | 0.518        |
| Time/Buffer             | 0.0362       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3485386    |
| Train/Action_magnitu... | 0.79262483   |
| Train/Action_magnitude  | 0.6133403    |
| Train/Action_max        | 0.3396729    |
| Train/Action_std        | 0.20347427   |
| Train/Entropy           | -0.252783    |
| Train/Entropy_Loss      | 0.000253     |
| Train/Entropy_loss      | 0.000253     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.45412335   |
| Train/Loss              | -0.014687873 |
| Train/PolicyClip        | 0.001805702  |
| Train/Policy_loss       | -0.020999836 |
| Train/Ratio             | 1.0030462    |
| Train/Return            | 2.1756763    |
| Train/V                 | 2.14905      |
| Train/Value             | 2.14905      |
| Train/control_penalty   | 0.605918     |
| Train/policy_loss       | -0.020999836 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0612       |
------------------------------------------

 ---------------- Iteration 157 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 156          |
| Time/Actor_Time         | 0.542        |
| Time/B_Format_Time      | 0.552        |
| Time/B_Original_Form... | 0.551        |
| Time/Buffer             | 0.0507       |
| Time/Critic_Time        | 1.19e-06     |
| Train/Action_abs_mean   | 0.33538282   |
| Train/Action_magnitu... | 0.76668763   |
| Train/Action_magnitude  | 0.594572     |
| Train/Action_max        | 0.33640945   |
| Train/Action_std        | 0.20520118   |
| Train/Entropy           | -0.23749912  |
| Train/Entropy_Loss      | 0.000237     |
| Train/Entropy_loss      | 0.000237     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.45979512   |
| Train/Loss              | 0.0035654712 |
| Train/PolicyClip        | 0.0012828073 |
| Train/Policy_loss       | -0.002576703 |
| Train/Ratio             | 1.0015078    |
| Train/Return            | 2.3325996    |
| Train/V                 | 2.3232853    |
| Train/Value             | 2.3232853    |
| Train/control_penalty   | 0.5904675    |
| Train/policy_loss       | -0.002576703 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0673       |
------------------------------------------

 ---------------- Iteration 158 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 157           |
| Time/Actor_Time         | 0.499         |
| Time/B_Format_Time      | 0.516         |
| Time/B_Original_Form... | 0.523         |
| Time/Buffer             | 0.0488        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.35287184    |
| Train/Action_magnitu... | 0.78858596    |
| Train/Action_magnitude  | 0.6127987     |
| Train/Action_max        | 0.34389442    |
| Train/Action_std        | 0.21148708    |
| Train/Entropy           | -0.19889772   |
| Train/Entropy_Loss      | 0.000199      |
| Train/Entropy_loss      | 0.000199      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.4529162     |
| Train/Loss              | 0.014184495   |
| Train/PolicyClip        | 0.00012356759 |
| Train/Policy_loss       | 0.007799738   |
| Train/Ratio             | 0.99969363    |
| Train/Return            | 2.200911      |
| Train/V                 | 2.207035      |
| Train/Value             | 2.207035      |
| Train/control_penalty   | 0.61858594    |
| Train/policy_loss       | 0.007799738   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06875       |
-------------------------------------------

 ---------------- Iteration 159 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 158           |
| Time/Actor_Time         | 0.521         |
| Time/B_Format_Time      | 0.548         |
| Time/B_Original_Form... | 0.542         |
| Time/Buffer             | 0.0437        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.385317      |
| Train/Action_magnitu... | 0.8456069     |
| Train/Action_magnitude  | 0.65649086    |
| Train/Action_max        | 0.376047      |
| Train/Action_std        | 0.20828106    |
| Train/Entropy           | -0.22030617   |
| Train/Entropy_Loss      | 0.00022       |
| Train/Entropy_loss      | 0.00022       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.3988834     |
| Train/Loss              | -0.028883869  |
| Train/PolicyClip        | 0.00026154393 |
| Train/Policy_loss       | -0.0357086    |
| Train/Ratio             | 1.0001465     |
| Train/Return            | 2.287496      |
| Train/V                 | 2.2517614     |
| Train/Value             | 2.2517614     |
| Train/control_penalty   | 0.66044235    |
| Train/policy_loss       | -0.0357086    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07255       |
-------------------------------------------

 ---------------- Iteration 160 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 159           |
| Time/Actor_Time         | 0.494         |
| Time/B_Format_Time      | 0.488         |
| Time/B_Original_Form... | 0.487         |
| Time/Buffer             | 0.0519        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.4019773     |
| Train/Action_magnitu... | 0.871337      |
| Train/Action_magnitude  | 0.67815554    |
| Train/Action_max        | 0.35473236    |
| Train/Action_std        | 0.20278445    |
| Train/Entropy           | -0.24717283   |
| Train/Entropy_Loss      | 0.000247      |
| Train/Entropy_loss      | 0.000247      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.4662313     |
| Train/Loss              | -0.043959193  |
| Train/PolicyClip        | 0.00040566953 |
| Train/Policy_loss       | -0.050977208  |
| Train/Ratio             | 0.99843603    |
| Train/Return            | 2.316526      |
| Train/V                 | 2.2648478     |
| Train/Value             | 2.2648478     |
| Train/control_penalty   | 0.67708427    |
| Train/policy_loss       | -0.050977208  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0763        |
-------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 161 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 160           |
| Time/Actor_Time         | 0.638         |
| Time/B_Format_Time      | 0.662         |
| Time/B_Original_Form... | 0.657         |
| Time/Buffer             | 0.0416        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.39950296    |
| Train/Action_magnitu... | 0.8696188     |
| Train/Action_magnitude  | 0.6765596     |
| Train/Action_max        | 0.34229523    |
| Train/Action_std        | 0.19838414    |
| Train/Entropy           | -0.2694601    |
| Train/Entropy_Loss      | 0.000269      |
| Train/Entropy_loss      | 0.000269      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.48870704    |
| Train/Loss              | -0.018948445  |
| Train/PolicyClip        | -2.173005e-06 |
| Train/Policy_loss       | -0.025952293  |
| Train/Ratio             | 0.99861115    |
| Train/Return            | 2.4129393     |
| Train/V                 | 2.3888924     |
| Train/Value             | 2.3888924     |
| Train/control_penalty   | 0.6734388     |
| Train/policy_loss       | -0.025952293  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0744        |
-------------------------------------------

 ---------------- Iteration 162 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 161           |
| Time/Actor_Time         | 0.589         |
| Time/B_Format_Time      | 0.567         |
| Time/B_Original_Form... | 0.566         |
| Time/Buffer             | 0.0407        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.41201958    |
| Train/Action_magnitu... | 0.8893784     |
| Train/Action_magnitude  | 0.6883123     |
| Train/Action_max        | 0.36272407    |
| Train/Action_std        | 0.20053415    |
| Train/Entropy           | -0.26099193   |
| Train/Entropy_Loss      | 0.000261      |
| Train/Entropy_loss      | 0.000261      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.4613588     |
| Train/Loss              | -0.017776825  |
| Train/PolicyClip        | 0.00020425234 |
| Train/Policy_loss       | -0.024939686  |
| Train/Ratio             | 0.99874884    |
| Train/Return            | 2.314408      |
| Train/V                 | 2.2913897     |
| Train/Value             | 2.2913897     |
| Train/control_penalty   | 0.690187      |
| Train/policy_loss       | -0.024939686  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06725       |
-------------------------------------------

 ---------------- Iteration 163 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 162           |
| Time/Actor_Time         | 0.546         |
| Time/B_Format_Time      | 0.537         |
| Time/B_Original_Form... | 0.566         |
| Time/Buffer             | 0.0429        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.40087277    |
| Train/Action_magnitu... | 0.8681999     |
| Train/Action_magnitude  | 0.66949844    |
| Train/Action_max        | 0.34303415    |
| Train/Action_std        | 0.19767225    |
| Train/Entropy           | -0.2712484    |
| Train/Entropy_Loss      | 0.000271      |
| Train/Entropy_loss      | 0.000271      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.5233361     |
| Train/Loss              | -0.023374373  |
| Train/PolicyClip        | 1.6470021e-05 |
| Train/Policy_loss       | -0.030365698  |
| Train/Ratio             | 1.0001103     |
| Train/Return            | 2.3922386     |
| Train/V                 | 2.3642402     |
| Train/Value             | 2.3642402     |
| Train/control_penalty   | 0.67200774    |
| Train/policy_loss       | -0.030365698  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0658        |
-------------------------------------------

 ---------------- Iteration 164 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 163          |
| Time/Actor_Time         | 0.539        |
| Time/B_Format_Time      | 0.55         |
| Time/B_Original_Form... | 0.549        |
| Time/Buffer             | 0.0531       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3910292    |
| Train/Action_magnitu... | 0.86228865   |
| Train/Action_magnitude  | 0.665746     |
| Train/Action_max        | 0.34731942   |
| Train/Action_std        | 0.19790845   |
| Train/Entropy           | -0.2631767   |
| Train/Entropy_Loss      | 0.000263     |
| Train/Entropy_loss      | 0.000263     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.4517595    |
| Train/Loss              | -0.026359318 |
| Train/PolicyClip        | 0.0027445315 |
| Train/Policy_loss       | -0.033275623 |
| Train/Ratio             | 0.9999494    |
| Train/Return            | 2.3462632    |
| Train/V                 | 2.2999208    |
| Train/Value             | 2.2999208    |
| Train/control_penalty   | 0.66531277   |
| Train/policy_loss       | -0.033275623 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06805      |
------------------------------------------

 ---------------- Iteration 165 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 164          |
| Time/Actor_Time         | 0.507        |
| Time/B_Format_Time      | 0.518        |
| Time/B_Original_Form... | 0.535        |
| Time/Buffer             | 0.0494       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.38125098   |
| Train/Action_magnitu... | 0.84180593   |
| Train/Action_magnitude  | 0.6549506    |
| Train/Action_max        | 0.3021528    |
| Train/Action_std        | 0.19668148   |
| Train/Entropy           | -0.26161224  |
| Train/Entropy_Loss      | 0.000262     |
| Train/Entropy_loss      | 0.000262     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.53105557   |
| Train/Loss              | -0.014535958 |
| Train/PolicyClip        | 0.0012207106 |
| Train/Policy_loss       | -0.021357177 |
| Train/Ratio             | 0.99990046   |
| Train/Return            | 2.422643     |
| Train/V                 | 2.401651     |
| Train/Value             | 2.401651     |
| Train/control_penalty   | 0.65596074   |
| Train/policy_loss       | -0.021357177 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07195      |
------------------------------------------

 ---------------- Iteration 166 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 165           |
| Time/Actor_Time         | 0.55          |
| Time/B_Format_Time      | 0.549         |
| Time/B_Original_Form... | 0.532         |
| Time/Buffer             | 0.043         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36069825    |
| Train/Action_magnitu... | 0.793502      |
| Train/Action_magnitude  | 0.6213747     |
| Train/Action_max        | 0.2669833     |
| Train/Action_std        | 0.19131936    |
| Train/Entropy           | -0.28955695   |
| Train/Entropy_Loss      | 0.00029       |
| Train/Entropy_loss      | 0.00029       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.5685268     |
| Train/Loss              | 0.020887155   |
| Train/PolicyClip        | 0.00076482503 |
| Train/Policy_loss       | 0.014341785   |
| Train/Ratio             | 1.0008359     |
| Train/Return            | 2.38784       |
| Train/V                 | 2.4010575     |
| Train/Value             | 2.4010575     |
| Train/control_penalty   | 0.6255814     |
| Train/policy_loss       | 0.014341785   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.069         |
-------------------------------------------

 ---------------- Iteration 167 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 166            |
| Time/Actor_Time         | 0.564          |
| Time/B_Format_Time      | 0.519          |
| Time/B_Original_Form... | 0.525          |
| Time/Buffer             | 0.0471         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.35859814     |
| Train/Action_magnitu... | 0.79389215     |
| Train/Action_magnitude  | 0.62119657     |
| Train/Action_max        | 0.2579675      |
| Train/Action_std        | 0.19676153     |
| Train/Entropy           | -0.25905034    |
| Train/Entropy_Loss      | 0.000259       |
| Train/Entropy_loss      | 0.000259       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.54630816     |
| Train/Loss              | 0.010526834    |
| Train/PolicyClip        | -0.00013427675 |
| Train/Policy_loss       | 0.004097564    |
| Train/Ratio             | 0.9979248      |
| Train/Return            | 2.1076384      |
| Train/V                 | 2.1134028      |
| Train/Value             | 2.1134028      |
| Train/control_penalty   | 0.617022       |
| Train/policy_loss       | 0.004097564    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.06455        |
--------------------------------------------

 ---------------- Iteration 168 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 167            |
| Time/Actor_Time         | 0.651          |
| Time/B_Format_Time      | 0.635          |
| Time/B_Original_Form... | 0.609          |
| Time/Buffer             | 0.0529         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.37092757     |
| Train/Action_magnitu... | 0.8162003      |
| Train/Action_magnitude  | 0.6359414      |
| Train/Action_max        | 0.28141302     |
| Train/Action_std        | 0.19341762     |
| Train/Entropy           | -0.27761215    |
| Train/Entropy_Loss      | 0.000278       |
| Train/Entropy_loss      | 0.000278       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.5371633      |
| Train/Loss              | 0.043027844    |
| Train/PolicyClip        | -3.9104176e-05 |
| Train/Policy_loss       | 0.036442414    |
| Train/Ratio             | 0.9989797      |
| Train/Return            | 2.292399       |
| Train/V                 | 2.3302474      |
| Train/Value             | 2.3302474      |
| Train/control_penalty   | 0.6307819      |
| Train/policy_loss       | 0.036442414    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.07075        |
--------------------------------------------

 ---------------- Iteration 169 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 168          |
| Time/Actor_Time         | 0.513        |
| Time/B_Format_Time      | 0.48         |
| Time/B_Original_Form... | 0.493        |
| Time/Buffer             | 0.0434       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.38042638   |
| Train/Action_magnitu... | 0.8447743    |
| Train/Action_magnitude  | 0.6555077    |
| Train/Action_max        | 0.31289062   |
| Train/Action_std        | 0.20506775   |
| Train/Entropy           | -0.21863542  |
| Train/Entropy_Loss      | 0.000219     |
| Train/Entropy_loss      | 0.000219     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.46169096   |
| Train/Loss              | 0.03860593   |
| Train/PolicyClip        | -0.001090567 |
| Train/Policy_loss       | 0.031898852  |
| Train/Ratio             | 0.998036     |
| Train/Return            | 2.6888804    |
| Train/V                 | 2.7196925    |
| Train/Value             | 2.7196925    |
| Train/control_penalty   | 0.64884406   |
| Train/policy_loss       | 0.031898852  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07605      |
------------------------------------------

 ---------------- Iteration 170 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 169          |
| Time/Actor_Time         | 0.511        |
| Time/B_Format_Time      | 0.537        |
| Time/B_Original_Form... | 0.543        |
| Time/Buffer             | 0.0373       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.40678984   |
| Train/Action_magnitu... | 0.8761331    |
| Train/Action_magnitude  | 0.6786667    |
| Train/Action_max        | 0.3201962    |
| Train/Action_std        | 0.207203     |
| Train/Entropy           | -0.21076189  |
| Train/Entropy_Loss      | 0.000211     |
| Train/Entropy_loss      | 0.000211     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.41487598   |
| Train/Loss              | 0.049998343  |
| Train/PolicyClip        | 6.050002e-05 |
| Train/Policy_loss       | 0.04295391   |
| Train/Ratio             | 0.99926347   |
| Train/Return            | 2.9179287    |
| Train/V                 | 2.9606495    |
| Train/Value             | 2.9606495    |
| Train/control_penalty   | 0.6833673    |
| Train/policy_loss       | 0.04295391   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07495      |
------------------------------------------

 ---------------- Iteration 171 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 170            |
| Time/Actor_Time         | 0.472          |
| Time/B_Format_Time      | 0.471          |
| Time/B_Original_Form... | 0.469          |
| Time/Buffer             | 0.0383         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.41495073     |
| Train/Action_magnitu... | 0.8890271      |
| Train/Action_magnitude  | 0.6885763      |
| Train/Action_max        | 0.3107237      |
| Train/Action_std        | 0.20775801     |
| Train/Entropy           | -0.20445195    |
| Train/Entropy_Loss      | 0.000204       |
| Train/Entropy_loss      | 0.000204       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.4084348      |
| Train/Loss              | 0.044044077    |
| Train/PolicyClip        | -8.9683854e-05 |
| Train/Policy_loss       | 0.03689414     |
| Train/Ratio             | 0.99578476     |
| Train/Return            | 2.7939875      |
| Train/V                 | 2.8259676      |
| Train/Value             | 2.8259676      |
| Train/control_penalty   | 0.6945489      |
| Train/policy_loss       | 0.03689414     |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.07185        |
--------------------------------------------

 ---------------- Iteration 172 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 171           |
| Time/Actor_Time         | 0.498         |
| Time/B_Format_Time      | 0.499         |
| Time/B_Original_Form... | 0.495         |
| Time/Buffer             | 0.0491        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.41321573    |
| Train/Action_magnitu... | 0.8906311     |
| Train/Action_magnitude  | 0.69046366    |
| Train/Action_max        | 0.29045781    |
| Train/Action_std        | 0.20553       |
| Train/Entropy           | -0.21383291   |
| Train/Entropy_Loss      | 0.000214      |
| Train/Entropy_loss      | 0.000214      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.44452295    |
| Train/Loss              | 0.04825601    |
| Train/PolicyClip        | 0.00019013893 |
| Train/Policy_loss       | 0.041132066   |
| Train/Ratio             | 0.9966674     |
| Train/Return            | 2.5915644     |
| Train/V                 | 2.6345975     |
| Train/Value             | 2.6345975     |
| Train/control_penalty   | 0.69101125    |
| Train/policy_loss       | 0.041132066   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0719        |
-------------------------------------------

 ---------------- Iteration 173 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 172            |
| Time/Actor_Time         | 0.651          |
| Time/B_Format_Time      | 0.55           |
| Time/B_Original_Form... | 0.512          |
| Time/Buffer             | 0.0485         |
| Time/Critic_Time        | 1.19e-06       |
| Train/Action_abs_mean   | 0.39605394     |
| Train/Action_magnitu... | 0.86485547     |
| Train/Action_magnitude  | 0.6730346      |
| Train/Action_max        | 0.2968024      |
| Train/Action_std        | 0.20497182     |
| Train/Entropy           | -0.22009578    |
| Train/Entropy_Loss      | 0.00022        |
| Train/Entropy_loss      | 0.00022        |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.4447         |
| Train/Loss              | 0.04632669     |
| Train/PolicyClip        | 0.000110476816 |
| Train/Policy_loss       | 0.03938232     |
| Train/Ratio             | 0.9977844      |
| Train/Return            | 2.455485       |
| Train/V                 | 2.4964662      |
| Train/Value             | 2.4964662      |
| Train/control_penalty   | 0.6724272      |
| Train/policy_loss       | 0.03938232     |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0746         |
--------------------------------------------

 ---------------- Iteration 174 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 173           |
| Time/Actor_Time         | 0.542         |
| Time/B_Format_Time      | 0.528         |
| Time/B_Original_Form... | 0.518         |
| Time/Buffer             | 0.0583        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3781334     |
| Train/Action_magnitu... | 0.83059436    |
| Train/Action_magnitude  | 0.6461761     |
| Train/Action_max        | 0.28573322    |
| Train/Action_std        | 0.19719793    |
| Train/Entropy           | -0.25578946   |
| Train/Entropy_Loss      | 0.000256      |
| Train/Entropy_loss      | 0.000256      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.45188096    |
| Train/Loss              | 0.07818654    |
| Train/PolicyClip        | 0.00086719665 |
| Train/Policy_loss       | 0.07150168    |
| Train/Ratio             | 0.99698484    |
| Train/Return            | 2.4594479     |
| Train/V                 | 2.5266178     |
| Train/Value             | 2.5266178     |
| Train/control_penalty   | 0.6429078     |
| Train/policy_loss       | 0.07150168    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07315       |
-------------------------------------------

 ---------------- Iteration 175 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 174          |
| Time/Actor_Time         | 0.508        |
| Time/B_Format_Time      | 0.486        |
| Time/B_Original_Form... | 0.48         |
| Time/Buffer             | 0.0428       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3649237    |
| Train/Action_magnitu... | 0.80371886   |
| Train/Action_magnitude  | 0.620965     |
| Train/Action_max        | 0.3166949    |
| Train/Action_std        | 0.19549145   |
| Train/Entropy           | -0.26165137  |
| Train/Entropy_Loss      | 0.000262     |
| Train/Entropy_loss      | 0.000262     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.5378411    |
| Train/Loss              | 0.0077585177 |
| Train/PolicyClip        | 0.0010616452 |
| Train/Policy_loss       | 0.0013050244 |
| Train/Ratio             | 1.0004563    |
| Train/Return            | 2.4168847    |
| Train/V                 | 2.4183717    |
| Train/Value             | 2.4183717    |
| Train/control_penalty   | 0.61918426   |
| Train/policy_loss       | 0.0013050244 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07195      |
------------------------------------------

 ---------------- Iteration 176 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 175           |
| Time/Actor_Time         | 0.532         |
| Time/B_Format_Time      | 0.56          |
| Time/B_Original_Form... | 0.565         |
| Time/Buffer             | 0.0505        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36728606    |
| Train/Action_magnitu... | 0.81452763    |
| Train/Action_magnitude  | 0.62856895    |
| Train/Action_max        | 0.32723036    |
| Train/Action_std        | 0.19350412    |
| Train/Entropy           | -0.27166593   |
| Train/Entropy_Loss      | 0.000272      |
| Train/Entropy_loss      | 0.000272      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.52925825    |
| Train/Loss              | -0.026681203  |
| Train/PolicyClip        | 0.00029258622 |
| Train/Policy_loss       | -0.033152808  |
| Train/Ratio             | 1.0007023     |
| Train/Return            | 2.4636195     |
| Train/V                 | 2.4295585     |
| Train/Value             | 2.4295585     |
| Train/control_penalty   | 0.61999375    |
| Train/policy_loss       | -0.033152808  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07335       |
-------------------------------------------

 ---------------- Iteration 177 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 176          |
| Time/Actor_Time         | 0.583        |
| Time/B_Format_Time      | 0.556        |
| Time/B_Original_Form... | 0.552        |
| Time/Buffer             | 0.0355       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3930852    |
| Train/Action_magnitu... | 0.83922684   |
| Train/Action_magnitude  | 0.64731485   |
| Train/Action_max        | 0.31737036   |
| Train/Action_std        | 0.19468847   |
| Train/Entropy           | -0.26118994  |
| Train/Entropy_Loss      | 0.000261     |
| Train/Entropy_loss      | 0.000261     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.47255048   |
| Train/Loss              | -0.05687234  |
| Train/PolicyClip        | 0.0025484366 |
| Train/Policy_loss       | -0.06366266  |
| Train/Ratio             | 1.001923     |
| Train/Return            | 2.671201     |
| Train/V                 | 2.6007357    |
| Train/Value             | 2.6007357    |
| Train/control_penalty   | 0.6529133    |
| Train/policy_loss       | -0.06366266  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07595      |
------------------------------------------

 ---------------- Iteration 178 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 177          |
| Time/Actor_Time         | 0.497        |
| Time/B_Format_Time      | 0.499        |
| Time/B_Original_Form... | 0.504        |
| Time/Buffer             | 0.0401       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3795095    |
| Train/Action_magnitu... | 0.82737684   |
| Train/Action_magnitude  | 0.63838977   |
| Train/Action_max        | 0.3060302    |
| Train/Action_std        | 0.19678728   |
| Train/Entropy           | -0.25475517  |
| Train/Entropy_Loss      | 0.000255     |
| Train/Entropy_loss      | 0.000255     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.5026237    |
| Train/Loss              | -0.06540898  |
| Train/PolicyClip        | 0.0010131841 |
| Train/Policy_loss       | -0.07203545  |
| Train/Ratio             | 0.99889785   |
| Train/Return            | 2.7132406    |
| Train/V                 | 2.6390615    |
| Train/Value             | 2.6390615    |
| Train/control_penalty   | 0.637171     |
| Train/policy_loss       | -0.07203545  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0751       |
------------------------------------------

 ---------------- Iteration 179 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 178           |
| Time/Actor_Time         | 0.447         |
| Time/B_Format_Time      | 0.449         |
| Time/B_Original_Form... | 0.445         |
| Time/Buffer             | 0.0428        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.35060567    |
| Train/Action_magnitu... | 0.7804073     |
| Train/Action_magnitude  | 0.60604954    |
| Train/Action_max        | 0.27266       |
| Train/Action_std        | 0.21098308    |
| Train/Entropy           | -0.18608116   |
| Train/Entropy_Loss      | 0.000186      |
| Train/Entropy_loss      | 0.000186      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.41413805    |
| Train/Loss              | 0.038936272   |
| Train/PolicyClip        | -0.0015419394 |
| Train/Policy_loss       | 0.032676466   |
| Train/Ratio             | 0.99693644    |
| Train/Return            | 2.582785      |
| Train/V                 | 2.6012492     |
| Train/Value             | 2.6012492     |
| Train/control_penalty   | 0.60737234    |
| Train/policy_loss       | 0.032676466   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07405       |
-------------------------------------------

 ---------------- Iteration 180 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 179            |
| Time/Actor_Time         | 0.531          |
| Time/B_Format_Time      | 0.592          |
| Time/B_Original_Form... | 0.5            |
| Time/Buffer             | 0.0423         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.34547526     |
| Train/Action_magnitu... | 0.7654992      |
| Train/Action_magnitude  | 0.59573346     |
| Train/Action_max        | 0.24380341     |
| Train/Action_std        | 0.2162669      |
| Train/Entropy           | -0.15868436    |
| Train/Entropy_Loss      | 0.000159       |
| Train/Entropy_loss      | 0.000159       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.3194775      |
| Train/Loss              | 0.08121118     |
| Train/PolicyClip        | -5.3543805e-05 |
| Train/Policy_loss       | 0.07498857     |
| Train/Ratio             | 0.9963202      |
| Train/Return            | 2.4078276      |
| Train/V                 | 2.4834316      |
| Train/Value             | 2.4834316      |
| Train/control_penalty   | 0.60639334     |
| Train/policy_loss       | 0.07498857     |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0674         |
--------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 181 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 180           |
| Time/Actor_Time         | 0.637         |
| Time/B_Format_Time      | 0.667         |
| Time/B_Original_Form... | 0.657         |
| Time/Buffer             | 0.0421        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.35906607    |
| Train/Action_magnitu... | 0.7864474     |
| Train/Action_magnitude  | 0.6137513     |
| Train/Action_max        | 0.2370007     |
| Train/Action_std        | 0.23663685    |
| Train/Entropy           | -0.061814357  |
| Train/Entropy_Loss      | 6.18e-05      |
| Train/Entropy_loss      | 6.18e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.22140239    |
| Train/Loss              | 0.09488002    |
| Train/PolicyClip        | -0.0019974725 |
| Train/Policy_loss       | 0.08842865    |
| Train/Ratio             | 0.99352306    |
| Train/Return            | 2.4949892     |
| Train/V                 | 2.5766947     |
| Train/Value             | 2.5766947     |
| Train/control_penalty   | 0.638956      |
| Train/policy_loss       | 0.08842865    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.068         |
-------------------------------------------

 ---------------- Iteration 182 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 181          |
| Time/Actor_Time         | 0.537        |
| Time/B_Format_Time      | 0.553        |
| Time/B_Original_Form... | 0.554        |
| Time/Buffer             | 0.0458       |
| Time/Critic_Time        | 1.19e-06     |
| Train/Action_abs_mean   | 0.3758716    |
| Train/Action_magnitu... | 0.8504334    |
| Train/Action_magnitude  | 0.6598539    |
| Train/Action_max        | 0.28859147   |
| Train/Action_std        | 0.23690942   |
| Train/Entropy           | -0.06163367  |
| Train/Entropy_Loss      | 6.16e-05     |
| Train/Entropy_loss      | 6.16e-05     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.11780772   |
| Train/Loss              | 0.03028576   |
| Train/PolicyClip        | 7.711684e-05 |
| Train/Policy_loss       | 0.02361495   |
| Train/Ratio             | 0.9980854    |
| Train/Return            | 2.4187112    |
| Train/V                 | 2.4395432    |
| Train/Value             | 2.4395432    |
| Train/control_penalty   | 0.6609177    |
| Train/policy_loss       | 0.02361495   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06985      |
------------------------------------------

 ---------------- Iteration 183 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 182          |
| Time/Actor_Time         | 0.564        |
| Time/B_Format_Time      | 0.554        |
| Time/B_Original_Form... | 0.554        |
| Time/Buffer             | 0.043        |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39467335   |
| Train/Action_magnitu... | 0.88364697   |
| Train/Action_magnitude  | 0.6841448    |
| Train/Action_max        | 0.31444624   |
| Train/Action_std        | 0.2346073    |
| Train/Entropy           | -0.07453241  |
| Train/Entropy_Loss      | 7.45e-05     |
| Train/Entropy_loss      | 7.45e-05     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.12473819   |
| Train/Loss              | -0.04552022  |
| Train/PolicyClip        | 0.0004184886 |
| Train/Policy_loss       | -0.05244283  |
| Train/Ratio             | 1.0011125    |
| Train/Return            | 2.1188128    |
| Train/V                 | 2.067952     |
| Train/Value             | 2.067952     |
| Train/control_penalty   | 0.68480796   |
| Train/policy_loss       | -0.05244283  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.066        |
------------------------------------------

 ---------------- Iteration 184 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 183          |
| Time/Actor_Time         | 0.534        |
| Time/B_Format_Time      | 0.519        |
| Time/B_Original_Form... | 0.521        |
| Time/Buffer             | 0.0515       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39027715   |
| Train/Action_magnitu... | 0.8748175    |
| Train/Action_magnitude  | 0.67584324   |
| Train/Action_max        | 0.31511605   |
| Train/Action_std        | 0.23144777   |
| Train/Entropy           | -0.09009642  |
| Train/Entropy_Loss      | 9.01e-05     |
| Train/Entropy_loss      | 9.01e-05     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.14661872   |
| Train/Loss              | -0.028805207 |
| Train/PolicyClip        | 5.5946e-05   |
| Train/Policy_loss       | -0.035656963 |
| Train/Ratio             | 1.0005563    |
| Train/Return            | 1.9691195    |
| Train/V                 | 1.9348875    |
| Train/Value             | 1.9348875    |
| Train/control_penalty   | 0.6761659    |
| Train/policy_loss       | -0.035656963 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06315      |
------------------------------------------

 ---------------- Iteration 185 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 184           |
| Time/Actor_Time         | 0.449         |
| Time/B_Format_Time      | 0.44          |
| Time/B_Original_Form... | 0.445         |
| Time/Buffer             | 0.0506        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36580995    |
| Train/Action_magnitu... | 0.83709246    |
| Train/Action_magnitude  | 0.6472221     |
| Train/Action_max        | 0.30238697    |
| Train/Action_std        | 0.241601      |
| Train/Entropy           | -0.038959887  |
| Train/Entropy_Loss      | 3.9e-05       |
| Train/Entropy_loss      | 3.9e-05       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.17132506    |
| Train/Loss              | 0.06714341    |
| Train/PolicyClip        | -0.0004898097 |
| Train/Policy_loss       | 0.060577065   |
| Train/Ratio             | 0.99383163    |
| Train/Return            | 2.0639853     |
| Train/V                 | 2.1254303     |
| Train/Value             | 2.1254303     |
| Train/control_penalty   | 0.6527388     |
| Train/policy_loss       | 0.060577065   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.061         |
-------------------------------------------

 ---------------- Iteration 186 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 185            |
| Time/Actor_Time         | 0.483          |
| Time/B_Format_Time      | 0.459          |
| Time/B_Original_Form... | 0.481          |
| Time/Buffer             | 0.04           |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.37020233     |
| Train/Action_magnitu... | 0.8288547      |
| Train/Action_magnitude  | 0.64160585     |
| Train/Action_max        | 0.30369544     |
| Train/Action_std        | 0.23163396     |
| Train/Entropy           | -0.10385468    |
| Train/Entropy_Loss      | 0.000104       |
| Train/Entropy_loss      | 0.000104       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.22286987     |
| Train/Loss              | 0.062674716    |
| Train/PolicyClip        | -1.0674435e-05 |
| Train/Policy_loss       | 0.056046583    |
| Train/Ratio             | 0.99925476     |
| Train/Return            | 2.147643       |
| Train/V                 | 2.2038085      |
| Train/Value             | 2.2038085      |
| Train/control_penalty   | 0.65242773     |
| Train/policy_loss       | 0.056046583    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.06285        |
--------------------------------------------

 ---------------- Iteration 187 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 186           |
| Time/Actor_Time         | 0.589         |
| Time/B_Format_Time      | 0.627         |
| Time/B_Original_Form... | 0.596         |
| Time/Buffer             | 0.0552        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37959003    |
| Train/Action_magnitu... | 0.86234766    |
| Train/Action_magnitude  | 0.6679859     |
| Train/Action_max        | 0.30870274    |
| Train/Action_std        | 0.22684711    |
| Train/Entropy           | -0.11613099   |
| Train/Entropy_Loss      | 0.000116      |
| Train/Entropy_loss      | 0.000116      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.21527149    |
| Train/Loss              | 0.057993457   |
| Train/PolicyClip        | 3.6437423e-06 |
| Train/Policy_loss       | 0.051235944   |
| Train/Ratio             | 0.99606603    |
| Train/Return            | 2.237296      |
| Train/V                 | 2.2909777     |
| Train/Value             | 2.2909777     |
| Train/control_penalty   | 0.66413796    |
| Train/policy_loss       | 0.051235944   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06175       |
-------------------------------------------

 ---------------- Iteration 188 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 187            |
| Time/Actor_Time         | 0.523          |
| Time/B_Format_Time      | 0.524          |
| Time/B_Original_Form... | 0.517          |
| Time/Buffer             | 0.0369         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.37048253     |
| Train/Action_magnitu... | 0.8483922      |
| Train/Action_magnitude  | 0.6570629      |
| Train/Action_max        | 0.31356594     |
| Train/Action_std        | 0.2341085      |
| Train/Entropy           | -0.08282327    |
| Train/Entropy_Loss      | 8.28e-05       |
| Train/Entropy_loss      | 8.28e-05       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.21643628     |
| Train/Loss              | 0.08203936     |
| Train/PolicyClip        | -0.00054116244 |
| Train/Policy_loss       | 0.0753981      |
| Train/Ratio             | 0.99476814     |
| Train/Return            | 2.4916313      |
| Train/V                 | 2.561154       |
| Train/Value             | 2.561154       |
| Train/control_penalty   | 0.6558444      |
| Train/policy_loss       | 0.0753981      |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.05945        |
--------------------------------------------

 ---------------- Iteration 189 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 188           |
| Time/Actor_Time         | 0.506         |
| Time/B_Format_Time      | 0.502         |
| Time/B_Original_Form... | 0.512         |
| Time/Buffer             | 0.0391        |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.3615691     |
| Train/Action_magnitu... | 0.82711184    |
| Train/Action_magnitude  | 0.6408042     |
| Train/Action_max        | 0.3129997     |
| Train/Action_std        | 0.23648028    |
| Train/Entropy           | -0.06852741   |
| Train/Entropy_Loss      | 6.85e-05      |
| Train/Entropy_loss      | 6.85e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.1525875     |
| Train/Loss              | 0.050981335   |
| Train/PolicyClip        | -0.0006268769 |
| Train/Policy_loss       | 0.04446551    |
| Train/Ratio             | 0.9992169     |
| Train/Return            | 2.3978548     |
| Train/V                 | 2.4418561     |
| Train/Value             | 2.4418561     |
| Train/control_penalty   | 0.6447301     |
| Train/policy_loss       | 0.04446551    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05645       |
-------------------------------------------

 ---------------- Iteration 190 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 189           |
| Time/Actor_Time         | 0.516         |
| Time/B_Format_Time      | 0.546         |
| Time/B_Original_Form... | 0.555         |
| Time/Buffer             | 0.0388        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37446874    |
| Train/Action_magnitu... | 0.85306054    |
| Train/Action_magnitude  | 0.6626498     |
| Train/Action_max        | 0.31853253    |
| Train/Action_std        | 0.24582337    |
| Train/Entropy           | -0.030416565  |
| Train/Entropy_Loss      | 3.04e-05      |
| Train/Entropy_loss      | 3.04e-05      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.082437046   |
| Train/Loss              | 0.021507561   |
| Train/PolicyClip        | 0.00030202954 |
| Train/Policy_loss       | 0.014840796   |
| Train/Ratio             | 0.99791485    |
| Train/Return            | 2.1785433     |
| Train/V                 | 2.195358      |
| Train/Value             | 2.195358      |
| Train/control_penalty   | 0.6636348     |
| Train/policy_loss       | 0.014840796   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05975       |
-------------------------------------------

 ---------------- Iteration 191 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 190          |
| Time/Actor_Time         | 0.562        |
| Time/B_Format_Time      | 0.541        |
| Time/B_Original_Form... | 0.538        |
| Time/Buffer             | 0.0453       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39480215   |
| Train/Action_magnitu... | 0.87898254   |
| Train/Action_magnitude  | 0.6822317    |
| Train/Action_max        | 0.32066265   |
| Train/Action_std        | 0.24069203   |
| Train/Entropy           | -0.048359383 |
| Train/Entropy_Loss      | 4.84e-05     |
| Train/Entropy_loss      | 4.84e-05     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.07772616   |
| Train/Loss              | -0.025800394 |
| Train/PolicyClip        | 0.0005126388 |
| Train/Policy_loss       | -0.032695636 |
| Train/Ratio             | 0.99973184   |
| Train/Return            | 2.0660195    |
| Train/V                 | 2.0340197    |
| Train/Value             | 2.0340197    |
| Train/control_penalty   | 0.68468845   |
| Train/policy_loss       | -0.032695636 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0662       |
------------------------------------------

 ---------------- Iteration 192 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 191            |
| Time/Actor_Time         | 0.518          |
| Time/B_Format_Time      | 0.506          |
| Time/B_Original_Form... | 0.496          |
| Time/Buffer             | 0.0374         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.38271806     |
| Train/Action_magnitu... | 0.86170137     |
| Train/Action_magnitude  | 0.6706873      |
| Train/Action_max        | 0.3061113      |
| Train/Action_std        | 0.22465734     |
| Train/Entropy           | -0.11308727    |
| Train/Entropy_Loss      | 0.000113       |
| Train/Entropy_loss      | 0.000113       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.1639674      |
| Train/Loss              | -0.08325917    |
| Train/PolicyClip        | -0.00036117763 |
| Train/Policy_loss       | -0.09002951    |
| Train/Ratio             | 1.0031555      |
| Train/Return            | 1.970771       |
| Train/V                 | 1.8830199      |
| Train/Value             | 1.8830199      |
| Train/control_penalty   | 0.66572475     |
| Train/policy_loss       | -0.09002951    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0679         |
--------------------------------------------

 ---------------- Iteration 193 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 192           |
| Time/Actor_Time         | 0.517         |
| Time/B_Format_Time      | 0.512         |
| Time/B_Original_Form... | 0.513         |
| Time/Buffer             | 0.0413        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3545972     |
| Train/Action_magnitu... | 0.8034812     |
| Train/Action_magnitude  | 0.62734824    |
| Train/Action_max        | 0.302725      |
| Train/Action_std        | 0.2160416     |
| Train/Entropy           | -0.15743104   |
| Train/Entropy_Loss      | 0.000157      |
| Train/Entropy_loss      | 0.000157      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.23964062    |
| Train/Loss              | -0.108924896  |
| Train/PolicyClip        | 0.00014381079 |
| Train/Policy_loss       | -0.11530459   |
| Train/Ratio             | 1.0022981     |
| Train/Return            | 1.9732721     |
| Train/V                 | 1.8597418     |
| Train/Value             | 1.8597418     |
| Train/control_penalty   | 0.62222606    |
| Train/policy_loss       | -0.11530459   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06775       |
-------------------------------------------

 ---------------- Iteration 194 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 193           |
| Time/Actor_Time         | 0.444         |
| Time/B_Format_Time      | 0.433         |
| Time/B_Original_Form... | 0.429         |
| Time/Buffer             | 0.0513        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36922193    |
| Train/Action_magnitu... | 0.8169585     |
| Train/Action_magnitude  | 0.6383247     |
| Train/Action_max        | 0.2960949     |
| Train/Action_std        | 0.21245274    |
| Train/Entropy           | -0.17990702   |
| Train/Entropy_Loss      | 0.00018       |
| Train/Entropy_loss      | 0.00018       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.2988229     |
| Train/Loss              | -0.08452566   |
| Train/PolicyClip        | 0.00035325947 |
| Train/Policy_loss       | -0.091113195  |
| Train/Ratio             | 1.0005015     |
| Train/Return            | 2.014568      |
| Train/V                 | 1.9235625     |
| Train/Value             | 1.9235625     |
| Train/control_penalty   | 0.64076257    |
| Train/policy_loss       | -0.091113195  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0687        |
-------------------------------------------

 ---------------- Iteration 195 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 194          |
| Time/Actor_Time         | 0.476        |
| Time/B_Format_Time      | 0.453        |
| Time/B_Original_Form... | 0.454        |
| Time/Buffer             | 0.0392       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.35999042   |
| Train/Action_magnitu... | 0.8153619    |
| Train/Action_magnitude  | 0.63722885   |
| Train/Action_max        | 0.28404552   |
| Train/Action_std        | 0.21869639   |
| Train/Entropy           | -0.14903711  |
| Train/Entropy_Loss      | 0.000149     |
| Train/Entropy_loss      | 0.000149     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.26812524   |
| Train/Loss              | -0.06341107  |
| Train/PolicyClip        | 0.0005521019 |
| Train/Policy_loss       | -0.069895774 |
| Train/Ratio             | 1.0016897    |
| Train/Return            | 2.0792043    |
| Train/V                 | 2.0091524    |
| Train/Value             | 2.0091524    |
| Train/control_penalty   | 0.63356686   |
| Train/policy_loss       | -0.069895774 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06875      |
------------------------------------------

 ---------------- Iteration 196 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 195           |
| Time/Actor_Time         | 0.481         |
| Time/B_Format_Time      | 0.509         |
| Time/B_Original_Form... | 0.509         |
| Time/Buffer             | 0.0345        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.35574073    |
| Train/Action_magnitu... | 0.79802835    |
| Train/Action_magnitude  | 0.6230574     |
| Train/Action_max        | 0.27842233    |
| Train/Action_std        | 0.21517608    |
| Train/Entropy           | -0.1663155    |
| Train/Entropy_Loss      | 0.000166      |
| Train/Entropy_loss      | 0.000166      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.26674613    |
| Train/Loss              | -0.041870248  |
| Train/PolicyClip        | 0.00035848413 |
| Train/Policy_loss       | -0.04825835   |
| Train/Ratio             | 1.0008229     |
| Train/Return            | 2.0333593     |
| Train/V                 | 1.9874481     |
| Train/Value             | 1.9874481     |
| Train/control_penalty   | 0.62217873    |
| Train/policy_loss       | -0.04825835   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06585       |
-------------------------------------------

 ---------------- Iteration 197 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 196          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.349        |
| Time/B_Original_Form... | 0.35         |
| Time/Buffer             | 0.023        |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.34754995   |
| Train/Action_magnitu... | 0.78057986   |
| Train/Action_magnitude  | 0.60958606   |
| Train/Action_max        | 0.28068623   |
| Train/Action_std        | 0.2105784    |
| Train/Entropy           | -0.18987493  |
| Train/Entropy_Loss      | 0.00019      |
| Train/Entropy_loss      | 0.00019      |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.29064816   |
| Train/Loss              | -0.026911765 |
| Train/PolicyClip        | 0.0008198203 |
| Train/Policy_loss       | -0.033197116 |
| Train/Ratio             | 1.0028138    |
| Train/Return            | 2.3101523    |
| Train/V                 | 2.2776353    |
| Train/Value             | 2.2776353    |
| Train/control_penalty   | 0.6095476    |
| Train/policy_loss       | -0.033197116 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06875      |
------------------------------------------

 ---------------- Iteration 198 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 197          |
| Time/Actor_Time         | 0.357        |
| Time/B_Format_Time      | 0.347        |
| Time/B_Original_Form... | 0.349        |
| Time/Buffer             | 0.027        |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3466078    |
| Train/Action_magnitu... | 0.77154046   |
| Train/Action_magnitude  | 0.6020242    |
| Train/Action_max        | 0.2816545    |
| Train/Action_std        | 0.20476025   |
| Train/Entropy           | -0.21548213  |
| Train/Entropy_Loss      | 0.000215     |
| Train/Entropy_loss      | 0.000215     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.41130498   |
| Train/Loss              | -0.020305565 |
| Train/PolicyClip        | 0.000841088  |
| Train/Policy_loss       | -0.026504721 |
| Train/Ratio             | 1.0008135    |
| Train/Return            | 2.466353     |
| Train/V                 | 2.4410098    |
| Train/Value             | 2.4410098    |
| Train/control_penalty   | 0.59836745   |
| Train/policy_loss       | -0.026504721 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06945      |
------------------------------------------

 ---------------- Iteration 199 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 198           |
| Time/Actor_Time         | 0.36          |
| Time/B_Format_Time      | 0.362         |
| Time/B_Original_Form... | 0.367         |
| Time/Buffer             | 0.0233        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36067724    |
| Train/Action_magnitu... | 0.7967471     |
| Train/Action_magnitude  | 0.621544      |
| Train/Action_max        | 0.31437746    |
| Train/Action_std        | 0.19988096    |
| Train/Entropy           | -0.24710178   |
| Train/Entropy_Loss      | 0.000247      |
| Train/Entropy_loss      | 0.000247      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.44532686    |
| Train/Loss              | -0.042688727  |
| Train/PolicyClip        | 0.00019772328 |
| Train/Policy_loss       | -0.049082037  |
| Train/Ratio             | 1.0015429     |
| Train/Return            | 2.5894868     |
| Train/V                 | 2.542438      |
| Train/Value             | 2.542438      |
| Train/control_penalty   | 0.6146206     |
| Train/policy_loss       | -0.049082037  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0722        |
-------------------------------------------

 ---------------- Iteration 200 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 199          |
| Time/Actor_Time         | 0.373        |
| Time/B_Format_Time      | 0.363        |
| Time/B_Original_Form... | 0.357        |
| Time/Buffer             | 0.0518       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37123147   |
| Train/Action_magnitu... | 0.81360996   |
| Train/Action_magnitude  | 0.6333475    |
| Train/Action_max        | 0.33025292   |
| Train/Action_std        | 0.1952848    |
| Train/Entropy           | -0.27802455  |
| Train/Entropy_Loss      | 0.000278     |
| Train/Entropy_loss      | 0.000278     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.47541445   |
| Train/Loss              | -0.050423123 |
| Train/PolicyClip        | 0.0011392124 |
| Train/Policy_loss       | -0.056985803 |
| Train/Ratio             | 1.0007015    |
| Train/Return            | 2.450128     |
| Train/V                 | 2.3903031    |
| Train/Value             | 2.3903031    |
| Train/control_penalty   | 0.6284653    |
| Train/policy_loss       | -0.056985803 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07515      |
------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 201 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 200           |
| Time/Actor_Time         | 0.367         |
| Time/B_Format_Time      | 0.359         |
| Time/B_Original_Form... | 0.36          |
| Time/Buffer             | 0.0317        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37007514    |
| Train/Action_magnitu... | 0.817406      |
| Train/Action_magnitude  | 0.63405156    |
| Train/Action_max        | 0.3343106     |
| Train/Action_std        | 0.19228366    |
| Train/Entropy           | -0.3015976    |
| Train/Entropy_Loss      | 0.000302      |
| Train/Entropy_loss      | 0.000302      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.5644214     |
| Train/Loss              | -0.046030015  |
| Train/PolicyClip        | 0.00037898513 |
| Train/Policy_loss       | -0.052625634  |
| Train/Ratio             | 1.0021003     |
| Train/Return            | 2.4092517     |
| Train/V                 | 2.357508      |
| Train/Value             | 2.357508      |
| Train/control_penalty   | 0.6294025     |
| Train/policy_loss       | -0.052625634  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06965       |
-------------------------------------------

 ---------------- Iteration 202 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 201           |
| Time/Actor_Time         | 0.363         |
| Time/B_Format_Time      | 0.313         |
| Time/B_Original_Form... | 0.321         |
| Time/Buffer             | 0.623         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.35813302    |
| Train/Action_magnitu... | 0.7927078     |
| Train/Action_magnitude  | 0.61692       |
| Train/Action_max        | 0.3124598     |
| Train/Action_std        | 0.18467121    |
| Train/Entropy           | -0.33368754   |
| Train/Entropy_Loss      | 0.000334      |
| Train/Entropy_loss      | 0.000334      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.62362343    |
| Train/Loss              | -0.06006142   |
| Train/PolicyClip        | 2.2520238e-05 |
| Train/Policy_loss       | -0.06655375   |
| Train/Ratio             | 1.0029845     |
| Train/Return            | 2.2385054     |
| Train/V                 | 2.1733577     |
| Train/Value             | 2.1733577     |
| Train/control_penalty   | 0.61586404    |
| Train/policy_loss       | -0.06655375   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06875       |
-------------------------------------------

 ---------------- Iteration 203 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 202           |
| Time/Actor_Time         | 0.36          |
| Time/B_Format_Time      | 0.376         |
| Time/B_Original_Form... | 0.369         |
| Time/Buffer             | 0.0253        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36188975    |
| Train/Action_magnitu... | 0.7984486     |
| Train/Action_magnitude  | 0.622349      |
| Train/Action_max        | 0.30950937    |
| Train/Action_std        | 0.18288532    |
| Train/Entropy           | -0.34562287   |
| Train/Entropy_Loss      | 0.000346      |
| Train/Entropy_loss      | 0.000346      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6505458     |
| Train/Loss              | -0.06514987   |
| Train/PolicyClip        | 9.6784206e-05 |
| Train/Policy_loss       | -0.07175484   |
| Train/Ratio             | 1.0014744     |
| Train/Return            | 2.0887167     |
| Train/V                 | 2.0184941     |
| Train/Value             | 2.0184941     |
| Train/control_penalty   | 0.6259348     |
| Train/policy_loss       | -0.07175484   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0653        |
-------------------------------------------

 ---------------- Iteration 204 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 203          |
| Time/Actor_Time         | 0.354        |
| Time/B_Format_Time      | 0.337        |
| Time/B_Original_Form... | 0.333        |
| Time/Buffer             | 0.0303       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37007728   |
| Train/Action_magnitu... | 0.80707455   |
| Train/Action_magnitude  | 0.6326535    |
| Train/Action_max        | 0.28810057   |
| Train/Action_std        | 0.18338121   |
| Train/Entropy           | -0.33886927  |
| Train/Entropy_Loss      | 0.000339     |
| Train/Entropy_loss      | 0.000339     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.6439843    |
| Train/Loss              | -0.04486042  |
| Train/PolicyClip        | 0.0006614091 |
| Train/Policy_loss       | -0.051565204 |
| Train/Ratio             | 1.0009977    |
| Train/Return            | 2.0270514    |
| Train/V                 | 1.9764582    |
| Train/Value             | 1.9764582    |
| Train/control_penalty   | 0.63659143   |
| Train/policy_loss       | -0.051565204 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0679       |
------------------------------------------

 ---------------- Iteration 205 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 204           |
| Time/Actor_Time         | 0.374         |
| Time/B_Format_Time      | 0.349         |
| Time/B_Original_Form... | 0.361         |
| Time/Buffer             | 0.0304        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3670223     |
| Train/Action_magnitu... | 0.80997586    |
| Train/Action_magnitude  | 0.6373866     |
| Train/Action_max        | 0.2817868     |
| Train/Action_std        | 0.18367693    |
| Train/Entropy           | -0.33640757   |
| Train/Entropy_Loss      | 0.000336      |
| Train/Entropy_loss      | 0.000336      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6201338     |
| Train/Loss              | -0.04607738   |
| Train/PolicyClip        | 6.5507826e-05 |
| Train/Policy_loss       | -0.052766174  |
| Train/Ratio             | 1.0010352     |
| Train/Return            | 2.0157876     |
| Train/V                 | 1.9648912     |
| Train/Value             | 1.9648912     |
| Train/control_penalty   | 0.6352384     |
| Train/policy_loss       | -0.052766174  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07005       |
-------------------------------------------

 ---------------- Iteration 206 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 205          |
| Time/Actor_Time         | 0.358        |
| Time/B_Format_Time      | 0.348        |
| Time/B_Original_Form... | 0.36         |
| Time/Buffer             | 0.0349       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37315664   |
| Train/Action_magnitu... | 0.8153244    |
| Train/Action_magnitude  | 0.6418057    |
| Train/Action_max        | 0.2818813    |
| Train/Action_std        | 0.18233162   |
| Train/Entropy           | -0.3471194   |
| Train/Entropy_Loss      | 0.000347     |
| Train/Entropy_loss      | 0.000347     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.64907557   |
| Train/Loss              | -0.054314602 |
| Train/PolicyClip        | 6.640411e-05 |
| Train/Policy_loss       | -0.061084833 |
| Train/Ratio             | 1.0005876    |
| Train/Return            | 1.9820273    |
| Train/V                 | 1.922901     |
| Train/Value             | 1.922901     |
| Train/control_penalty   | 0.64231116   |
| Train/policy_loss       | -0.061084833 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06995      |
------------------------------------------

 ---------------- Iteration 207 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 206           |
| Time/Actor_Time         | 0.359         |
| Time/B_Format_Time      | 0.348         |
| Time/B_Original_Form... | 0.35          |
| Time/Buffer             | 0.0406        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37823614    |
| Train/Action_magnitu... | 0.8242204     |
| Train/Action_magnitude  | 0.64450014    |
| Train/Action_max        | 0.3090682     |
| Train/Action_std        | 0.17709936    |
| Train/Entropy           | -0.3796346    |
| Train/Entropy_Loss      | 0.00038       |
| Train/Entropy_loss      | 0.00038       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6797146     |
| Train/Loss              | -0.083682016  |
| Train/PolicyClip        | 6.7146495e-05 |
| Train/Policy_loss       | -0.090467274  |
| Train/Ratio             | 1.0035458     |
| Train/Return            | 2.015223      |
| Train/V                 | 1.9255552     |
| Train/Value             | 1.9255552     |
| Train/control_penalty   | 0.640562      |
| Train/policy_loss       | -0.090467274  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07245       |
-------------------------------------------

 ---------------- Iteration 208 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 207          |
| Time/Actor_Time         | 0.363        |
| Time/B_Format_Time      | 0.336        |
| Time/B_Original_Form... | 0.345        |
| Time/Buffer             | 0.0637       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.37844053   |
| Train/Action_magnitu... | 0.81593275   |
| Train/Action_magnitude  | 0.6354215    |
| Train/Action_max        | 0.33392665   |
| Train/Action_std        | 0.1756685    |
| Train/Entropy           | -0.39473537  |
| Train/Entropy_Loss      | 0.000395     |
| Train/Entropy_loss      | 0.000395     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.7151299    |
| Train/Loss              | -0.076103725 |
| Train/PolicyClip        | 0.0008574282 |
| Train/Policy_loss       | -0.0828852   |
| Train/Ratio             | 1.0008591    |
| Train/Return            | 2.0429366    |
| Train/V                 | 1.9529641    |
| Train/Value             | 1.9529641    |
| Train/control_penalty   | 0.638674     |
| Train/policy_loss       | -0.0828852   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0736       |
------------------------------------------

 ---------------- Iteration 209 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 208          |
| Time/Actor_Time         | 0.359        |
| Time/B_Format_Time      | 0.339        |
| Time/B_Original_Form... | 0.339        |
| Time/Buffer             | 0.0398       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.36617628   |
| Train/Action_magnitu... | 0.79570067   |
| Train/Action_magnitude  | 0.6214035    |
| Train/Action_max        | 0.35225612   |
| Train/Action_std        | 0.16954829   |
| Train/Entropy           | -0.4338027   |
| Train/Entropy_Loss      | 0.000434     |
| Train/Entropy_loss      | 0.000434     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.7770586    |
| Train/Loss              | -0.071107745 |
| Train/PolicyClip        | 0.0012268818 |
| Train/Policy_loss       | -0.07777886  |
| Train/Ratio             | 0.99869853   |
| Train/Return            | 1.9749056    |
| Train/V                 | 1.8909557    |
| Train/Value             | 1.8909557    |
| Train/control_penalty   | 0.62373155   |
| Train/policy_loss       | -0.07777886  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0715       |
------------------------------------------

 ---------------- Iteration 210 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 209          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.336        |
| Time/B_Original_Form... | 0.342        |
| Time/Buffer             | 0.0291       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37819418   |
| Train/Action_magnitu... | 0.8147672    |
| Train/Action_magnitude  | 0.6345379    |
| Train/Action_max        | 0.3567816    |
| Train/Action_std        | 0.16610886   |
| Train/Entropy           | -0.45994884  |
| Train/Entropy_Loss      | 0.00046      |
| Train/Entropy_loss      | 0.00046      |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.8411942    |
| Train/Loss              | -0.017589081 |
| Train/PolicyClip        | 0.0011503521 |
| Train/Policy_loss       | -0.024419723 |
| Train/Ratio             | 1.0035383    |
| Train/Return            | 1.9499664    |
| Train/V                 | 1.9206855    |
| Train/Value             | 1.9206855    |
| Train/control_penalty   | 0.6370694    |
| Train/policy_loss       | -0.024419723 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0641       |
------------------------------------------

 ---------------- Iteration 211 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 210          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.351        |
| Time/B_Original_Form... | 0.36         |
| Time/Buffer             | 0.0282       |
| Time/Critic_Time        | 1.19e-06     |
| Train/Action_abs_mean   | 0.40485716   |
| Train/Action_magnitu... | 0.85897326   |
| Train/Action_magnitude  | 0.66566604   |
| Train/Action_max        | 0.37095144   |
| Train/Action_std        | 0.16455022   |
| Train/Entropy           | -0.4717362   |
| Train/Entropy_Loss      | 0.000472     |
| Train/Entropy_loss      | 0.000472     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.857478     |
| Train/Loss              | -0.029547837 |
| Train/PolicyClip        | 0.0031774484 |
| Train/Policy_loss       | -0.03673753  |
| Train/Ratio             | 1.0010256    |
| Train/Return            | 2.0641227    |
| Train/V                 | 2.0162501    |
| Train/Value             | 2.0162501    |
| Train/control_penalty   | 0.6717957    |
| Train/policy_loss       | -0.03673753  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0659       |
------------------------------------------

 ---------------- Iteration 212 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 211          |
| Time/Actor_Time         | 0.36         |
| Time/B_Format_Time      | 0.35         |
| Time/B_Original_Form... | 0.362        |
| Time/Buffer             | 0.0302       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.4015887    |
| Train/Action_magnitu... | 0.86419207   |
| Train/Action_magnitude  | 0.6670665    |
| Train/Action_max        | 0.3481376    |
| Train/Action_std        | 0.1637781    |
| Train/Entropy           | -0.471171    |
| Train/Entropy_Loss      | 0.000471     |
| Train/Entropy_loss      | 0.000471     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.8628398    |
| Train/Loss              | -0.025971374 |
| Train/PolicyClip        | 0.0013646826 |
| Train/Policy_loss       | -0.033082776 |
| Train/Ratio             | 1.0033839    |
| Train/Return            | 2.3075101    |
| Train/V                 | 2.2665117    |
| Train/Value             | 2.2665117    |
| Train/control_penalty   | 0.6640231    |
| Train/policy_loss       | -0.033082776 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07365      |
------------------------------------------

 ---------------- Iteration 213 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 212          |
| Time/Actor_Time         | 0.36         |
| Time/B_Format_Time      | 0.349        |
| Time/B_Original_Form... | 0.354        |
| Time/Buffer             | 0.0284       |
| Time/Critic_Time        | 1.19e-06     |
| Train/Action_abs_mean   | 0.37530914   |
| Train/Action_magnitu... | 0.80832237   |
| Train/Action_magnitude  | 0.6259897    |
| Train/Action_max        | 0.29757792   |
| Train/Action_std        | 0.16151616   |
| Train/Entropy           | -0.46752775  |
| Train/Entropy_Loss      | 0.000468     |
| Train/Entropy_loss      | 0.000468     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.89694357   |
| Train/Loss              | -0.018647505 |
| Train/PolicyClip        | 0.0013546733 |
| Train/Policy_loss       | -0.025395077 |
| Train/Ratio             | 0.9992682    |
| Train/Return            | 2.2780116    |
| Train/V                 | 2.2507484    |
| Train/Value             | 2.2507484    |
| Train/control_penalty   | 0.62800443   |
| Train/policy_loss       | -0.025395077 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0756       |
------------------------------------------

 ---------------- Iteration 214 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 213           |
| Time/Actor_Time         | 0.362         |
| Time/B_Format_Time      | 0.352         |
| Time/B_Original_Form... | 0.348         |
| Time/Buffer             | 0.0352        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3650795     |
| Train/Action_magnitu... | 0.78750783    |
| Train/Action_magnitude  | 0.6129442     |
| Train/Action_max        | 0.28914785    |
| Train/Action_std        | 0.1649576     |
| Train/Entropy           | -0.44418314   |
| Train/Entropy_Loss      | 0.000444      |
| Train/Entropy_loss      | 0.000444      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.85939       |
| Train/Loss              | 0.02723631    |
| Train/PolicyClip        | 0.00064447924 |
| Train/Policy_loss       | 0.020644596   |
| Train/Ratio             | 0.99696404    |
| Train/Return            | 2.2108605     |
| Train/V                 | 2.2312973     |
| Train/Value             | 2.2312973     |
| Train/control_penalty   | 0.61475325    |
| Train/policy_loss       | 0.020644596   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07035       |
-------------------------------------------

 ---------------- Iteration 215 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 214           |
| Time/Actor_Time         | 0.364         |
| Time/B_Format_Time      | 0.35          |
| Time/B_Original_Form... | 0.348         |
| Time/Buffer             | 0.0283        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3496155     |
| Train/Action_magnitu... | 0.76221853    |
| Train/Action_magnitude  | 0.59539866    |
| Train/Action_max        | 0.31259233    |
| Train/Action_std        | 0.16646026    |
| Train/Entropy           | -0.4461136    |
| Train/Entropy_Loss      | 0.000446      |
| Train/Entropy_loss      | 0.000446      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.8837406     |
| Train/Loss              | -0.0010450687 |
| Train/PolicyClip        | 0.00048156982 |
| Train/Policy_loss       | -0.007449202  |
| Train/Ratio             | 1.0004791     |
| Train/Return            | 2.0762887     |
| Train/V                 | 2.0703614     |
| Train/Value             | 2.0703614     |
| Train/control_penalty   | 0.59580195    |
| Train/policy_loss       | -0.007449202  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0687        |
-------------------------------------------

 ---------------- Iteration 216 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 215           |
| Time/Actor_Time         | 0.367         |
| Time/B_Format_Time      | 0.354         |
| Time/B_Original_Form... | 0.347         |
| Time/Buffer             | 0.0378        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.35427284    |
| Train/Action_magnitu... | 0.7604666     |
| Train/Action_magnitude  | 0.59381646    |
| Train/Action_max        | 0.32204214    |
| Train/Action_std        | 0.16849321    |
| Train/Entropy           | -0.43797022   |
| Train/Entropy_Loss      | 0.000438      |
| Train/Entropy_loss      | 0.000438      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.88365364    |
| Train/Loss              | 0.05752685    |
| Train/PolicyClip        | 0.00013079714 |
| Train/Policy_loss       | 0.051063463   |
| Train/Ratio             | 0.9963791     |
| Train/Return            | 2.231223      |
| Train/V                 | 2.2835662     |
| Train/Value             | 2.2835662     |
| Train/control_penalty   | 0.6025416     |
| Train/policy_loss       | 0.051063463   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07045       |
-------------------------------------------

 ---------------- Iteration 217 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 216          |
| Time/Actor_Time         | 0.363        |
| Time/B_Format_Time      | 0.337        |
| Time/B_Original_Form... | 0.339        |
| Time/Buffer             | 0.0335       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3503582    |
| Train/Action_magnitu... | 0.7624816    |
| Train/Action_magnitude  | 0.59512043   |
| Train/Action_max        | 0.31556746   |
| Train/Action_std        | 0.16934022   |
| Train/Entropy           | -0.4235933   |
| Train/Entropy_Loss      | 0.000424     |
| Train/Entropy_loss      | 0.000424     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.83334863   |
| Train/Loss              | 0.04530526   |
| Train/PolicyClip        | 0.0006779588 |
| Train/Policy_loss       | 0.03888951   |
| Train/Ratio             | 0.995692     |
| Train/Return            | 2.2013168    |
| Train/V                 | 2.2358115    |
| Train/Value             | 2.2358115    |
| Train/control_penalty   | 0.59921604   |
| Train/policy_loss       | 0.03888951   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07445      |
------------------------------------------

 ---------------- Iteration 218 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 217           |
| Time/Actor_Time         | 0.383         |
| Time/B_Format_Time      | 0.34          |
| Time/B_Original_Form... | 0.339         |
| Time/Buffer             | 0.0316        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3501774     |
| Train/Action_magnitu... | 0.7640671     |
| Train/Action_magnitude  | 0.59775084    |
| Train/Action_max        | 0.29742008    |
| Train/Action_std        | 0.17110798    |
| Train/Entropy           | -0.4147544    |
| Train/Entropy_Loss      | 0.000415      |
| Train/Entropy_loss      | 0.000415      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.78168505    |
| Train/Loss              | -0.0029213098 |
| Train/PolicyClip        | 0.00036231178 |
| Train/Policy_loss       | -0.009330336  |
| Train/Ratio             | 1.0019385     |
| Train/Return            | 2.1771145     |
| Train/V                 | 2.1670082     |
| Train/Value             | 2.1670082     |
| Train/control_penalty   | 0.5994272     |
| Train/policy_loss       | -0.009330336  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0748        |
-------------------------------------------

 ---------------- Iteration 219 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 218           |
| Time/Actor_Time         | 0.364         |
| Time/B_Format_Time      | 0.336         |
| Time/B_Original_Form... | 0.337         |
| Time/Buffer             | 0.0297        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.33818224    |
| Train/Action_magnitu... | 0.74187535    |
| Train/Action_magnitude  | 0.5800202     |
| Train/Action_max        | 0.28231907    |
| Train/Action_std        | 0.1654456     |
| Train/Entropy           | -0.4483228    |
| Train/Entropy_Loss      | 0.000448      |
| Train/Entropy_loss      | 0.000448      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.84778136    |
| Train/Loss              | -0.013259076  |
| Train/PolicyClip        | 0.00049085135 |
| Train/Policy_loss       | -0.01952596   |
| Train/Ratio             | 0.9997914     |
| Train/Return            | 2.1665812     |
| Train/V                 | 2.1485453     |
| Train/Value             | 2.1485453     |
| Train/control_penalty   | 0.5818563     |
| Train/policy_loss       | -0.01952596   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07505       |
-------------------------------------------

 ---------------- Iteration 220 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 219          |
| Time/Actor_Time         | 0.368        |
| Time/B_Format_Time      | 0.358        |
| Time/B_Original_Form... | 0.359        |
| Time/Buffer             | 0.0314       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.32573807   |
| Train/Action_magnitu... | 0.7252115    |
| Train/Action_magnitude  | 0.5694747    |
| Train/Action_max        | 0.2822707    |
| Train/Action_std        | 0.16774708   |
| Train/Entropy           | -0.43090782  |
| Train/Entropy_Loss      | 0.000431     |
| Train/Entropy_loss      | 0.000431     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.8629746    |
| Train/Loss              | -0.011712852 |
| Train/PolicyClip        | 0.0009988141 |
| Train/Policy_loss       | -0.017828137 |
| Train/Ratio             | 0.9997293    |
| Train/Return            | 2.2359042    |
| Train/V                 | 2.2179954    |
| Train/Value             | 2.2179954    |
| Train/control_penalty   | 0.5684377    |
| Train/policy_loss       | -0.017828137 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.074        |
------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 221 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 220           |
| Time/Actor_Time         | 0.367         |
| Time/B_Format_Time      | 0.336         |
| Time/B_Original_Form... | 0.343         |
| Time/Buffer             | 0.0351        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.32849059    |
| Train/Action_magnitu... | 0.72907877    |
| Train/Action_magnitude  | 0.5744837     |
| Train/Action_max        | 0.2899855     |
| Train/Action_std        | 0.16239856    |
| Train/Entropy           | -0.45021766   |
| Train/Entropy_Loss      | 0.00045       |
| Train/Entropy_loss      | 0.00045       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.8390965     |
| Train/Loss              | 0.012352144   |
| Train/PolicyClip        | 0.00077881955 |
| Train/Policy_loss       | 0.006190422   |
| Train/Ratio             | 0.9962337     |
| Train/Return            | 2.2161355     |
| Train/V                 | 2.2175915     |
| Train/Value             | 2.2175915     |
| Train/control_penalty   | 0.5711504     |
| Train/policy_loss       | 0.006190422   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07165       |
-------------------------------------------

 ---------------- Iteration 222 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 221           |
| Time/Actor_Time         | 0.361         |
| Time/B_Format_Time      | 0.347         |
| Time/B_Original_Form... | 0.354         |
| Time/Buffer             | 0.0331        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.34628183    |
| Train/Action_magnitu... | 0.7527452     |
| Train/Action_magnitude  | 0.59249234    |
| Train/Action_max        | 0.2884369     |
| Train/Action_std        | 0.16160053    |
| Train/Entropy           | -0.45549315   |
| Train/Entropy_Loss      | 0.000455      |
| Train/Entropy_loss      | 0.000455      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.898056      |
| Train/Loss              | -0.014366593  |
| Train/PolicyClip        | 0.00045796018 |
| Train/Policy_loss       | -0.020749912  |
| Train/Ratio             | 0.9990918     |
| Train/Return            | 2.0621505     |
| Train/V                 | 2.0413888     |
| Train/Value             | 2.0413888     |
| Train/control_penalty   | 0.5927826     |
| Train/policy_loss       | -0.020749912  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06635       |
-------------------------------------------

 ---------------- Iteration 223 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 222          |
| Time/Actor_Time         | 0.363        |
| Time/B_Format_Time      | 0.342        |
| Time/B_Original_Form... | 0.359        |
| Time/Buffer             | 0.0255       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.34647992   |
| Train/Action_magnitu... | 0.7555544    |
| Train/Action_magnitude  | 0.5913476    |
| Train/Action_max        | 0.2671308    |
| Train/Action_std        | 0.16650341   |
| Train/Entropy           | -0.43168798  |
| Train/Entropy_Loss      | 0.000432     |
| Train/Entropy_loss      | 0.000432     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.81349427   |
| Train/Loss              | -0.02157012  |
| Train/PolicyClip        | 0.0019986061 |
| Train/Policy_loss       | -0.0279031   |
| Train/Ratio             | 1.0015723    |
| Train/Return            | 2.1925833    |
| Train/V                 | 2.1551676    |
| Train/Value             | 2.1551676    |
| Train/control_penalty   | 0.5901293    |
| Train/policy_loss       | -0.0279031   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0689       |
------------------------------------------

 ---------------- Iteration 224 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 223          |
| Time/Actor_Time         | 0.365        |
| Time/B_Format_Time      | 0.337        |
| Time/B_Original_Form... | 0.336        |
| Time/Buffer             | 0.0343       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.34863755   |
| Train/Action_magnitu... | 0.75629      |
| Train/Action_magnitude  | 0.58989847   |
| Train/Action_max        | 0.2528181    |
| Train/Action_std        | 0.17412993   |
| Train/Entropy           | -0.38227946  |
| Train/Entropy_Loss      | 0.000382     |
| Train/Entropy_loss      | 0.000382     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.73108625   |
| Train/Loss              | -0.009984566 |
| Train/PolicyClip        | 0.0025080051 |
| Train/Policy_loss       | -0.016346913 |
| Train/Ratio             | 1.0017139    |
| Train/Return            | 2.2489047    |
| Train/V                 | 2.2194896    |
| Train/Value             | 2.2194896    |
| Train/control_penalty   | 0.59800667   |
| Train/policy_loss       | -0.016346913 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07105      |
------------------------------------------

 ---------------- Iteration 225 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 224          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.343        |
| Time/B_Original_Form... | 0.35         |
| Time/Buffer             | 0.0332       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.3627964    |
| Train/Action_magnitu... | 0.78195614   |
| Train/Action_magnitude  | 0.6096694    |
| Train/Action_max        | 0.26460844   |
| Train/Action_std        | 0.1733793    |
| Train/Entropy           | -0.38273028  |
| Train/Entropy_Loss      | 0.000383     |
| Train/Entropy_loss      | 0.000383     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.7439343    |
| Train/Loss              | -0.007958874 |
| Train/PolicyClip        | 0.0017790834 |
| Train/Policy_loss       | -0.014480766 |
| Train/Ratio             | 0.99864376   |
| Train/Return            | 2.2773926    |
| Train/V                 | 2.258983     |
| Train/Value             | 2.258983     |
| Train/control_penalty   | 0.61391616   |
| Train/policy_loss       | -0.014480766 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0728       |
------------------------------------------

 ---------------- Iteration 226 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 225           |
| Time/Actor_Time         | 0.364         |
| Time/B_Format_Time      | 0.364         |
| Time/B_Original_Form... | 0.356         |
| Time/Buffer             | 0.0307        |
| Time/Critic_Time        | 7.15e-07      |
| Train/Action_abs_mean   | 0.3639704     |
| Train/Action_magnitu... | 0.77918655    |
| Train/Action_magnitude  | 0.60510886    |
| Train/Action_max        | 0.29711163    |
| Train/Action_std        | 0.16715899    |
| Train/Entropy           | -0.41922486   |
| Train/Entropy_Loss      | 0.000419      |
| Train/Entropy_loss      | 0.000419      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.8538832     |
| Train/Loss              | -0.0088973325 |
| Train/PolicyClip        | 0.00033382908 |
| Train/Policy_loss       | -0.015403956  |
| Train/Ratio             | 0.9987727     |
| Train/Return            | 2.2671275     |
| Train/V                 | 2.252489      |
| Train/Value             | 2.252489      |
| Train/control_penalty   | 0.60874       |
| Train/policy_loss       | -0.015403956  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0691        |
-------------------------------------------

 ---------------- Iteration 227 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 226          |
| Time/Actor_Time         | 0.36         |
| Time/B_Format_Time      | 0.351        |
| Time/B_Original_Form... | 0.354        |
| Time/Buffer             | 0.0314       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.35894862   |
| Train/Action_magnitu... | 0.769967     |
| Train/Action_magnitude  | 0.602064     |
| Train/Action_max        | 0.28957546   |
| Train/Action_std        | 0.17248262   |
| Train/Entropy           | -0.38785723  |
| Train/Entropy_Loss      | 0.000388     |
| Train/Entropy_loss      | 0.000388     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.723766     |
| Train/Loss              | 0.046794876  |
| Train/PolicyClip        | 0.0017088036 |
| Train/Policy_loss       | 0.04036683   |
| Train/Ratio             | 0.99406624   |
| Train/Return            | 2.4066846    |
| Train/V                 | 2.4357765    |
| Train/Value             | 2.4357765    |
| Train/control_penalty   | 0.60401875   |
| Train/policy_loss       | 0.04036683   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06885      |
------------------------------------------

 ---------------- Iteration 228 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 227          |
| Time/Actor_Time         | 0.362        |
| Time/B_Format_Time      | 0.351        |
| Time/B_Original_Form... | 0.36         |
| Time/Buffer             | 0.0356       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3353439    |
| Train/Action_magnitu... | 0.7409912    |
| Train/Action_magnitude  | 0.57974195   |
| Train/Action_max        | 0.27190384   |
| Train/Action_std        | 0.17012405   |
| Train/Entropy           | -0.3959901   |
| Train/Entropy_Loss      | 0.000396     |
| Train/Entropy_loss      | 0.000396     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.7914302    |
| Train/Loss              | 0.028683858  |
| Train/PolicyClip        | 0.0005397005 |
| Train/Policy_loss       | 0.022526598  |
| Train/Ratio             | 0.9975838    |
| Train/Return            | 2.5798888    |
| Train/V                 | 2.6028924    |
| Train/Value             | 2.6028924    |
| Train/control_penalty   | 0.57612693   |
| Train/policy_loss       | 0.022526598  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06845      |
------------------------------------------

 ---------------- Iteration 229 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 228           |
| Time/Actor_Time         | 0.364         |
| Time/B_Format_Time      | 0.344         |
| Time/B_Original_Form... | 0.347         |
| Time/Buffer             | 0.0246        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3400927     |
| Train/Action_magnitu... | 0.74361765    |
| Train/Action_magnitude  | 0.5823463     |
| Train/Action_max        | 0.26370883    |
| Train/Action_std        | 0.1789297     |
| Train/Entropy           | -0.34315342   |
| Train/Entropy_Loss      | 0.000343      |
| Train/Entropy_loss      | 0.000343      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.67796403    |
| Train/Loss              | 0.07758984    |
| Train/PolicyClip        | -6.476117e-05 |
| Train/Policy_loss       | 0.071356945   |
| Train/Ratio             | 0.9951716     |
| Train/Return            | 2.6248977     |
| Train/V                 | 2.692772      |
| Train/Value             | 2.692772      |
| Train/control_penalty   | 0.5889743     |
| Train/policy_loss       | 0.071356945   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06935       |
-------------------------------------------

 ---------------- Iteration 230 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 229           |
| Time/Actor_Time         | 0.366         |
| Time/B_Format_Time      | 0.351         |
| Time/B_Original_Form... | 0.348         |
| Time/Buffer             | 0.043         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3621897     |
| Train/Action_magnitu... | 0.7808622     |
| Train/Action_magnitude  | 0.6150953     |
| Train/Action_max        | 0.25124186    |
| Train/Action_std        | 0.18429488    |
| Train/Entropy           | -0.31055588   |
| Train/Entropy_Loss      | 0.000311      |
| Train/Entropy_loss      | 0.000311      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.64340293    |
| Train/Loss              | 0.022966282   |
| Train/PolicyClip        | 0.00068548426 |
| Train/Policy_loss       | 0.016383063   |
| Train/Ratio             | 0.9993949     |
| Train/Return            | 2.3410864     |
| Train/V                 | 2.3572168     |
| Train/Value             | 2.3572168     |
| Train/control_penalty   | 0.62726647    |
| Train/policy_loss       | 0.016383063   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0736        |
-------------------------------------------

 ---------------- Iteration 231 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 230          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.334        |
| Time/B_Original_Form... | 0.332        |
| Time/Buffer             | 0.0375       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37732598   |
| Train/Action_magnitu... | 0.8175552    |
| Train/Action_magnitude  | 0.6399328    |
| Train/Action_max        | 0.29072952   |
| Train/Action_std        | 0.18211834   |
| Train/Entropy           | -0.32055092  |
| Train/Entropy_Loss      | 0.000321     |
| Train/Entropy_loss      | 0.000321     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.5772186    |
| Train/Loss              | -0.009721002 |
| Train/PolicyClip        | 0.0006500415 |
| Train/Policy_loss       | -0.016486298 |
| Train/Ratio             | 0.99860907   |
| Train/Return            | 2.109449     |
| Train/V                 | 2.0934372    |
| Train/Value             | 2.0934372    |
| Train/control_penalty   | 0.6444747    |
| Train/policy_loss       | -0.016486298 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07385      |
------------------------------------------

 ---------------- Iteration 232 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 231           |
| Time/Actor_Time         | 0.362         |
| Time/B_Format_Time      | 0.335         |
| Time/B_Original_Form... | 0.334         |
| Time/Buffer             | 0.0355        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.39377454    |
| Train/Action_magnitu... | 0.8406963     |
| Train/Action_magnitude  | 0.65518147    |
| Train/Action_max        | 0.31035063    |
| Train/Action_std        | 0.18146558    |
| Train/Entropy           | -0.32370567   |
| Train/Entropy_Loss      | 0.000324      |
| Train/Entropy_loss      | 0.000324      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.648881      |
| Train/Loss              | 0.015070206   |
| Train/PolicyClip        | 0.00027942396 |
| Train/Policy_loss       | 0.008148928   |
| Train/Ratio             | 0.9989633     |
| Train/Return            | 2.191232      |
| Train/V                 | 2.2013373     |
| Train/Value             | 2.2013373     |
| Train/control_penalty   | 0.6597572     |
| Train/policy_loss       | 0.008148928   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07405       |
-------------------------------------------

 ---------------- Iteration 233 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 232           |
| Time/Actor_Time         | 0.359         |
| Time/B_Format_Time      | 0.344         |
| Time/B_Original_Form... | 0.35          |
| Time/Buffer             | 0.0289        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.40521783    |
| Train/Action_magnitu... | 0.85723066    |
| Train/Action_magnitude  | 0.6630454     |
| Train/Action_max        | 0.33222896    |
| Train/Action_std        | 0.18477476    |
| Train/Entropy           | -0.30953315   |
| Train/Entropy_Loss      | 0.00031       |
| Train/Entropy_loss      | 0.00031       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6010373     |
| Train/Loss              | 0.023302466   |
| Train/PolicyClip        | 0.00024415064 |
| Train/Policy_loss       | 0.016311487   |
| Train/Ratio             | 0.9984507     |
| Train/Return            | 2.444568      |
| Train/V                 | 2.4625847     |
| Train/Value             | 2.4625847     |
| Train/control_penalty   | 0.6681447     |
| Train/policy_loss       | 0.016311487   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0761        |
-------------------------------------------

 ---------------- Iteration 234 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 233          |
| Time/Actor_Time         | 0.357        |
| Time/B_Format_Time      | 0.349        |
| Time/B_Original_Form... | 0.347        |
| Time/Buffer             | 0.0307       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.41830155   |
| Train/Action_magnitu... | 0.8814518    |
| Train/Action_magnitude  | 0.6773973    |
| Train/Action_max        | 0.33258998   |
| Train/Action_std        | 0.18151627   |
| Train/Entropy           | -0.32653913  |
| Train/Entropy_Loss      | 0.000327     |
| Train/Entropy_loss      | 0.000327     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.61439097   |
| Train/Loss              | 0.015855787  |
| Train/PolicyClip        | 0.0010048184 |
| Train/Policy_loss       | 0.008739204  |
| Train/Ratio             | 0.9977995    |
| Train/Return            | 2.40472      |
| Train/V                 | 2.4120646    |
| Train/Value             | 2.4120646    |
| Train/control_penalty   | 0.6790044    |
| Train/policy_loss       | 0.008739204  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07735      |
------------------------------------------

 ---------------- Iteration 235 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 234          |
| Time/Actor_Time         | 0.358        |
| Time/B_Format_Time      | 0.33         |
| Time/B_Original_Form... | 0.328        |
| Time/Buffer             | 0.0309       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.42521665   |
| Train/Action_magnitu... | 0.8993359    |
| Train/Action_magnitude  | 0.69035476   |
| Train/Action_max        | 0.32629526   |
| Train/Action_std        | 0.17998259   |
| Train/Entropy           | -0.33619383  |
| Train/Entropy_Loss      | 0.000336     |
| Train/Entropy_loss      | 0.000336     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.63810945   |
| Train/Loss              | 0.008026073  |
| Train/PolicyClip        | 4.017144e-05 |
| Train/Policy_loss       | 0.0007939829 |
| Train/Ratio             | 0.99996316   |
| Train/Return            | 2.5194507    |
| Train/V                 | 2.5219092    |
| Train/Value             | 2.5219092    |
| Train/control_penalty   | 0.68958956   |
| Train/policy_loss       | 0.0007939829 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07865      |
------------------------------------------

 ---------------- Iteration 236 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 235          |
| Time/Actor_Time         | 0.363        |
| Time/B_Format_Time      | 0.342        |
| Time/B_Original_Form... | 0.34         |
| Time/Buffer             | 0.0303       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.42461655   |
| Train/Action_magnitu... | 0.89362127   |
| Train/Action_magnitude  | 0.6863007    |
| Train/Action_max        | 0.35717735   |
| Train/Action_std        | 0.18208861   |
| Train/Entropy           | -0.32324156  |
| Train/Entropy_Loss      | 0.000323     |
| Train/Entropy_loss      | 0.000323     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.6678017    |
| Train/Loss              | 0.011595762  |
| Train/PolicyClip        | 0.001363609  |
| Train/Policy_loss       | 0.0043728976 |
| Train/Ratio             | 0.99609023   |
| Train/Return            | 2.3708515    |
| Train/V                 | 2.3722134    |
| Train/Value             | 2.3722134    |
| Train/control_penalty   | 0.6899623    |
| Train/policy_loss       | 0.0043728976 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07435      |
------------------------------------------

 ---------------- Iteration 237 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 236            |
| Time/Actor_Time         | 0.359          |
| Time/B_Format_Time      | 0.343          |
| Time/B_Original_Form... | 0.345          |
| Time/Buffer             | 0.0348         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.41877237     |
| Train/Action_magnitu... | 0.88683516     |
| Train/Action_magnitude  | 0.6860488      |
| Train/Action_max        | 0.35313287     |
| Train/Action_std        | 0.17702974     |
| Train/Entropy           | -0.350251      |
| Train/Entropy_Loss      | 0.00035        |
| Train/Entropy_loss      | 0.00035        |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.73832774     |
| Train/Loss              | 0.040269874    |
| Train/PolicyClip        | -0.00011581838 |
| Train/Policy_loss       | 0.033078533    |
| Train/Ratio             | 0.9962678      |
| Train/Return            | 2.2274215      |
| Train/V                 | 2.2623003      |
| Train/Value             | 2.2623003      |
| Train/control_penalty   | 0.684109       |
| Train/policy_loss       | 0.033078533    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.0691         |
--------------------------------------------

 ---------------- Iteration 238 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 237           |
| Time/Actor_Time         | 0.363         |
| Time/B_Format_Time      | 0.335         |
| Time/B_Original_Form... | 0.34          |
| Time/Buffer             | 0.0316        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.40070233    |
| Train/Action_magnitu... | 0.8562002     |
| Train/Action_magnitude  | 0.6634422     |
| Train/Action_max        | 0.35852396    |
| Train/Action_std        | 0.17589249    |
| Train/Entropy           | -0.35003477   |
| Train/Entropy_Loss      | 0.00035       |
| Train/Entropy_loss      | 0.00035       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.7216523     |
| Train/Loss              | 0.0651166     |
| Train/PolicyClip        | -0.0003033048 |
| Train/Policy_loss       | 0.058119763   |
| Train/Ratio             | 0.9987287     |
| Train/Return            | 2.173054      |
| Train/V                 | 2.2292242     |
| Train/Value             | 2.2292242     |
| Train/control_penalty   | 0.6646799     |
| Train/policy_loss       | 0.058119763   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.065         |
-------------------------------------------

 ---------------- Iteration 239 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 238            |
| Time/Actor_Time         | 0.36           |
| Time/B_Format_Time      | 0.342          |
| Time/B_Original_Form... | 0.345          |
| Time/Buffer             | 0.03           |
| Time/Critic_Time        | 1.19e-06       |
| Train/Action_abs_mean   | 0.3855557      |
| Train/Action_magnitu... | 0.82912713     |
| Train/Action_magnitude  | 0.6462628      |
| Train/Action_max        | 0.35312024     |
| Train/Action_std        | 0.17792955     |
| Train/Entropy           | -0.33888617    |
| Train/Entropy_Loss      | 0.000339       |
| Train/Entropy_loss      | 0.000339       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.7199763      |
| Train/Loss              | 0.049318556    |
| Train/PolicyClip        | -2.2661194e-05 |
| Train/Policy_loss       | 0.042471454    |
| Train/Ratio             | 0.99800086     |
| Train/Return            | 1.9491875      |
| Train/V                 | 1.9930145      |
| Train/Value             | 1.9930145      |
| Train/control_penalty   | 0.65082157     |
| Train/policy_loss       | 0.042471454    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.05805        |
--------------------------------------------

 ---------------- Iteration 240 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 239           |
| Time/Actor_Time         | 0.368         |
| Time/B_Format_Time      | 0.363         |
| Time/B_Original_Form... | 0.359         |
| Time/Buffer             | 0.0339        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.39545873    |
| Train/Action_magnitu... | 0.8379078     |
| Train/Action_magnitude  | 0.65358835    |
| Train/Action_max        | 0.33916575    |
| Train/Action_std        | 0.17753476    |
| Train/Entropy           | -0.3425416    |
| Train/Entropy_Loss      | 0.000343      |
| Train/Entropy_loss      | 0.000343      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.67397726    |
| Train/Loss              | 0.012765698   |
| Train/PolicyClip        | 0.00034046598 |
| Train/Policy_loss       | 0.0058207526  |
| Train/Ratio             | 0.995402      |
| Train/Return            | 1.927731      |
| Train/V                 | 1.9299417     |
| Train/Value             | 1.9299417     |
| Train/control_penalty   | 0.66024035    |
| Train/policy_loss       | 0.0058207526  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06055       |
-------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 241 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 240          |
| Time/Actor_Time         | 0.369        |
| Time/B_Format_Time      | 0.364        |
| Time/B_Original_Form... | 0.356        |
| Time/Buffer             | 0.0332       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37773773   |
| Train/Action_magnitu... | 0.8173789    |
| Train/Action_magnitude  | 0.63901776   |
| Train/Action_max        | 0.32177728   |
| Train/Action_std        | 0.17541045   |
| Train/Entropy           | -0.3525933   |
| Train/Entropy_Loss      | 0.000353     |
| Train/Entropy_loss      | 0.000353     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.67686445   |
| Train/Loss              | -0.024538707 |
| Train/PolicyClip        | 0.0009163001 |
| Train/Policy_loss       | -0.03126882  |
| Train/Ratio             | 1.0004064    |
| Train/Return            | 2.0468628    |
| Train/V                 | 2.0158775    |
| Train/Value             | 2.0158775    |
| Train/control_penalty   | 0.63775206   |
| Train/policy_loss       | -0.03126882  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06395      |
------------------------------------------

 ---------------- Iteration 242 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 241          |
| Time/Actor_Time         | 0.362        |
| Time/B_Format_Time      | 0.348        |
| Time/B_Original_Form... | 0.362        |
| Time/Buffer             | 0.0284       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39450532   |
| Train/Action_magnitu... | 0.84921736   |
| Train/Action_magnitude  | 0.6600377    |
| Train/Action_max        | 0.33042204   |
| Train/Action_std        | 0.17602819   |
| Train/Entropy           | -0.3491875   |
| Train/Entropy_Loss      | 0.000349     |
| Train/Entropy_loss      | 0.000349     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.6499547    |
| Train/Loss              | -0.05289429  |
| Train/PolicyClip        | 0.0016978402 |
| Train/Policy_loss       | -0.05979392  |
| Train/Ratio             | 1.0014079    |
| Train/Return            | 2.085246     |
| Train/V                 | 2.0229745    |
| Train/Value             | 2.0229745    |
| Train/control_penalty   | 0.6550444    |
| Train/policy_loss       | -0.05979392  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06515      |
------------------------------------------

 ---------------- Iteration 243 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 242          |
| Time/Actor_Time         | 0.356        |
| Time/B_Format_Time      | 0.345        |
| Time/B_Original_Form... | 0.348        |
| Time/Buffer             | 0.0257       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.40396354   |
| Train/Action_magnitu... | 0.8608793    |
| Train/Action_magnitude  | 0.6691989    |
| Train/Action_max        | 0.35215455   |
| Train/Action_std        | 0.17634018   |
| Train/Entropy           | -0.35091135  |
| Train/Entropy_Loss      | 0.000351     |
| Train/Entropy_loss      | 0.000351     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.6799742    |
| Train/Loss              | -0.04464914  |
| Train/PolicyClip        | 0.0004920869 |
| Train/Policy_loss       | -0.051715918 |
| Train/Ratio             | 1.0017638    |
| Train/Return            | 2.2110589    |
| Train/V                 | 2.1613376    |
| Train/Value             | 2.1613376    |
| Train/control_penalty   | 0.67158663   |
| Train/policy_loss       | -0.051715918 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06395      |
------------------------------------------

 ---------------- Iteration 244 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 243          |
| Time/Actor_Time         | 0.359        |
| Time/B_Format_Time      | 0.349        |
| Time/B_Original_Form... | 0.354        |
| Time/Buffer             | 0.0286       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.41120556   |
| Train/Action_magnitu... | 0.87052226   |
| Train/Action_magnitude  | 0.6758879    |
| Train/Action_max        | 0.33101088   |
| Train/Action_std        | 0.17336802   |
| Train/Entropy           | -0.3644835   |
| Train/Entropy_Loss      | 0.000364     |
| Train/Entropy_loss      | 0.000364     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.68662596   |
| Train/Loss              | -0.03907591  |
| Train/PolicyClip        | 0.0007528972 |
| Train/Policy_loss       | -0.046194192 |
| Train/Ratio             | 0.99991083   |
| Train/Return            | 2.4084694    |
| Train/V                 | 2.3601136    |
| Train/Value             | 2.3601136    |
| Train/control_penalty   | 0.6753798    |
| Train/policy_loss       | -0.046194192 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06705      |
------------------------------------------

 ---------------- Iteration 245 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 244           |
| Time/Actor_Time         | 0.356         |
| Time/B_Format_Time      | 0.345         |
| Time/B_Original_Form... | 0.348         |
| Time/Buffer             | 0.0211        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3964249     |
| Train/Action_magnitu... | 0.841466      |
| Train/Action_magnitude  | 0.6526538     |
| Train/Action_max        | 0.2934432     |
| Train/Action_std        | 0.16863483    |
| Train/Entropy           | -0.3892866    |
| Train/Entropy_Loss      | 0.000389      |
| Train/Entropy_loss      | 0.000389      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6984686     |
| Train/Loss              | -0.034288038  |
| Train/PolicyClip        | 0.00072973064 |
| Train/Policy_loss       | -0.041243743  |
| Train/Ratio             | 0.9998651     |
| Train/Return            | 2.4397852     |
| Train/V                 | 2.3943172     |
| Train/Value             | 2.3943172     |
| Train/control_penalty   | 0.6566421     |
| Train/policy_loss       | -0.041243743  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0707        |
-------------------------------------------

 ---------------- Iteration 246 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 245          |
| Time/Actor_Time         | 0.358        |
| Time/B_Format_Time      | 0.345        |
| Time/B_Original_Form... | 0.343        |
| Time/Buffer             | 0.0247       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.38048214   |
| Train/Action_magnitu... | 0.82322073   |
| Train/Action_magnitude  | 0.6440074    |
| Train/Action_max        | 0.2546032    |
| Train/Action_std        | 0.16716623   |
| Train/Entropy           | -0.39491224  |
| Train/Entropy_Loss      | 0.000395     |
| Train/Entropy_loss      | 0.000395     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.7189911    |
| Train/Loss              | -0.01782062  |
| Train/PolicyClip        | 0.0022884929 |
| Train/Policy_loss       | -0.02458061  |
| Train/Ratio             | 1.001983     |
| Train/Return            | 2.353157     |
| Train/V                 | 2.3212936    |
| Train/Value             | 2.3212936    |
| Train/control_penalty   | 0.6365078    |
| Train/policy_loss       | -0.02458061  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07065      |
------------------------------------------

 ---------------- Iteration 247 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 246            |
| Time/Actor_Time         | 0.359          |
| Time/B_Format_Time      | 0.356          |
| Time/B_Original_Form... | 0.359          |
| Time/Buffer             | 0.0298         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.38184884     |
| Train/Action_magnitu... | 0.821048       |
| Train/Action_magnitude  | 0.64554465     |
| Train/Action_max        | 0.2614672      |
| Train/Action_std        | 0.1650113      |
| Train/Entropy           | -0.40817335    |
| Train/Entropy_Loss      | 0.000408       |
| Train/Entropy_loss      | 0.000408       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.7775157      |
| Train/Loss              | -0.00048119947 |
| Train/PolicyClip        | 0.00071161473  |
| Train/Policy_loss       | -0.0073012183  |
| Train/Ratio             | 0.9986935      |
| Train/Return            | 2.4132683      |
| Train/V                 | 2.4057207      |
| Train/Value             | 2.4057207      |
| Train/control_penalty   | 0.64118457     |
| Train/policy_loss       | -0.0073012183  |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.06955        |
--------------------------------------------

 ---------------- Iteration 248 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 247           |
| Time/Actor_Time         | 0.355         |
| Time/B_Format_Time      | 0.344         |
| Time/B_Original_Form... | 0.354         |
| Time/Buffer             | 0.0354        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3928229     |
| Train/Action_magnitu... | 0.8384109     |
| Train/Action_magnitude  | 0.66010094    |
| Train/Action_max        | 0.27132738    |
| Train/Action_std        | 0.16592628    |
| Train/Entropy           | -0.40537706   |
| Train/Entropy_Loss      | 0.000405      |
| Train/Entropy_loss      | 0.000405      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.806353      |
| Train/Loss              | -0.006737099  |
| Train/PolicyClip        | 0.00061080506 |
| Train/Policy_loss       | -0.013741517  |
| Train/Ratio             | 0.9998406     |
| Train/Return            | 2.5136056     |
| Train/V                 | 2.5000978     |
| Train/Value             | 2.5000978     |
| Train/control_penalty   | 0.6599042     |
| Train/policy_loss       | -0.013741517  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07075       |
-------------------------------------------

 ---------------- Iteration 249 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 248           |
| Time/Actor_Time         | 0.36          |
| Time/B_Format_Time      | 0.356         |
| Time/B_Original_Form... | 0.358         |
| Time/Buffer             | 0.0322        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4007762     |
| Train/Action_magnitu... | 0.84727305    |
| Train/Action_magnitude  | 0.6613835     |
| Train/Action_max        | 0.2761312     |
| Train/Action_std        | 0.16125631    |
| Train/Entropy           | -0.4390915    |
| Train/Entropy_Loss      | 0.000439      |
| Train/Entropy_loss      | 0.000439      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.80981636    |
| Train/Loss              | -0.008594191  |
| Train/PolicyClip        | 0.00084255723 |
| Train/Policy_loss       | -0.015701782  |
| Train/Ratio             | 0.9993468     |
| Train/Return            | 2.5985026     |
| Train/V                 | 2.5827606     |
| Train/Value             | 2.5827606     |
| Train/control_penalty   | 0.66685       |
| Train/policy_loss       | -0.015701782  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0707        |
-------------------------------------------

 ---------------- Iteration 250 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 249          |
| Time/Actor_Time         | 0.367        |
| Time/B_Format_Time      | 0.343        |
| Time/B_Original_Form... | 0.349        |
| Time/Buffer             | 0.0353       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39145657   |
| Train/Action_magnitu... | 0.8196293    |
| Train/Action_magnitude  | 0.6397762    |
| Train/Action_max        | 0.25810575   |
| Train/Action_std        | 0.16136971   |
| Train/Entropy           | -0.43741947  |
| Train/Entropy_Loss      | 0.000437     |
| Train/Entropy_loss      | 0.000437     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.852742     |
| Train/Loss              | 0.017663065  |
| Train/PolicyClip        | 0.0009027652 |
| Train/Policy_loss       | 0.010724617  |
| Train/Ratio             | 0.9974748    |
| Train/Return            | 2.5170681    |
| Train/V                 | 2.5271595    |
| Train/Value             | 2.5271595    |
| Train/control_penalty   | 0.65010285   |
| Train/policy_loss       | 0.010724617  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0739       |
------------------------------------------

 ---------------- Iteration 251 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 250           |
| Time/Actor_Time         | 0.363         |
| Time/B_Format_Time      | 0.343         |
| Time/B_Original_Form... | 0.338         |
| Time/Buffer             | 0.0449        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3930434     |
| Train/Action_magnitu... | 0.8347373     |
| Train/Action_magnitude  | 0.6475196     |
| Train/Action_max        | 0.2701526     |
| Train/Action_std        | 0.16388726    |
| Train/Entropy           | -0.42111537   |
| Train/Entropy_Loss      | 0.000421      |
| Train/Entropy_loss      | 0.000421      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.8351586     |
| Train/Loss              | 0.0031254564  |
| Train/PolicyClip        | 0.00051414187 |
| Train/Policy_loss       | -0.0037730546 |
| Train/Ratio             | 1.0001873     |
| Train/Return            | 2.5079625     |
| Train/V                 | 2.5057063     |
| Train/Value             | 2.5057063     |
| Train/control_penalty   | 0.6477396     |
| Train/policy_loss       | -0.0037730546 |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0771        |
-------------------------------------------

 ---------------- Iteration 252 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 251          |
| Time/Actor_Time         | 0.358        |
| Time/B_Format_Time      | 0.345        |
| Time/B_Original_Form... | 0.343        |
| Time/Buffer             | 0.035        |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.3961236    |
| Train/Action_magnitu... | 0.8428681    |
| Train/Action_magnitude  | 0.6564786    |
| Train/Action_max        | 0.30258647   |
| Train/Action_std        | 0.16419853   |
| Train/Entropy           | -0.42157075  |
| Train/Entropy_Loss      | 0.000422     |
| Train/Entropy_loss      | 0.000422     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.84328127   |
| Train/Loss              | 0.019900331  |
| Train/PolicyClip        | 0.0002555356 |
| Train/Policy_loss       | 0.01291185   |
| Train/Ratio             | 0.9988229    |
| Train/Return            | 2.390351     |
| Train/V                 | 2.4043872    |
| Train/Value             | 2.4043872    |
| Train/control_penalty   | 0.65669113   |
| Train/policy_loss       | 0.01291185   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.077        |
------------------------------------------

 ---------------- Iteration 253 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 252          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.37         |
| Time/B_Original_Form... | 0.377        |
| Time/Buffer             | 0.0427       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.39585996   |
| Train/Action_magnitu... | 0.8387831    |
| Train/Action_magnitude  | 0.6547251    |
| Train/Action_max        | 0.32003033   |
| Train/Action_std        | 0.1648796    |
| Train/Entropy           | -0.42176434  |
| Train/Entropy_Loss      | 0.000422     |
| Train/Entropy_loss      | 0.000422     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.81667835   |
| Train/Loss              | 0.047194235  |
| Train/PolicyClip        | 0.0003600666 |
| Train/Policy_loss       | 0.040148     |
| Train/Ratio             | 0.9977671    |
| Train/Return            | 2.4373353    |
| Train/V                 | 2.4741714    |
| Train/Value             | 2.4741714    |
| Train/control_penalty   | 0.66244674   |
| Train/policy_loss       | 0.040148     |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07765      |
------------------------------------------

 ---------------- Iteration 254 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 253          |
| Time/Actor_Time         | 0.358        |
| Time/B_Format_Time      | 0.346        |
| Time/B_Original_Form... | 0.349        |
| Time/Buffer             | 0.0282       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37974155   |
| Train/Action_magnitu... | 0.81400806   |
| Train/Action_magnitude  | 0.6379662    |
| Train/Action_max        | 0.31420812   |
| Train/Action_std        | 0.16696885   |
| Train/Entropy           | -0.4119747   |
| Train/Entropy_Loss      | 0.000412     |
| Train/Entropy_loss      | 0.000412     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.7996425    |
| Train/Loss              | -0.024506995 |
| Train/PolicyClip        | 0.0007583479 |
| Train/Policy_loss       | -0.03133511  |
| Train/Ratio             | 0.9995301    |
| Train/Return            | 2.371766     |
| Train/V                 | 2.3411112    |
| Train/Value             | 2.3411112    |
| Train/control_penalty   | 0.64161426   |
| Train/policy_loss       | -0.03133511  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0737       |
------------------------------------------

 ---------------- Iteration 255 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 254          |
| Time/Actor_Time         | 0.354        |
| Time/B_Format_Time      | 0.357        |
| Time/B_Original_Form... | 0.35         |
| Time/Buffer             | 0.0274       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37455925   |
| Train/Action_magnitu... | 0.8094261    |
| Train/Action_magnitude  | 0.63653415   |
| Train/Action_max        | 0.305137     |
| Train/Action_std        | 0.17250012   |
| Train/Entropy           | -0.3839335   |
| Train/Entropy_Loss      | 0.000384     |
| Train/Entropy_loss      | 0.000384     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.7672607    |
| Train/Loss              | 0.036003783  |
| Train/PolicyClip        | 0.0006196242 |
| Train/Policy_loss       | 0.029216327  |
| Train/Ratio             | 0.99673533   |
| Train/Return            | 2.6619668    |
| Train/V                 | 2.6914952    |
| Train/Value             | 2.6914952    |
| Train/control_penalty   | 0.6403521    |
| Train/policy_loss       | 0.029216327  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07425      |
------------------------------------------

 ---------------- Iteration 256 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 255           |
| Time/Actor_Time         | 0.355         |
| Time/B_Format_Time      | 0.343         |
| Time/B_Original_Form... | 0.346         |
| Time/Buffer             | 0.0261        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36671698    |
| Train/Action_magnitu... | 0.80508715    |
| Train/Action_magnitude  | 0.6349042     |
| Train/Action_max        | 0.26855853    |
| Train/Action_std        | 0.16954015    |
| Train/Entropy           | -0.39780092   |
| Train/Entropy_Loss      | 0.000398      |
| Train/Entropy_loss      | 0.000398      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.74535865    |
| Train/Loss              | 0.013953596   |
| Train/PolicyClip        | 0.00059679954 |
| Train/Policy_loss       | 0.0072674286  |
| Train/Ratio             | 0.99874866    |
| Train/Return            | 2.7305553     |
| Train/V                 | 2.7395332     |
| Train/Value             | 2.7395332     |
| Train/control_penalty   | 0.62883675    |
| Train/policy_loss       | 0.0072674286  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07995       |
-------------------------------------------

 ---------------- Iteration 257 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 256          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.339        |
| Time/B_Original_Form... | 0.34         |
| Time/Buffer             | 0.0327       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37024692   |
| Train/Action_magnitu... | 0.79900336   |
| Train/Action_magnitude  | 0.62896824   |
| Train/Action_max        | 0.25723696   |
| Train/Action_std        | 0.17297244   |
| Train/Entropy           | -0.37555417  |
| Train/Entropy_Loss      | 0.000376     |
| Train/Entropy_loss      | 0.000376     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.7459093    |
| Train/Loss              | 0.026337046  |
| Train/PolicyClip        | 0.0008054679 |
| Train/Policy_loss       | 0.01961981   |
| Train/Ratio             | 0.99654704   |
| Train/Return            | 2.8376482    |
| Train/V                 | 2.8588753    |
| Train/Value             | 2.8588753    |
| Train/control_penalty   | 0.6341684    |
| Train/policy_loss       | 0.01961981   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0828       |
------------------------------------------

 ---------------- Iteration 258 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 257          |
| Time/Actor_Time         | 0.36         |
| Time/B_Format_Time      | 0.338        |
| Time/B_Original_Form... | 0.34         |
| Time/Buffer             | 0.0315       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.36436608   |
| Train/Action_magnitu... | 0.7956941    |
| Train/Action_magnitude  | 0.6203259    |
| Train/Action_max        | 0.26592904   |
| Train/Action_std        | 0.16901098   |
| Train/Entropy           | -0.3968545   |
| Train/Entropy_Loss      | 0.000397     |
| Train/Entropy_loss      | 0.000397     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.74257326   |
| Train/Loss              | 0.015671883  |
| Train/PolicyClip        | 0.0012037517 |
| Train/Policy_loss       | 0.0091078095 |
| Train/Ratio             | 1.0001241    |
| Train/Return            | 2.768016     |
| Train/V                 | 2.7759254    |
| Train/Value             | 2.7759254    |
| Train/control_penalty   | 0.61672187   |
| Train/policy_loss       | 0.0091078095 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07805      |
------------------------------------------

 ---------------- Iteration 259 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 258           |
| Time/Actor_Time         | 0.359         |
| Time/B_Format_Time      | 0.341         |
| Time/B_Original_Form... | 0.345         |
| Time/Buffer             | 0.022         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.36282393    |
| Train/Action_magnitu... | 0.7746788     |
| Train/Action_magnitude  | 0.6013155     |
| Train/Action_max        | 0.29222667    |
| Train/Action_std        | 0.1718188     |
| Train/Entropy           | -0.38704357   |
| Train/Entropy_Loss      | 0.000387      |
| Train/Entropy_loss      | 0.000387      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.7811147     |
| Train/Loss              | 0.042214077   |
| Train/PolicyClip        | 0.00089234696 |
| Train/Policy_loss       | 0.0356953     |
| Train/Ratio             | 0.996739      |
| Train/Return            | 2.5887535     |
| Train/V                 | 2.62113       |
| Train/Value             | 2.62113       |
| Train/control_penalty   | 0.6131736     |
| Train/policy_loss       | 0.0356953     |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06805       |
-------------------------------------------

 ---------------- Iteration 260 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 259           |
| Time/Actor_Time         | 0.364         |
| Time/B_Format_Time      | 0.367         |
| Time/B_Original_Form... | 0.372         |
| Time/Buffer             | 0.0257        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.35677955    |
| Train/Action_magnitu... | 0.7793444     |
| Train/Action_magnitude  | 0.6055648     |
| Train/Action_max        | 0.29405254    |
| Train/Action_std        | 0.17341009    |
| Train/Entropy           | -0.37290585   |
| Train/Entropy_Loss      | 0.000373      |
| Train/Entropy_loss      | 0.000373      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.7454462     |
| Train/Loss              | 0.0064476104  |
| Train/PolicyClip        | 0.00052967586 |
| Train/Policy_loss       | 4.0060186e-05 |
| Train/Ratio             | 1.0002736     |
| Train/Return            | 2.357346      |
| Train/V                 | 2.3586202     |
| Train/Value             | 2.3586202     |
| Train/control_penalty   | 0.6034644     |
| Train/policy_loss       | 4.0060186e-05 |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.066         |
-------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 261 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 260           |
| Time/Actor_Time         | 0.367         |
| Time/B_Format_Time      | 0.357         |
| Time/B_Original_Form... | 0.362         |
| Time/Buffer             | 0.0283        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.3746747     |
| Train/Action_magnitu... | 0.8107017     |
| Train/Action_magnitude  | 0.6306302     |
| Train/Action_max        | 0.29913297    |
| Train/Action_std        | 0.1742251     |
| Train/Entropy           | -0.36918268   |
| Train/Entropy_Loss      | 0.000369      |
| Train/Entropy_loss      | 0.000369      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.7234152     |
| Train/Loss              | -0.008270672  |
| Train/PolicyClip        | 0.00027635292 |
| Train/Policy_loss       | -0.01494101   |
| Train/Ratio             | 0.99816465    |
| Train/Return            | 2.0728388     |
| Train/V                 | 2.0596716     |
| Train/Value             | 2.0596716     |
| Train/control_penalty   | 0.63011557    |
| Train/policy_loss       | -0.01494101   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0637        |
-------------------------------------------

 ---------------- Iteration 262 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 261           |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.351         |
| Time/B_Original_Form... | 0.366         |
| Time/Buffer             | 0.0262        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.4003457     |
| Train/Action_magnitu... | 0.8617665     |
| Train/Action_magnitude  | 0.6688074     |
| Train/Action_max        | 0.32334894    |
| Train/Action_std        | 0.1770729     |
| Train/Entropy           | -0.3531423    |
| Train/Entropy_Loss      | 0.000353      |
| Train/Entropy_loss      | 0.000353      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6847878     |
| Train/Loss              | 0.017999616   |
| Train/PolicyClip        | 0.00031828275 |
| Train/Policy_loss       | 0.010978037   |
| Train/Ratio             | 0.9997984     |
| Train/Return            | 1.87022       |
| Train/V                 | 1.8827057     |
| Train/Value             | 1.8827057     |
| Train/control_penalty   | 0.66684365    |
| Train/policy_loss       | 0.010978037   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05925       |
-------------------------------------------

 ---------------- Iteration 263 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 262           |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.349         |
| Time/B_Original_Form... | 0.351         |
| Time/Buffer             | 0.0298        |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.39755       |
| Train/Action_magnitu... | 0.851629      |
| Train/Action_magnitude  | 0.65901107    |
| Train/Action_max        | 0.32036883    |
| Train/Action_std        | 0.17718413    |
| Train/Entropy           | -0.35281685   |
| Train/Entropy_Loss      | 0.000353      |
| Train/Entropy_loss      | 0.000353      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.66243416    |
| Train/Loss              | 0.014103816   |
| Train/PolicyClip        | 0.00035274902 |
| Train/Policy_loss       | 0.0072226166  |
| Train/Ratio             | 0.99919677    |
| Train/Return            | 2.0062618     |
| Train/V                 | 2.015447      |
| Train/Value             | 2.015447      |
| Train/control_penalty   | 0.6528383     |
| Train/policy_loss       | 0.0072226166  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06225       |
-------------------------------------------

 ---------------- Iteration 264 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 263           |
| Time/Actor_Time         | 0.359         |
| Time/B_Format_Time      | 0.35          |
| Time/B_Original_Form... | 0.35          |
| Time/Buffer             | 0.0258        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3727813     |
| Train/Action_magnitu... | 0.80059767    |
| Train/Action_magnitude  | 0.6196473     |
| Train/Action_max        | 0.30312428    |
| Train/Action_std        | 0.17384997    |
| Train/Entropy           | -0.3733848    |
| Train/Entropy_Loss      | 0.000373      |
| Train/Entropy_loss      | 0.000373      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.70748645    |
| Train/Loss              | -0.038749915  |
| Train/PolicyClip        | 0.00010648577 |
| Train/Policy_loss       | -0.045306932  |
| Train/Ratio             | 0.9999921     |
| Train/Return            | 1.9905883     |
| Train/V                 | 1.9471219     |
| Train/Value             | 1.9471219     |
| Train/control_penalty   | 0.6183631     |
| Train/policy_loss       | -0.045306932  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0674        |
-------------------------------------------

 ---------------- Iteration 265 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 264          |
| Time/Actor_Time         | 0.359        |
| Time/B_Format_Time      | 0.344        |
| Time/B_Original_Form... | 0.345        |
| Time/Buffer             | 0.0274       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3643643    |
| Train/Action_magnitu... | 0.78635496   |
| Train/Action_magnitude  | 0.6103137    |
| Train/Action_max        | 0.30340028   |
| Train/Action_std        | 0.17201747   |
| Train/Entropy           | -0.38505137  |
| Train/Entropy_Loss      | 0.000385     |
| Train/Entropy_loss      | 0.000385     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.71838915   |
| Train/Loss              | -0.061453618 |
| Train/PolicyClip        | 0.003700472  |
| Train/Policy_loss       | -0.06795192  |
| Train/Ratio             | 1.0038978    |
| Train/Return            | 2.2115731    |
| Train/V                 | 2.1345828    |
| Train/Value             | 2.1345828    |
| Train/control_penalty   | 0.6113246    |
| Train/policy_loss       | -0.06795192  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07035      |
------------------------------------------

 ---------------- Iteration 266 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 265          |
| Time/Actor_Time         | 0.36         |
| Time/B_Format_Time      | 0.356        |
| Time/B_Original_Form... | 0.361        |
| Time/Buffer             | 0.0268       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.35434055   |
| Train/Action_magnitu... | 0.7781741    |
| Train/Action_magnitude  | 0.60707057   |
| Train/Action_max        | 0.29650372   |
| Train/Action_std        | 0.17113777   |
| Train/Entropy           | -0.39362794  |
| Train/Entropy_Loss      | 0.000394     |
| Train/Entropy_loss      | 0.000394     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.75966763   |
| Train/Loss              | -0.052043386 |
| Train/PolicyClip        | 0.0006022454 |
| Train/Policy_loss       | -0.058444325 |
| Train/Ratio             | 1.0028316    |
| Train/Return            | 2.4784768    |
| Train/V                 | 2.4206965    |
| Train/Value             | 2.4206965    |
| Train/control_penalty   | 0.60073113   |
| Train/policy_loss       | -0.058444325 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07575      |
------------------------------------------

 ---------------- Iteration 267 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 266           |
| Time/Actor_Time         | 0.358         |
| Time/B_Format_Time      | 0.341         |
| Time/B_Original_Form... | 0.343         |
| Time/Buffer             | 0.0296        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.37496886    |
| Train/Action_magnitu... | 0.8121118     |
| Train/Action_magnitude  | 0.6315204     |
| Train/Action_max        | 0.2902645     |
| Train/Action_std        | 0.17681621    |
| Train/Entropy           | -0.3575333    |
| Train/Entropy_Loss      | 0.000358      |
| Train/Entropy_loss      | 0.000358      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.7018523     |
| Train/Loss              | -0.008803273  |
| Train/PolicyClip        | 0.00070616027 |
| Train/Policy_loss       | -0.015455109  |
| Train/Ratio             | 0.99792707    |
| Train/Return            | 2.5818033     |
| Train/V                 | 2.5671747     |
| Train/Value             | 2.5671747     |
| Train/control_penalty   | 0.6294304     |
| Train/policy_loss       | -0.015455109  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07745       |
-------------------------------------------

 ---------------- Iteration 268 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 267           |
| Time/Actor_Time         | 0.359         |
| Time/B_Format_Time      | 0.344         |
| Time/B_Original_Form... | 0.338         |
| Time/Buffer             | 0.0315        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.38962153    |
| Train/Action_magnitu... | 0.8372287     |
| Train/Action_magnitude  | 0.6520906     |
| Train/Action_max        | 0.32573888    |
| Train/Action_std        | 0.17672504    |
| Train/Entropy           | -0.358371     |
| Train/Entropy_Loss      | 0.000358      |
| Train/Entropy_loss      | 0.000358      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.70503235    |
| Train/Loss              | 0.0013629287  |
| Train/PolicyClip        | 0.00040968996 |
| Train/Policy_loss       | -0.005502642  |
| Train/Ratio             | 0.99889463    |
| Train/Return            | 2.2526417     |
| Train/V                 | 2.2484224     |
| Train/Value             | 2.2484224     |
| Train/control_penalty   | 0.65072       |
| Train/policy_loss       | -0.005502642  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0729        |
-------------------------------------------

 ---------------- Iteration 269 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 268          |
| Time/Actor_Time         | 0.362        |
| Time/B_Format_Time      | 0.333        |
| Time/B_Original_Form... | 0.336        |
| Time/Buffer             | 0.0376       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39113408   |
| Train/Action_magnitu... | 0.8455242    |
| Train/Action_magnitude  | 0.65931416   |
| Train/Action_max        | 0.33877867   |
| Train/Action_std        | 0.1692646    |
| Train/Entropy           | -0.40410978  |
| Train/Entropy_Loss      | 0.000404     |
| Train/Entropy_loss      | 0.000404     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.7874503    |
| Train/Loss              | -0.011951953 |
| Train/PolicyClip        | 0.0010108313 |
| Train/Policy_loss       | -0.018883143 |
| Train/Ratio             | 0.9990071    |
| Train/Return            | 2.0419838    |
| Train/V                 | 2.022572     |
| Train/Value             | 2.022572     |
| Train/control_penalty   | 0.65270793   |
| Train/policy_loss       | -0.018883143 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07255      |
------------------------------------------

 ---------------- Iteration 270 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 269          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.34         |
| Time/B_Original_Form... | 0.341        |
| Time/Buffer             | 0.0334       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39194655   |
| Train/Action_magnitu... | 0.828717     |
| Train/Action_magnitude  | 0.6466356    |
| Train/Action_max        | 0.3148227    |
| Train/Action_std        | 0.15974554   |
| Train/Entropy           | -0.46000314  |
| Train/Entropy_Loss      | 0.00046      |
| Train/Entropy_loss      | 0.00046      |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.88590586   |
| Train/Loss              | 0.017514173  |
| Train/PolicyClip        | 0.0011569519 |
| Train/Policy_loss       | 0.01056572   |
| Train/Ratio             | 0.99856883   |
| Train/Return            | 2.2921991    |
| Train/V                 | 2.302215     |
| Train/Value             | 2.302215     |
| Train/control_penalty   | 0.648845     |
| Train/policy_loss       | 0.01056572   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0745       |
------------------------------------------

 ---------------- Iteration 271 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 270          |
| Time/Actor_Time         | 0.358        |
| Time/B_Format_Time      | 0.354        |
| Time/B_Original_Form... | 0.352        |
| Time/Buffer             | 0.0382       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39772397   |
| Train/Action_magnitu... | 0.8354607    |
| Train/Action_magnitude  | 0.65025985   |
| Train/Action_max        | 0.31061324   |
| Train/Action_std        | 0.15957057   |
| Train/Entropy           | -0.4590044   |
| Train/Entropy_Loss      | 0.000459     |
| Train/Entropy_loss      | 0.000459     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.9210225    |
| Train/Loss              | 0.01685797   |
| Train/PolicyClip        | 0.0004927717 |
| Train/Policy_loss       | 0.009844106  |
| Train/Ratio             | 0.9997857    |
| Train/Return            | 2.2425673    |
| Train/V                 | 2.252461     |
| Train/Value             | 2.252461     |
| Train/control_penalty   | 0.6554861    |
| Train/policy_loss       | 0.009844106  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0715       |
------------------------------------------

 ---------------- Iteration 272 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 271          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.336        |
| Time/B_Original_Form... | 0.339        |
| Time/Buffer             | 0.036        |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39718783   |
| Train/Action_magnitu... | 0.82871497   |
| Train/Action_magnitude  | 0.64526886   |
| Train/Action_max        | 0.28960583   |
| Train/Action_std        | 0.16161066   |
| Train/Entropy           | -0.4461464   |
| Train/Entropy_Loss      | 0.000446     |
| Train/Entropy_loss      | 0.000446     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.8843291    |
| Train/Loss              | -0.017335176 |
| Train/PolicyClip        | 0.002574886  |
| Train/Policy_loss       | -0.024362259 |
| Train/Ratio             | 1.0006938    |
| Train/Return            | 2.1448922    |
| Train/V                 | 2.1128013    |
| Train/Value             | 2.1128013    |
| Train/control_penalty   | 0.65809363   |
| Train/policy_loss       | -0.024362259 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0736       |
------------------------------------------

 ---------------- Iteration 273 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 272          |
| Time/Actor_Time         | 0.358        |
| Time/B_Format_Time      | 0.343        |
| Time/B_Original_Form... | 0.34         |
| Time/Buffer             | 0.0301       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.40352196   |
| Train/Action_magnitu... | 0.8536378    |
| Train/Action_magnitude  | 0.66528094   |
| Train/Action_max        | 0.2930479    |
| Train/Action_std        | 0.16482419   |
| Train/Entropy           | -0.42374057  |
| Train/Entropy_Loss      | 0.000424     |
| Train/Entropy_loss      | 0.000424     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.8596407    |
| Train/Loss              | -0.035294242 |
| Train/PolicyClip        | 0.0003831935 |
| Train/Policy_loss       | -0.042367626 |
| Train/Ratio             | 1.0024241    |
| Train/Return            | 2.2263687    |
| Train/V                 | 2.1852028    |
| Train/Value             | 2.1852028    |
| Train/control_penalty   | 0.6649644    |
| Train/policy_loss       | -0.042367626 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07205      |
------------------------------------------

 ---------------- Iteration 274 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 273          |
| Time/Actor_Time         | 0.356        |
| Time/B_Format_Time      | 0.337        |
| Time/B_Original_Form... | 0.338        |
| Time/Buffer             | 0.0275       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.41542384   |
| Train/Action_magnitu... | 0.8680545    |
| Train/Action_magnitude  | 0.6766244    |
| Train/Action_max        | 0.31172296   |
| Train/Action_std        | 0.16196018   |
| Train/Entropy           | -0.4361505   |
| Train/Entropy_Loss      | 0.000436     |
| Train/Entropy_loss      | 0.000436     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.8578709    |
| Train/Loss              | -0.028466273 |
| Train/PolicyClip        | 0.00103575   |
| Train/Policy_loss       | -0.035757966 |
| Train/Ratio             | 1.0002432    |
| Train/Return            | 2.1452036    |
| Train/V                 | 2.1103144    |
| Train/Value             | 2.1103144    |
| Train/control_penalty   | 0.68555444   |
| Train/policy_loss       | -0.035757966 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0678       |
------------------------------------------

 ---------------- Iteration 275 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 274          |
| Time/Actor_Time         | 0.362        |
| Time/B_Format_Time      | 0.354        |
| Time/B_Original_Form... | 0.354        |
| Time/Buffer             | 0.0342       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.41325253   |
| Train/Action_magnitu... | 0.87585217   |
| Train/Action_magnitude  | 0.68258834   |
| Train/Action_max        | 0.30527943   |
| Train/Action_std        | 0.16354524   |
| Train/Entropy           | -0.42846337  |
| Train/Entropy_Loss      | 0.000428     |
| Train/Entropy_loss      | 0.000428     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.853362     |
| Train/Loss              | 0.012590073  |
| Train/PolicyClip        | 0.0007485741 |
| Train/Policy_loss       | 0.0053782677 |
| Train/Ratio             | 0.9982418    |
| Train/Return            | 2.222846     |
| Train/V                 | 2.2299874    |
| Train/Value             | 2.2299874    |
| Train/control_penalty   | 0.67833424   |
| Train/policy_loss       | 0.0053782677 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06735      |
------------------------------------------

 ---------------- Iteration 276 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 275          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.348        |
| Time/B_Original_Form... | 0.349        |
| Time/Buffer             | 0.0278       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.42331573   |
| Train/Action_magnitu... | 0.88186574   |
| Train/Action_magnitude  | 0.6862934    |
| Train/Action_max        | 0.30288568   |
| Train/Action_std        | 0.16331443   |
| Train/Entropy           | -0.4249498   |
| Train/Entropy_Loss      | 0.000425     |
| Train/Entropy_loss      | 0.000425     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.85071707   |
| Train/Loss              | 0.0155389905 |
| Train/PolicyClip        | 0.0018268211 |
| Train/Policy_loss       | 0.008199013  |
| Train/Ratio             | 1.0002986    |
| Train/Return            | 2.1807585    |
| Train/V                 | 2.1888232    |
| Train/Value             | 2.1888232    |
| Train/control_penalty   | 0.6915028    |
| Train/policy_loss       | 0.008199013  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0652       |
------------------------------------------

 ---------------- Iteration 277 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 276           |
| Time/Actor_Time         | 0.358         |
| Time/B_Format_Time      | 0.347         |
| Time/B_Original_Form... | 0.351         |
| Time/Buffer             | 0.034         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.41894004    |
| Train/Action_magnitu... | 0.87370706    |
| Train/Action_magnitude  | 0.68087316    |
| Train/Action_max        | 0.29586473    |
| Train/Action_std        | 0.16471605    |
| Train/Entropy           | -0.4162747    |
| Train/Entropy_Loss      | 0.000416      |
| Train/Entropy_loss      | 0.000416      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.85034627    |
| Train/Loss              | 0.014737524   |
| Train/PolicyClip        | 0.00069721276 |
| Train/Policy_loss       | 0.007439108   |
| Train/Ratio             | 0.99968624    |
| Train/Return            | 2.3126907     |
| Train/V                 | 2.3213172     |
| Train/Value             | 2.3213172     |
| Train/control_penalty   | 0.6882142     |
| Train/policy_loss       | 0.007439108   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0676        |
-------------------------------------------

 ---------------- Iteration 278 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 277          |
| Time/Actor_Time         | 0.359        |
| Time/B_Format_Time      | 0.341        |
| Time/B_Original_Form... | 0.35         |
| Time/Buffer             | 0.0293       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3976059    |
| Train/Action_magnitu... | 0.8453863    |
| Train/Action_magnitude  | 0.6609528    |
| Train/Action_max        | 0.29832503   |
| Train/Action_std        | 0.1634377    |
| Train/Entropy           | -0.42447275  |
| Train/Entropy_Loss      | 0.000424     |
| Train/Entropy_loss      | 0.000424     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.8212046    |
| Train/Loss              | -0.002268407 |
| Train/PolicyClip        | 0.0007443023 |
| Train/Policy_loss       | -0.009289187 |
| Train/Ratio             | 1.0008819    |
| Train/Return            | 2.2128496    |
| Train/V                 | 2.2022543    |
| Train/Value             | 2.2022543    |
| Train/control_penalty   | 0.6596308    |
| Train/policy_loss       | -0.009289187 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07095      |
------------------------------------------

 ---------------- Iteration 279 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 278          |
| Time/Actor_Time         | 0.356        |
| Time/B_Format_Time      | 0.34         |
| Time/B_Original_Form... | 0.341        |
| Time/Buffer             | 0.0333       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.38044295   |
| Train/Action_magnitu... | 0.81270933   |
| Train/Action_magnitude  | 0.63660395   |
| Train/Action_max        | 0.28586423   |
| Train/Action_std        | 0.15888517   |
| Train/Entropy           | -0.45080099  |
| Train/Entropy_Loss      | 0.000451     |
| Train/Entropy_loss      | 0.000451     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.85147053   |
| Train/Loss              | -0.01076179  |
| Train/PolicyClip        | 0.0010998703 |
| Train/Policy_loss       | -0.017538933 |
| Train/Ratio             | 1.0016676    |
| Train/Return            | 2.1398814    |
| Train/V                 | 2.1215568    |
| Train/Value             | 2.1215568    |
| Train/control_penalty   | 0.6326343    |
| Train/policy_loss       | -0.017538933 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0761       |
------------------------------------------

 ---------------- Iteration 280 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 279           |
| Time/Actor_Time         | 0.377         |
| Time/B_Format_Time      | 0.356         |
| Time/B_Original_Form... | 0.359         |
| Time/Buffer             | 0.0382        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37312773    |
| Train/Action_magnitu... | 0.8059686     |
| Train/Action_magnitude  | 0.6311179     |
| Train/Action_max        | 0.27973822    |
| Train/Action_std        | 0.1567811     |
| Train/Entropy           | -0.46223575   |
| Train/Entropy_Loss      | 0.000462      |
| Train/Entropy_loss      | 0.000462      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.88181025    |
| Train/Loss              | 0.0060684616  |
| Train/PolicyClip        | 0.0008593006  |
| Train/Policy_loss       | -0.0006247895 |
| Train/Ratio             | 0.9968555     |
| Train/Return            | 2.0496757     |
| Train/V                 | 2.0443623     |
| Train/Value             | 2.0443623     |
| Train/control_penalty   | 0.62310153    |
| Train/policy_loss       | -0.0006247895 |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0765        |
-------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 281 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 280          |
| Time/Actor_Time         | 0.369        |
| Time/B_Format_Time      | 0.347        |
| Time/B_Original_Form... | 0.349        |
| Time/Buffer             | 0.0372       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3855796    |
| Train/Action_magnitu... | 0.8113551    |
| Train/Action_magnitude  | 0.6346746    |
| Train/Action_max        | 0.28702164   |
| Train/Action_std        | 0.1539486    |
| Train/Entropy           | -0.48687568  |
| Train/Entropy_Loss      | 0.000487     |
| Train/Entropy_loss      | 0.000487     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.9168554    |
| Train/Loss              | -0.007382067 |
| Train/PolicyClip        | 0.0009081742 |
| Train/Policy_loss       | -0.014248011 |
| Train/Ratio             | 1.0009203    |
| Train/Return            | 2.0247655    |
| Train/V                 | 2.0087798    |
| Train/Value             | 2.0087798    |
| Train/control_penalty   | 0.6379068    |
| Train/policy_loss       | -0.014248011 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07515      |
------------------------------------------

 ---------------- Iteration 282 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 281           |
| Time/Actor_Time         | 0.36          |
| Time/B_Format_Time      | 0.341         |
| Time/B_Original_Form... | 0.344         |
| Time/Buffer             | 0.0349        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3881977     |
| Train/Action_magnitu... | 0.8185948     |
| Train/Action_magnitude  | 0.6380401     |
| Train/Action_max        | 0.3015762     |
| Train/Action_std        | 0.15604779    |
| Train/Entropy           | -0.4768321    |
| Train/Entropy_Loss      | 0.000477      |
| Train/Entropy_loss      | 0.000477      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.89795095    |
| Train/Loss              | -0.0013205879 |
| Train/PolicyClip        | 0.0012734318  |
| Train/Policy_loss       | -0.008204184  |
| Train/Ratio             | 0.99867374    |
| Train/Return            | 2.1889396     |
| Train/V                 | 2.1758423     |
| Train/Value             | 2.1758423     |
| Train/control_penalty   | 0.6406764     |
| Train/policy_loss       | -0.008204184  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07275       |
-------------------------------------------

 ---------------- Iteration 283 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 282           |
| Time/Actor_Time         | 0.361         |
| Time/B_Format_Time      | 0.336         |
| Time/B_Original_Form... | 0.346         |
| Time/Buffer             | 0.0295        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3894153     |
| Train/Action_magnitu... | 0.8217189     |
| Train/Action_magnitude  | 0.6386042     |
| Train/Action_max        | 0.2749189     |
| Train/Action_std        | 0.15624651    |
| Train/Entropy           | -0.47346193   |
| Train/Entropy_Loss      | 0.000473      |
| Train/Entropy_loss      | 0.000473      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.8890917     |
| Train/Loss              | -0.037435766  |
| Train/PolicyClip        | 0.00084905187 |
| Train/Policy_loss       | -0.044317454  |
| Train/Ratio             | 0.99868995    |
| Train/Return            | 2.4729073     |
| Train/V                 | 2.4283352     |
| Train/Value             | 2.4283352     |
| Train/control_penalty   | 0.6408225     |
| Train/policy_loss       | -0.044317454  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0751        |
-------------------------------------------

 ---------------- Iteration 284 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 283           |
| Time/Actor_Time         | 0.36          |
| Time/B_Format_Time      | 0.341         |
| Time/B_Original_Form... | 0.341         |
| Time/Buffer             | 0.0307        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.38625205    |
| Train/Action_magnitu... | 0.8207064     |
| Train/Action_magnitude  | 0.638408      |
| Train/Action_max        | 0.28726026    |
| Train/Action_std        | 0.15475875    |
| Train/Entropy           | -0.48212785   |
| Train/Entropy_Loss      | 0.000482      |
| Train/Entropy_loss      | 0.000482      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.9076512     |
| Train/Loss              | -0.0109227095 |
| Train/PolicyClip        | 0.00067752827 |
| Train/Policy_loss       | -0.017765936  |
| Train/Ratio             | 0.99841464    |
| Train/Return            | 2.7007058     |
| Train/V                 | 2.685311      |
| Train/Value             | 2.685311      |
| Train/control_penalty   | 0.6361099     |
| Train/policy_loss       | -0.017765936  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0791        |
-------------------------------------------

 ---------------- Iteration 285 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 284          |
| Time/Actor_Time         | 0.361        |
| Time/B_Format_Time      | 0.333        |
| Time/B_Original_Form... | 0.33         |
| Time/Buffer             | 0.0309       |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.3942721    |
| Train/Action_magnitu... | 0.8291328    |
| Train/Action_magnitude  | 0.64763194   |
| Train/Action_max        | 0.31048113   |
| Train/Action_std        | 0.16101503   |
| Train/Entropy           | -0.45327216  |
| Train/Entropy_Loss      | 0.000453     |
| Train/Entropy_loss      | 0.000453     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.87759817   |
| Train/Loss              | -0.017922483 |
| Train/PolicyClip        | 0.0011440979 |
| Train/Policy_loss       | -0.024924189 |
| Train/Ratio             | 0.999877     |
| Train/Return            | 2.61021      |
| Train/V                 | 2.585234     |
| Train/Value             | 2.585234     |
| Train/control_penalty   | 0.6548432    |
| Train/policy_loss       | -0.024924189 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07895      |
------------------------------------------

 ---------------- Iteration 286 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 285            |
| Time/Actor_Time         | 0.357          |
| Time/B_Format_Time      | 0.33           |
| Time/B_Original_Form... | 0.336          |
| Time/Buffer             | 0.0274         |
| Time/Critic_Time        | 1.19e-06       |
| Train/Action_abs_mean   | 0.40158358     |
| Train/Action_magnitu... | 0.8462858      |
| Train/Action_magnitude  | 0.6633988      |
| Train/Action_max        | 0.33720365     |
| Train/Action_std        | 0.16663979     |
| Train/Entropy           | -0.42823842    |
| Train/Entropy_Loss      | 0.000428       |
| Train/Entropy_loss      | 0.000428       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.8491961      |
| Train/Loss              | 0.006749909    |
| Train/PolicyClip        | 0.00066068256  |
| Train/Policy_loss       | -0.00036668772 |
| Train/Ratio             | 0.9995974      |
| Train/Return            | 2.407549       |
| Train/V                 | 2.4085283      |
| Train/Value             | 2.4085283      |
| Train/control_penalty   | 0.6688358      |
| Train/policy_loss       | -0.00036668772 |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.07585        |
--------------------------------------------

 ---------------- Iteration 287 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 286           |
| Time/Actor_Time         | 0.355         |
| Time/B_Format_Time      | 0.331         |
| Time/B_Original_Form... | 0.334         |
| Time/Buffer             | 0.027         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.41983882    |
| Train/Action_magnitu... | 0.88710165    |
| Train/Action_magnitude  | 0.68980736    |
| Train/Action_max        | 0.33302566    |
| Train/Action_std        | 0.16572891    |
| Train/Entropy           | -0.42632645   |
| Train/Entropy_Loss      | 0.000426      |
| Train/Entropy_loss      | 0.000426      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.82188994    |
| Train/Loss              | 0.035859834   |
| Train/PolicyClip        | 0.00024677638 |
| Train/Policy_loss       | 0.028558085   |
| Train/Ratio             | 0.99846923    |
| Train/Return            | 2.185699      |
| Train/V                 | 2.2165399     |
| Train/Value             | 2.2165399     |
| Train/control_penalty   | 0.6875424     |
| Train/policy_loss       | 0.028558085   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0715        |
-------------------------------------------

 ---------------- Iteration 288 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 287           |
| Time/Actor_Time         | 0.363         |
| Time/B_Format_Time      | 0.344         |
| Time/B_Original_Form... | 0.343         |
| Time/Buffer             | 0.0267        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.41750142    |
| Train/Action_magnitu... | 0.8796384     |
| Train/Action_magnitude  | 0.68344504    |
| Train/Action_max        | 0.28133792    |
| Train/Action_std        | 0.1623491     |
| Train/Entropy           | -0.42966568   |
| Train/Entropy_Loss      | 0.00043       |
| Train/Entropy_loss      | 0.00043       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.83576995    |
| Train/Loss              | 0.053581208   |
| Train/PolicyClip        | 0.00038370784 |
| Train/Policy_loss       | 0.046362758   |
| Train/Ratio             | 0.99556077    |
| Train/Return            | 2.21406       |
| Train/V                 | 2.2571871     |
| Train/Value             | 2.2571871     |
| Train/control_penalty   | 0.6788784     |
| Train/policy_loss       | 0.046362758   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07075       |
-------------------------------------------

 ---------------- Iteration 289 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 288           |
| Time/Actor_Time         | 0.363         |
| Time/B_Format_Time      | 0.337         |
| Time/B_Original_Form... | 0.338         |
| Time/Buffer             | 0.03          |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.40796608    |
| Train/Action_magnitu... | 0.8549904     |
| Train/Action_magnitude  | 0.6652971     |
| Train/Action_max        | 0.25497574    |
| Train/Action_std        | 0.16064484    |
| Train/Entropy           | -0.4393742    |
| Train/Entropy_Loss      | 0.000439      |
| Train/Entropy_loss      | 0.000439      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.88245106    |
| Train/Loss              | 0.019342698   |
| Train/PolicyClip        | 0.00020092768 |
| Train/Policy_loss       | 0.012222365   |
| Train/Ratio             | 0.99772304    |
| Train/Return            | 2.3474689     |
| Train/V                 | 2.3613243     |
| Train/Value             | 2.3613243     |
| Train/control_penalty   | 0.66809595    |
| Train/policy_loss       | 0.012222365   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0735        |
-------------------------------------------

 ---------------- Iteration 290 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 289           |
| Time/Actor_Time         | 0.361         |
| Time/B_Format_Time      | 0.355         |
| Time/B_Original_Form... | 0.359         |
| Time/Buffer             | 0.0305        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4203921     |
| Train/Action_magnitu... | 0.88348067    |
| Train/Action_magnitude  | 0.6872254     |
| Train/Action_max        | 0.29787323    |
| Train/Action_std        | 0.15891048    |
| Train/Entropy           | -0.4512166    |
| Train/Entropy_Loss      | 0.000451      |
| Train/Entropy_loss      | 0.000451      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.88243425    |
| Train/Loss              | 0.015572132   |
| Train/PolicyClip        | 0.00041413054 |
| Train/Policy_loss       | 0.00826189    |
| Train/Ratio             | 0.99989736    |
| Train/Return            | 2.4496088     |
| Train/V                 | 2.4597318     |
| Train/Value             | 2.4597318     |
| Train/control_penalty   | 0.68590254    |
| Train/policy_loss       | 0.00826189    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0712        |
-------------------------------------------

 ---------------- Iteration 291 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 290           |
| Time/Actor_Time         | 0.434         |
| Time/B_Format_Time      | 0.359         |
| Time/B_Original_Form... | 0.36          |
| Time/Buffer             | 0.0326        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4249956     |
| Train/Action_magnitu... | 0.89649403    |
| Train/Action_magnitude  | 0.70138854    |
| Train/Action_max        | 0.34168828    |
| Train/Action_std        | 0.1603959     |
| Train/Entropy           | -0.4514685    |
| Train/Entropy_Loss      | 0.000451      |
| Train/Entropy_loss      | 0.000451      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.89678997    |
| Train/Loss              | 0.016019683   |
| Train/PolicyClip        | 0.00038246947 |
| Train/Policy_loss       | 0.008581896   |
| Train/Ratio             | 0.9957857     |
| Train/Return            | 2.5636342     |
| Train/V                 | 2.5744846     |
| Train/Value             | 2.5744846     |
| Train/control_penalty   | 0.69863176    |
| Train/policy_loss       | 0.008581896   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07185       |
-------------------------------------------

 ---------------- Iteration 292 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 291           |
| Time/Actor_Time         | 0.361         |
| Time/B_Format_Time      | 0.362         |
| Time/B_Original_Form... | 0.354         |
| Time/Buffer             | 0.029         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.42345732    |
| Train/Action_magnitu... | 0.89587206    |
| Train/Action_magnitude  | 0.700593      |
| Train/Action_max        | 0.35760474    |
| Train/Action_std        | 0.16659835    |
| Train/Entropy           | -0.42409706   |
| Train/Entropy_Loss      | 0.000424      |
| Train/Entropy_loss      | 0.000424      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.8409958     |
| Train/Loss              | -0.006573111  |
| Train/PolicyClip        | 0.00072806585 |
| Train/Policy_loss       | -0.01400576   |
| Train/Ratio             | 0.9992347     |
| Train/Return            | 2.5380425     |
| Train/V                 | 2.5253308     |
| Train/Value             | 2.5253308     |
| Train/control_penalty   | 0.7008552     |
| Train/policy_loss       | -0.01400576   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07335       |
-------------------------------------------

 ---------------- Iteration 293 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 292           |
| Time/Actor_Time         | 0.361         |
| Time/B_Format_Time      | 0.349         |
| Time/B_Original_Form... | 0.35          |
| Time/Buffer             | 0.0306        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.41796347    |
| Train/Action_magnitu... | 0.8843838     |
| Train/Action_magnitude  | 0.69097483    |
| Train/Action_max        | 0.33778942    |
| Train/Action_std        | 0.16915733    |
| Train/Entropy           | -0.40929538   |
| Train/Entropy_Loss      | 0.000409      |
| Train/Entropy_loss      | 0.000409      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.8216949     |
| Train/Loss              | 0.016581174   |
| Train/PolicyClip        | 0.00094529265 |
| Train/Policy_loss       | 0.009267671   |
| Train/Ratio             | 0.9977842     |
| Train/Return            | 2.5853076     |
| Train/V                 | 2.5944982     |
| Train/Value             | 2.5944982     |
| Train/control_penalty   | 0.6904206     |
| Train/policy_loss       | 0.009267671   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0747        |
-------------------------------------------

 ---------------- Iteration 294 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 293          |
| Time/Actor_Time         | 0.357        |
| Time/B_Format_Time      | 0.353        |
| Time/B_Original_Form... | 0.355        |
| Time/Buffer             | 0.0372       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.41990146   |
| Train/Action_magnitu... | 0.88092023   |
| Train/Action_magnitude  | 0.6866274    |
| Train/Action_max        | 0.323555     |
| Train/Action_std        | 0.1736437    |
| Train/Entropy           | -0.3821926   |
| Train/Entropy_Loss      | 0.000382     |
| Train/Entropy_loss      | 0.000382     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.76370305   |
| Train/Loss              | 0.013082475  |
| Train/PolicyClip        | 0.0013041685 |
| Train/Policy_loss       | 0.005791148  |
| Train/Ratio             | 0.9973695    |
| Train/Return            | 2.397254     |
| Train/V                 | 2.4038975    |
| Train/Value             | 2.4038975    |
| Train/control_penalty   | 0.6909135    |
| Train/policy_loss       | 0.005791148  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07255      |
------------------------------------------

 ---------------- Iteration 295 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 294          |
| Time/Actor_Time         | 0.359        |
| Time/B_Format_Time      | 0.339        |
| Time/B_Original_Form... | 0.343        |
| Time/Buffer             | 0.0332       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.41606787   |
| Train/Action_magnitu... | 0.8736441    |
| Train/Action_magnitude  | 0.6786511    |
| Train/Action_max        | 0.3051387    |
| Train/Action_std        | 0.16668583   |
| Train/Entropy           | -0.41409966  |
| Train/Entropy_Loss      | 0.000414     |
| Train/Entropy_loss      | 0.000414     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.7587543    |
| Train/Loss              | -0.027715443 |
| Train/PolicyClip        | 0.0017533287 |
| Train/Policy_loss       | -0.034908645 |
| Train/Ratio             | 1.0029243    |
| Train/Return            | 2.2554796    |
| Train/V                 | 2.2166874    |
| Train/Value             | 2.2166874    |
| Train/control_penalty   | 0.67791027   |
| Train/policy_loss       | -0.034908645 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0702       |
------------------------------------------

 ---------------- Iteration 296 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 295           |
| Time/Actor_Time         | 0.358         |
| Time/B_Format_Time      | 0.351         |
| Time/B_Original_Form... | 0.348         |
| Time/Buffer             | 0.0331        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.39726907    |
| Train/Action_magnitu... | 0.8326248     |
| Train/Action_magnitude  | 0.64853424    |
| Train/Action_max        | 0.29165834    |
| Train/Action_std        | 0.16440873    |
| Train/Entropy           | -0.4272941    |
| Train/Entropy_Loss      | 0.000427      |
| Train/Entropy_loss      | 0.000427      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.8220005     |
| Train/Loss              | -0.0055410014 |
| Train/PolicyClip        | 0.00014467294 |
| Train/Policy_loss       | -0.0125089055 |
| Train/Ratio             | 1.0003978     |
| Train/Return            | 2.239325      |
| Train/V                 | 2.228606      |
| Train/Value             | 2.228606      |
| Train/control_penalty   | 0.65406096    |
| Train/policy_loss       | -0.0125089055 |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0671        |
-------------------------------------------

 ---------------- Iteration 297 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 296          |
| Time/Actor_Time         | 0.358        |
| Time/B_Format_Time      | 0.343        |
| Time/B_Original_Form... | 0.341        |
| Time/Buffer             | 0.0324       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39133358   |
| Train/Action_magnitu... | 0.82743925   |
| Train/Action_magnitude  | 0.64631844   |
| Train/Action_max        | 0.31891042   |
| Train/Action_std        | 0.15638201   |
| Train/Entropy           | -0.4810543   |
| Train/Entropy_Loss      | 0.000481     |
| Train/Entropy_loss      | 0.000481     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.9010966    |
| Train/Loss              | -0.012024866 |
| Train/PolicyClip        | 0.000578689  |
| Train/Policy_loss       | -0.018960854 |
| Train/Ratio             | 1.0009072    |
| Train/Return            | 2.1513972    |
| Train/V                 | 2.1347516    |
| Train/Value             | 2.1347516    |
| Train/control_penalty   | 0.6454934    |
| Train/policy_loss       | -0.018960854 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0656       |
------------------------------------------

 ---------------- Iteration 298 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 297           |
| Time/Actor_Time         | 0.359         |
| Time/B_Format_Time      | 0.347         |
| Time/B_Original_Form... | 0.352         |
| Time/Buffer             | 0.0318        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.39512345    |
| Train/Action_magnitu... | 0.8284084     |
| Train/Action_magnitude  | 0.6505887     |
| Train/Action_max        | 0.3348311     |
| Train/Action_std        | 0.15545952    |
| Train/Entropy           | -0.48836324   |
| Train/Entropy_Loss      | 0.000488      |
| Train/Entropy_loss      | 0.000488      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.92778313    |
| Train/Loss              | -0.0046738232 |
| Train/PolicyClip        | 0.00094585965 |
| Train/Policy_loss       | -0.011730774  |
| Train/Ratio             | 0.9984454     |
| Train/Return            | 1.9921826     |
| Train/V                 | 1.9808557     |
| Train/Value             | 1.9808557     |
| Train/control_penalty   | 0.6568588     |
| Train/policy_loss       | -0.011730774  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06505       |
-------------------------------------------

 ---------------- Iteration 299 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 298           |
| Time/Actor_Time         | 0.373         |
| Time/B_Format_Time      | 0.351         |
| Time/B_Original_Form... | 0.348         |
| Time/Buffer             | 0.0349        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.39255983    |
| Train/Action_magnitu... | 0.83839715    |
| Train/Action_magnitude  | 0.6647072     |
| Train/Action_max        | 0.35473615    |
| Train/Action_std        | 0.15956092    |
| Train/Entropy           | -0.46694258   |
| Train/Entropy_Loss      | 0.000467      |
| Train/Entropy_loss      | 0.000467      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.93608445    |
| Train/Loss              | 0.026040044   |
| Train/PolicyClip        | 0.00058062625 |
| Train/Policy_loss       | 0.018968936   |
| Train/Ratio             | 0.9968678     |
| Train/Return            | 2.0230584     |
| Train/V                 | 2.0436926     |
| Train/Value             | 2.0436926     |
| Train/control_penalty   | 0.6604164     |
| Train/policy_loss       | 0.018968936   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06355       |
-------------------------------------------

 ---------------- Iteration 300 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 299          |
| Time/Actor_Time         | 0.37         |
| Time/B_Format_Time      | 0.354        |
| Time/B_Original_Form... | 0.351        |
| Time/Buffer             | 0.0385       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.38707694   |
| Train/Action_magnitu... | 0.8289362    |
| Train/Action_magnitude  | 0.656993     |
| Train/Action_max        | 0.33185893   |
| Train/Action_std        | 0.16389042   |
| Train/Entropy           | -0.44161513  |
| Train/Entropy_Loss      | 0.000442     |
| Train/Entropy_loss      | 0.000442     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.85191387   |
| Train/Loss              | 0.019777307  |
| Train/PolicyClip        | 0.0018010208 |
| Train/Policy_loss       | 0.012840231  |
| Train/Ratio             | 0.9980339    |
| Train/Return            | 2.0524185    |
| Train/V                 | 2.062932     |
| Train/Value             | 2.062932     |
| Train/control_penalty   | 0.6495461    |
| Train/policy_loss       | 0.012840231  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0692       |
------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 301 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-----------------------------------------
| Itr                     | 300         |
| Time/Actor_Time         | 0.37        |
| Time/B_Format_Time      | 0.361       |
| Time/B_Original_Form... | 0.362       |
| Time/Buffer             | 0.0343      |
| Time/Critic_Time        | 0           |
| Train/Action_abs_mean   | 0.37382787  |
| Train/Action_magnitu... | 0.8114097   |
| Train/Action_magnitude  | 0.64096326  |
| Train/Action_max        | 0.3051767   |
| Train/Action_std        | 0.16606355  |
| Train/Entropy           | -0.42628232 |
| Train/Entropy_Loss      | 0.000426    |
| Train/Entropy_loss      | 0.000426    |
| Train/Grad_norm_actor   | 0.0         |
| Train/LogProb           | 0.79267734  |
| Train/Loss              | 0.016532766 |
| Train/PolicyClip        | 0.002298115 |
| Train/Policy_loss       | 0.009809058 |
| Train/Ratio             | 0.9990406   |
| Train/Return            | 2.1164148   |
| Train/V                 | 2.1153095   |
| Train/Value             | 2.1153095   |
| Train/control_penalty   | 0.62974256  |
| Train/policy_loss       | 0.009809058 |
| Train/recon_loss        | 0.0         |
| train/batch_reward      | 0.0711      |
-----------------------------------------

 ---------------- Iteration 302 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 301           |
| Time/Actor_Time         | 0.365         |
| Time/B_Format_Time      | 0.351         |
| Time/B_Original_Form... | 0.354         |
| Time/Buffer             | 0.032         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3722459     |
| Train/Action_magnitu... | 0.7957531     |
| Train/Action_magnitude  | 0.62641245    |
| Train/Action_max        | 0.28971395    |
| Train/Action_std        | 0.15804233    |
| Train/Entropy           | -0.4714748    |
| Train/Entropy_Loss      | 0.000471      |
| Train/Entropy_loss      | 0.000471      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.86355       |
| Train/Loss              | -0.016079366  |
| Train/PolicyClip        | 0.00094918755 |
| Train/Policy_loss       | -0.022776492  |
| Train/Ratio             | 1.0011734     |
| Train/Return            | 2.2033794     |
| Train/V                 | 2.1809168     |
| Train/Value             | 2.1809168     |
| Train/control_penalty   | 0.6225651     |
| Train/policy_loss       | -0.022776492  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07405       |
-------------------------------------------

 ---------------- Iteration 303 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 302           |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.325         |
| Time/B_Original_Form... | 0.327         |
| Time/Buffer             | 0.0291        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37720165    |
| Train/Action_magnitu... | 0.80152184    |
| Train/Action_magnitude  | 0.6297256     |
| Train/Action_max        | 0.27971512    |
| Train/Action_std        | 0.15334782    |
| Train/Entropy           | -0.49744156   |
| Train/Entropy_Loss      | 0.000497      |
| Train/Entropy_loss      | 0.000497      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.9705563     |
| Train/Loss              | -0.016547816  |
| Train/PolicyClip        | 0.00051430304 |
| Train/Policy_loss       | -0.023326032  |
| Train/Ratio             | 1.0002288     |
| Train/Return            | 2.4430082     |
| Train/V                 | 2.4210105     |
| Train/Value             | 2.4210105     |
| Train/control_penalty   | 0.62807745    |
| Train/policy_loss       | -0.023326032  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.076         |
-------------------------------------------

 ---------------- Iteration 304 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 303           |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.346         |
| Time/B_Original_Form... | 0.349         |
| Time/Buffer             | 0.0314        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.39919442    |
| Train/Action_magnitu... | 0.83375645    |
| Train/Action_magnitude  | 0.6570181     |
| Train/Action_max        | 0.31071615    |
| Train/Action_std        | 0.15217876    |
| Train/Entropy           | -0.501705     |
| Train/Entropy_Loss      | 0.000502      |
| Train/Entropy_loss      | 0.000502      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 1.0156163     |
| Train/Loss              | 0.0082281865  |
| Train/PolicyClip        | 0.00064386346 |
| Train/Policy_loss       | 0.0011051295  |
| Train/Ratio             | 1.0005918     |
| Train/Return            | 2.417011      |
| Train/V                 | 2.4177434     |
| Train/Value             | 2.4177434     |
| Train/control_penalty   | 0.6621352     |
| Train/policy_loss       | 0.0011051295  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0746        |
-------------------------------------------

 ---------------- Iteration 305 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 304          |
| Time/Actor_Time         | 0.355        |
| Time/B_Format_Time      | 0.332        |
| Time/B_Original_Form... | 0.426        |
| Time/Buffer             | 0.0312       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.39349312   |
| Train/Action_magnitu... | 0.82902527   |
| Train/Action_magnitude  | 0.6527687    |
| Train/Action_max        | 0.31453896   |
| Train/Action_std        | 0.14898874   |
| Train/Entropy           | -0.5186779   |
| Train/Entropy_Loss      | 0.000519     |
| Train/Entropy_loss      | 0.000519     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 1.0316992    |
| Train/Loss              | 0.008182841  |
| Train/PolicyClip        | 0.0008600339 |
| Train/Policy_loss       | 0.0011404065 |
| Train/Ratio             | 0.9982508    |
| Train/Return            | 2.3060288    |
| Train/V                 | 2.30762      |
| Train/Value             | 2.30762      |
| Train/control_penalty   | 0.6523757    |
| Train/policy_loss       | 0.0011404065 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0741       |
------------------------------------------

 ---------------- Iteration 306 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 305           |
| Time/Actor_Time         | 0.358         |
| Time/B_Format_Time      | 0.349         |
| Time/B_Original_Form... | 0.345         |
| Time/Buffer             | 0.0328        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.383248      |
| Train/Action_magnitu... | 0.8203315     |
| Train/Action_magnitude  | 0.64536095    |
| Train/Action_max        | 0.3155228     |
| Train/Action_std        | 0.1487629     |
| Train/Entropy           | -0.5151064    |
| Train/Entropy_Loss      | 0.000515      |
| Train/Entropy_loss      | 0.000515      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 1.0111499     |
| Train/Loss              | 0.031943116   |
| Train/PolicyClip        | 0.00057548983 |
| Train/Policy_loss       | 0.02501723    |
| Train/Ratio             | 0.9987851     |
| Train/Return            | 2.0426455     |
| Train/V                 | 2.0679817     |
| Train/Value             | 2.0679817     |
| Train/control_penalty   | 0.64107805    |
| Train/policy_loss       | 0.02501723    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06805       |
-------------------------------------------

 ---------------- Iteration 307 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 306           |
| Time/Actor_Time         | 0.36          |
| Time/B_Format_Time      | 0.352         |
| Time/B_Original_Form... | 0.347         |
| Time/Buffer             | 0.0323        |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.38004372    |
| Train/Action_magnitu... | 0.8066425     |
| Train/Action_magnitude  | 0.6389872     |
| Train/Action_max        | 0.28534967    |
| Train/Action_std        | 0.1588952     |
| Train/Entropy           | -0.44885996   |
| Train/Entropy_Loss      | 0.000449      |
| Train/Entropy_loss      | 0.000449      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.94011766    |
| Train/Loss              | 0.1048467     |
| Train/PolicyClip        | -9.842192e-05 |
| Train/Policy_loss       | 0.097970985   |
| Train/Ratio             | 0.9951135     |
| Train/Return            | 2.0210023     |
| Train/V                 | 2.120747      |
| Train/Value             | 2.120747      |
| Train/control_penalty   | 0.6426859     |
| Train/policy_loss       | 0.097970985   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0688        |
-------------------------------------------

 ---------------- Iteration 308 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 307           |
| Time/Actor_Time         | 0.357         |
| Time/B_Format_Time      | 0.34          |
| Time/B_Original_Form... | 0.345         |
| Time/Buffer             | 0.0333        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3777882     |
| Train/Action_magnitu... | 0.8076049     |
| Train/Action_magnitude  | 0.63740575    |
| Train/Action_max        | 0.29844692    |
| Train/Action_std        | 0.16665863    |
| Train/Entropy           | -0.40472513   |
| Train/Entropy_Loss      | 0.000405      |
| Train/Entropy_loss      | 0.000405      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.83864343    |
| Train/Loss              | 0.047270596   |
| Train/PolicyClip        | 5.5255937e-06 |
| Train/Policy_loss       | 0.040481173   |
| Train/Ratio             | 0.99661136    |
| Train/Return            | 2.0919313     |
| Train/V                 | 2.1343608     |
| Train/Value             | 2.1343608     |
| Train/control_penalty   | 0.63846964    |
| Train/policy_loss       | 0.040481173   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0694        |
-------------------------------------------

 ---------------- Iteration 309 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 308            |
| Time/Actor_Time         | 0.361          |
| Time/B_Format_Time      | 0.345          |
| Time/B_Original_Form... | 0.345          |
| Time/Buffer             | 0.0322         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.37957588     |
| Train/Action_magnitu... | 0.81736106     |
| Train/Action_magnitude  | 0.64408684     |
| Train/Action_max        | 0.33165383     |
| Train/Action_std        | 0.17332487     |
| Train/Entropy           | -0.37401816    |
| Train/Entropy_Loss      | 0.000374       |
| Train/Entropy_loss      | 0.000374       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.76735973     |
| Train/Loss              | 0.059950545    |
| Train/PolicyClip        | 0.000101065496 |
| Train/Policy_loss       | 0.053156823    |
| Train/Ratio             | 0.9958302      |
| Train/Return            | 2.3738186      |
| Train/V                 | 2.4297366      |
| Train/Value             | 2.4297366      |
| Train/control_penalty   | 0.6419703      |
| Train/policy_loss       | 0.053156823    |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.07155        |
--------------------------------------------

 ---------------- Iteration 310 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 309           |
| Time/Actor_Time         | 0.362         |
| Time/B_Format_Time      | 0.34          |
| Time/B_Original_Form... | 0.341         |
| Time/Buffer             | 0.0275        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.38250715    |
| Train/Action_magnitu... | 0.82679385    |
| Train/Action_magnitude  | 0.6492759     |
| Train/Action_max        | 0.3477222     |
| Train/Action_std        | 0.18178695    |
| Train/Entropy           | -0.3348348    |
| Train/Entropy_Loss      | 0.000335      |
| Train/Entropy_loss      | 0.000335      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.7453298     |
| Train/Loss              | 0.08293756    |
| Train/PolicyClip        | -0.0007965333 |
| Train/Policy_loss       | 0.076098286   |
| Train/Ratio             | 0.9933747     |
| Train/Return            | 2.493072      |
| Train/V                 | 2.5706997     |
| Train/Value             | 2.5706997     |
| Train/control_penalty   | 0.65044385    |
| Train/policy_loss       | 0.076098286   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0704        |
-------------------------------------------

 ---------------- Iteration 311 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 310           |
| Time/Actor_Time         | 0.361         |
| Time/B_Format_Time      | 0.345         |
| Time/B_Original_Form... | 0.342         |
| Time/Buffer             | 0.0291        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37684283    |
| Train/Action_magnitu... | 0.8124378     |
| Train/Action_magnitude  | 0.63910705    |
| Train/Action_max        | 0.32989442    |
| Train/Action_std        | 0.17937388    |
| Train/Entropy           | -0.34323028   |
| Train/Entropy_Loss      | 0.000343      |
| Train/Entropy_loss      | 0.000343      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.7202028     |
| Train/Loss              | 0.093625054   |
| Train/PolicyClip        | -0.0008570038 |
| Train/Policy_loss       | 0.08684748    |
| Train/Ratio             | 0.9912201     |
| Train/Return            | 2.4553478     |
| Train/V                 | 2.5398912     |
| Train/Value             | 2.5398912     |
| Train/control_penalty   | 0.6434341     |
| Train/policy_loss       | 0.08684748    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0712        |
-------------------------------------------

 ---------------- Iteration 312 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 311           |
| Time/Actor_Time         | 0.364         |
| Time/B_Format_Time      | 0.349         |
| Time/B_Original_Form... | 0.349         |
| Time/Buffer             | 0.033         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37824115    |
| Train/Action_magnitu... | 0.8291031     |
| Train/Action_magnitude  | 0.6494139     |
| Train/Action_max        | 0.34731874    |
| Train/Action_std        | 0.18060313    |
| Train/Entropy           | -0.34039757   |
| Train/Entropy_Loss      | 0.00034       |
| Train/Entropy_loss      | 0.00034       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.68373054    |
| Train/Loss              | 0.026528852   |
| Train/PolicyClip        | 0.00052112195 |
| Train/Policy_loss       | 0.019788958   |
| Train/Ratio             | 1.000919      |
| Train/Return            | 2.1867478     |
| Train/V                 | 2.207307      |
| Train/Value             | 2.207307      |
| Train/control_penalty   | 0.63994956    |
| Train/policy_loss       | 0.019788958   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06685       |
-------------------------------------------

 ---------------- Iteration 313 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 312           |
| Time/Actor_Time         | 0.359         |
| Time/B_Format_Time      | 0.348         |
| Time/B_Original_Form... | 0.35          |
| Time/Buffer             | 0.0372        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37383404    |
| Train/Action_magnitu... | 0.8148945     |
| Train/Action_magnitude  | 0.64056593    |
| Train/Action_max        | 0.3295318     |
| Train/Action_std        | 0.18115729    |
| Train/Entropy           | -0.33043775   |
| Train/Entropy_Loss      | 0.00033       |
| Train/Entropy_loss      | 0.00033       |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.61533713    |
| Train/Loss              | 0.0026884193  |
| Train/PolicyClip        | 0.0010384     |
| Train/Policy_loss       | -0.0040558404 |
| Train/Ratio             | 0.99826545    |
| Train/Return            | 2.235543      |
| Train/V                 | 2.2323632     |
| Train/Value             | 2.2323632     |
| Train/control_penalty   | 0.6413822     |
| Train/policy_loss       | -0.0040558404 |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06895       |
-------------------------------------------

 ---------------- Iteration 314 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 313           |
| Time/Actor_Time         | 0.362         |
| Time/B_Format_Time      | 0.353         |
| Time/B_Original_Form... | 0.351         |
| Time/Buffer             | 0.0273        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3781088     |
| Train/Action_magnitu... | 0.82043654    |
| Train/Action_magnitude  | 0.6463031     |
| Train/Action_max        | 0.34424496    |
| Train/Action_std        | 0.18484217    |
| Train/Entropy           | -0.3154436    |
| Train/Entropy_Loss      | 0.000315      |
| Train/Entropy_loss      | 0.000315      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.59227854    |
| Train/Loss              | -0.0072441953 |
| Train/PolicyClip        | 0.0009114318  |
| Train/Policy_loss       | -0.013996781  |
| Train/Ratio             | 1.0006671     |
| Train/Return            | 2.3866284     |
| Train/V                 | 2.3734777     |
| Train/Value             | 2.3734777     |
| Train/control_penalty   | 0.6437142     |
| Train/policy_loss       | -0.013996781  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07215       |
-------------------------------------------

 ---------------- Iteration 315 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 314          |
| Time/Actor_Time         | 0.411        |
| Time/B_Format_Time      | 0.355        |
| Time/B_Original_Form... | 0.382        |
| Time/Buffer             | 0.0404       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37169728   |
| Train/Action_magnitu... | 0.80990666   |
| Train/Action_magnitude  | 0.6382091    |
| Train/Action_max        | 0.31809214   |
| Train/Action_std        | 0.18460627   |
| Train/Entropy           | -0.31503516  |
| Train/Entropy_Loss      | 0.000315     |
| Train/Entropy_loss      | 0.000315     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.6158963    |
| Train/Loss              | 0.0009468552 |
| Train/PolicyClip        | 0.0003939072 |
| Train/Policy_loss       | -0.005715839 |
| Train/Ratio             | 1.0002109    |
| Train/Return            | 2.5184224    |
| Train/V                 | 2.5156937    |
| Train/Value             | 2.5156937    |
| Train/control_penalty   | 0.6347659    |
| Train/policy_loss       | -0.005715839 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0744       |
------------------------------------------

 ---------------- Iteration 316 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 315           |
| Time/Actor_Time         | 0.371         |
| Time/B_Format_Time      | 0.358         |
| Time/B_Original_Form... | 0.364         |
| Time/Buffer             | 0.0342        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37932453    |
| Train/Action_magnitu... | 0.81922287    |
| Train/Action_magnitude  | 0.6461073     |
| Train/Action_max        | 0.32027504    |
| Train/Action_std        | 0.18878528    |
| Train/Entropy           | -0.29353613   |
| Train/Entropy_Loss      | 0.000294      |
| Train/Entropy_loss      | 0.000294      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.5765271     |
| Train/Loss              | 0.0418291     |
| Train/PolicyClip        | 0.00072544714 |
| Train/Policy_loss       | 0.035009325   |
| Train/Ratio             | 0.995609      |
| Train/Return            | 2.5430655     |
| Train/V                 | 2.578914      |
| Train/Value             | 2.578914      |
| Train/control_penalty   | 0.6526238     |
| Train/policy_loss       | 0.035009325   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0723        |
-------------------------------------------

 ---------------- Iteration 317 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 316           |
| Time/Actor_Time         | 0.514         |
| Time/B_Format_Time      | 0.477         |
| Time/B_Original_Form... | 0.472         |
| Time/Buffer             | 0.857         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.3941867     |
| Train/Action_magnitu... | 0.853942      |
| Train/Action_magnitude  | 0.66983896    |
| Train/Action_max        | 0.3106637     |
| Train/Action_std        | 0.19408101    |
| Train/Entropy           | -0.26359624   |
| Train/Entropy_Loss      | 0.000264      |
| Train/Entropy_loss      | 0.000264      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.53120315    |
| Train/Loss              | 0.055207327   |
| Train/PolicyClip        | 0.00031456642 |
| Train/Policy_loss       | 0.048299022   |
| Train/Ratio             | 0.99620664    |
| Train/Return            | 2.3479142     |
| Train/V                 | 2.3987029     |
| Train/Value             | 2.3987029     |
| Train/control_penalty   | 0.6644707     |
| Train/policy_loss       | 0.048299022   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0655        |
-------------------------------------------

 ---------------- Iteration 318 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 317          |
| Time/Actor_Time         | 0.421        |
| Time/B_Format_Time      | 0.423        |
| Time/B_Original_Form... | 0.434        |
| Time/Buffer             | 0.0392       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3922047    |
| Train/Action_magnitu... | 0.8455252    |
| Train/Action_magnitude  | 0.66540533   |
| Train/Action_max        | 0.3078019    |
| Train/Action_std        | 0.19398513   |
| Train/Entropy           | -0.26561385  |
| Train/Entropy_Loss      | 0.000266     |
| Train/Entropy_loss      | 0.000266     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.56546634   |
| Train/Loss              | 0.06425218   |
| Train/PolicyClip        | 0.0002394502 |
| Train/Policy_loss       | 0.05731576   |
| Train/Ratio             | 0.99665254   |
| Train/Return            | 2.1733687    |
| Train/V                 | 2.2333632    |
| Train/Value             | 2.2333632    |
| Train/control_penalty   | 0.66708124   |
| Train/policy_loss       | 0.05731576   |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.05835      |
------------------------------------------

 ---------------- Iteration 319 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 318           |
| Time/Actor_Time         | 0.448         |
| Time/B_Format_Time      | 0.457         |
| Time/B_Original_Form... | 0.458         |
| Time/Buffer             | 0.0463        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.40059614    |
| Train/Action_magnitu... | 0.8613725     |
| Train/Action_magnitude  | 0.67693913    |
| Train/Action_max        | 0.34098154    |
| Train/Action_std        | 0.18630537    |
| Train/Entropy           | -0.31340778   |
| Train/Entropy_Loss      | 0.000313      |
| Train/Entropy_loss      | 0.000313      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6049128     |
| Train/Loss              | 0.050614245   |
| Train/PolicyClip        | 0.00096974085 |
| Train/Policy_loss       | 0.043564223   |
| Train/Ratio             | 0.9921466     |
| Train/Return            | 2.0968988     |
| Train/V                 | 2.142115      |
| Train/Value             | 2.142115      |
| Train/control_penalty   | 0.67366135    |
| Train/policy_loss       | 0.043564223   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05635       |
-------------------------------------------

 ---------------- Iteration 320 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 319          |
| Time/Actor_Time         | 0.432        |
| Time/B_Format_Time      | 0.441        |
| Time/B_Original_Form... | 0.45         |
| Time/Buffer             | 0.0368       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.4106241    |
| Train/Action_magnitu... | 0.8749304    |
| Train/Action_magnitude  | 0.68504167   |
| Train/Action_max        | 0.3778725    |
| Train/Action_std        | 0.18008725   |
| Train/Entropy           | -0.3510597   |
| Train/Entropy_Loss      | 0.000351     |
| Train/Entropy_loss      | 0.000351     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.6774917    |
| Train/Loss              | 0.009254954  |
| Train/PolicyClip        | 0.0009596096 |
| Train/Policy_loss       | 0.002021903  |
| Train/Ratio             | 1.0021901    |
| Train/Return            | 2.1717017    |
| Train/V                 | 2.1732688    |
| Train/Value             | 2.1732688    |
| Train/control_penalty   | 0.6881991    |
| Train/policy_loss       | 0.002021903  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0602       |
------------------------------------------
Saving snapshot...
Saved

 ---------------- Iteration 321 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 320           |
| Time/Actor_Time         | 0.514         |
| Time/B_Format_Time      | 0.471         |
| Time/B_Original_Form... | 0.474         |
| Time/Buffer             | 0.0451        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.41965204    |
| Train/Action_magnitu... | 0.8813871     |
| Train/Action_magnitude  | 0.68670595    |
| Train/Action_max        | 0.39912024    |
| Train/Action_std        | 0.18116067    |
| Train/Entropy           | -0.35205317   |
| Train/Entropy_Loss      | 0.000352      |
| Train/Entropy_loss      | 0.000352      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.73657393    |
| Train/Loss              | -0.0005197432 |
| Train/PolicyClip        | 0.0011198674  |
| Train/Policy_loss       | -0.0078075705 |
| Train/Ratio             | 0.99781716    |
| Train/Return            | 2.310745      |
| Train/V                 | 2.3047872     |
| Train/Value             | 2.3047872     |
| Train/control_penalty   | 0.69357747    |
| Train/policy_loss       | -0.0078075705 |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.06265       |
-------------------------------------------

 ---------------- Iteration 322 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 321          |
| Time/Actor_Time         | 0.515        |
| Time/B_Format_Time      | 0.505        |
| Time/B_Original_Form... | 0.486        |
| Time/Buffer             | 0.041        |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.42164463   |
| Train/Action_magnitu... | 0.89382976   |
| Train/Action_magnitude  | 0.6913012    |
| Train/Action_max        | 0.39913413   |
| Train/Action_std        | 0.18305217   |
| Train/Entropy           | -0.34534433  |
| Train/Entropy_Loss      | 0.000345     |
| Train/Entropy_loss      | 0.000345     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.6612372    |
| Train/Loss              | 0.02181096   |
| Train/PolicyClip        | 0.0008241372 |
| Train/Policy_loss       | 0.014528542  |
| Train/Ratio             | 0.9992501    |
| Train/Return            | 2.3178802    |
| Train/V                 | 2.3355844    |
| Train/Value             | 2.3355844    |
| Train/control_penalty   | 0.69370735   |
| Train/policy_loss       | 0.014528542  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.06185      |
------------------------------------------

 ---------------- Iteration 323 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 322           |
| Time/Actor_Time         | 0.44          |
| Time/B_Format_Time      | 0.452         |
| Time/B_Original_Form... | 0.455         |
| Time/Buffer             | 0.0441        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.4150271     |
| Train/Action_magnitu... | 0.8926115     |
| Train/Action_magnitude  | 0.690021      |
| Train/Action_max        | 0.36844915    |
| Train/Action_std        | 0.20021081    |
| Train/Entropy           | -0.2544447    |
| Train/Entropy_Loss      | 0.000254      |
| Train/Entropy_loss      | 0.000254      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.512954      |
| Train/Loss              | 0.028573211   |
| Train/PolicyClip        | 0.00052270095 |
| Train/Policy_loss       | 0.021409495   |
| Train/Ratio             | 0.9992131     |
| Train/Return            | 2.167821      |
| Train/V                 | 2.1921422     |
| Train/Value             | 2.1921422     |
| Train/control_penalty   | 0.69092727    |
| Train/policy_loss       | 0.021409495   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.05815       |
-------------------------------------------

 ---------------- Iteration 324 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 323          |
| Time/Actor_Time         | 0.513        |
| Time/B_Format_Time      | 0.484        |
| Time/B_Original_Form... | 0.463        |
| Time/Buffer             | 0.0285       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.41391227   |
| Train/Action_magnitu... | 0.88355774   |
| Train/Action_magnitude  | 0.68487984   |
| Train/Action_max        | 0.3246793    |
| Train/Action_std        | 0.21428825   |
| Train/Entropy           | -0.17375085  |
| Train/Entropy_Loss      | 0.000174     |
| Train/Entropy_loss      | 0.000174     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.35372478   |
| Train/Loss              | 0.027656723  |
| Train/PolicyClip        | 0.0010175728 |
| Train/Policy_loss       | 0.020562744  |
| Train/Ratio             | 0.9962484    |
| Train/Return            | 2.0315027    |
| Train/V                 | 2.0520518    |
| Train/Value             | 2.0520518    |
| Train/control_penalty   | 0.69202286   |
| Train/policy_loss       | 0.020562744  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.05715      |
------------------------------------------

 ---------------- Iteration 325 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
--------------------------------------------
| Itr                     | 324            |
| Time/Actor_Time         | 0.493          |
| Time/B_Format_Time      | 0.432          |
| Time/B_Original_Form... | 0.457          |
| Time/Buffer             | 0.0423         |
| Time/Critic_Time        | 0              |
| Train/Action_abs_mean   | 0.39843        |
| Train/Action_magnitu... | 0.86941785     |
| Train/Action_magnitude  | 0.6753439      |
| Train/Action_max        | 0.28952095     |
| Train/Action_std        | 0.21470112     |
| Train/Entropy           | -0.16906816    |
| Train/Entropy_Loss      | 0.000169       |
| Train/Entropy_loss      | 0.000169       |
| Train/Grad_norm_actor   | 0.0            |
| Train/LogProb           | 0.29388595     |
| Train/Loss              | -0.007476298   |
| Train/PolicyClip        | 0.000108567845 |
| Train/Policy_loss       | -0.014378815   |
| Train/Ratio             | 1.0006945      |
| Train/Return            | 2.087958       |
| Train/V                 | 2.07517        |
| Train/Value             | 2.07517        |
| Train/control_penalty   | 0.67334485     |
| Train/policy_loss       | -0.014378815   |
| Train/recon_loss        | 0.0            |
| train/batch_reward      | 0.06205        |
--------------------------------------------

 ---------------- Iteration 326 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 325           |
| Time/Actor_Time         | 0.476         |
| Time/B_Format_Time      | 0.469         |
| Time/B_Original_Form... | 0.439         |
| Time/Buffer             | 0.0467        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.38426533    |
| Train/Action_magnitu... | 0.83944356    |
| Train/Action_magnitude  | 0.6564207     |
| Train/Action_max        | 0.296917      |
| Train/Action_std        | 0.20799214    |
| Train/Entropy           | -0.20175837   |
| Train/Entropy_Loss      | 0.000202      |
| Train/Entropy_loss      | 0.000202      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.4164525     |
| Train/Loss              | -0.006402382  |
| Train/PolicyClip        | 0.00055731286 |
| Train/Policy_loss       | -0.013150972  |
| Train/Ratio             | 1.0002382     |
| Train/Return            | 2.2044735     |
| Train/V                 | 2.1940594     |
| Train/Value             | 2.1940594     |
| Train/control_penalty   | 0.65468323    |
| Train/policy_loss       | -0.013150972  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.069         |
-------------------------------------------

 ---------------- Iteration 327 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 326           |
| Time/Actor_Time         | 0.436         |
| Time/B_Format_Time      | 0.439         |
| Time/B_Original_Form... | 0.423         |
| Time/Buffer             | 0.041         |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37259564    |
| Train/Action_magnitu... | 0.8080958     |
| Train/Action_magnitude  | 0.636046      |
| Train/Action_max        | 0.32767084    |
| Train/Action_std        | 0.19333118    |
| Train/Entropy           | -0.27771354   |
| Train/Entropy_Loss      | 0.000278      |
| Train/Entropy_loss      | 0.000278      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.5432526     |
| Train/Loss              | -0.0041034776 |
| Train/PolicyClip        | 0.0003450031  |
| Train/Policy_loss       | -0.010743153  |
| Train/Ratio             | 0.9979        |
| Train/Return            | 2.2648683     |
| Train/V                 | 2.2566862     |
| Train/Value             | 2.2566862     |
| Train/control_penalty   | 0.6361962     |
| Train/policy_loss       | -0.010743153  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0726        |
-------------------------------------------

 ---------------- Iteration 328 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 327           |
| Time/Actor_Time         | 0.443         |
| Time/B_Format_Time      | 0.422         |
| Time/B_Original_Form... | 0.431         |
| Time/Buffer             | 0.0449        |
| Time/Critic_Time        | 1.19e-06      |
| Train/Action_abs_mean   | 0.3661955     |
| Train/Action_magnitu... | 0.8000729     |
| Train/Action_magnitude  | 0.62945026    |
| Train/Action_max        | 0.33422157    |
| Train/Action_std        | 0.18368967    |
| Train/Entropy           | -0.32606927   |
| Train/Entropy_Loss      | 0.000326      |
| Train/Entropy_loss      | 0.000326      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6000579     |
| Train/Loss              | -0.041618984  |
| Train/PolicyClip        | 0.00041057874 |
| Train/Policy_loss       | -0.04820131   |
| Train/Ratio             | 1.0021143     |
| Train/Return            | 2.2804782     |
| Train/V                 | 2.2345603     |
| Train/Value             | 2.2345603     |
| Train/control_penalty   | 0.6256258     |
| Train/policy_loss       | -0.04820131   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07675       |
-------------------------------------------

 ---------------- Iteration 329 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 328           |
| Time/Actor_Time         | 0.449         |
| Time/B_Format_Time      | 0.427         |
| Time/B_Original_Form... | 0.446         |
| Time/Buffer             | 0.0386        |
| Time/Critic_Time        | 0             |
| Train/Action_abs_mean   | 0.37253568    |
| Train/Action_magnitu... | 0.80880976    |
| Train/Action_magnitude  | 0.63477576    |
| Train/Action_max        | 0.33316278    |
| Train/Action_std        | 0.18342121    |
| Train/Entropy           | -0.32834232   |
| Train/Entropy_Loss      | 0.000328      |
| Train/Entropy_loss      | 0.000328      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.614488      |
| Train/Loss              | -0.067779094  |
| Train/PolicyClip        | 0.00057937525 |
| Train/Policy_loss       | -0.07443407   |
| Train/Ratio             | 1.0036708     |
| Train/Return            | 2.2517927     |
| Train/V                 | 2.1794827     |
| Train/Value             | 2.1794827     |
| Train/control_penalty   | 0.63266367    |
| Train/policy_loss       | -0.07443407   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.0743        |
-------------------------------------------

 ---------------- Iteration 330 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 329          |
| Time/Actor_Time         | 0.44         |
| Time/B_Format_Time      | 0.466        |
| Time/B_Original_Form... | 0.458        |
| Time/Buffer             | 0.0346       |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.37706357   |
| Train/Action_magnitu... | 0.81344795   |
| Train/Action_magnitude  | 0.63792634   |
| Train/Action_max        | 0.3232528    |
| Train/Action_std        | 0.18057722   |
| Train/Entropy           | -0.3372409   |
| Train/Entropy_Loss      | 0.000337     |
| Train/Entropy_loss      | 0.000337     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.643363     |
| Train/Loss              | -0.079283185 |
| Train/PolicyClip        | 0.0001097718 |
| Train/Policy_loss       | -0.085989505 |
| Train/Ratio             | 1.0041587    |
| Train/Return            | 2.3008282    |
| Train/V                 | 2.2177927    |
| Train/Value             | 2.2177927    |
| Train/control_penalty   | 0.63690746   |
| Train/policy_loss       | -0.085989505 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07295      |
------------------------------------------

 ---------------- Iteration 331 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 330          |
| Time/Actor_Time         | 0.48         |
| Time/B_Format_Time      | 0.487        |
| Time/B_Original_Form... | 0.509        |
| Time/Buffer             | 0.105        |
| Time/Critic_Time        | 9.54e-07     |
| Train/Action_abs_mean   | 0.38094047   |
| Train/Action_magnitu... | 0.8177438    |
| Train/Action_magnitude  | 0.63993084   |
| Train/Action_max        | 0.3155144    |
| Train/Action_std        | 0.17729102   |
| Train/Entropy           | -0.35131204  |
| Train/Entropy_Loss      | 0.000351     |
| Train/Entropy_loss      | 0.000351     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.64456385   |
| Train/Loss              | -0.09315704  |
| Train/PolicyClip        | 7.82522e-05  |
| Train/Policy_loss       | -0.099879086 |
| Train/Ratio             | 1.0022913    |
| Train/Return            | 2.3323631    |
| Train/V                 | 2.234973     |
| Train/Value             | 2.234973     |
| Train/control_penalty   | 0.6370735    |
| Train/policy_loss       | -0.099879086 |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.0742       |
------------------------------------------

 ---------------- Iteration 332 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 331           |
| Time/Actor_Time         | 0.66          |
| Time/B_Format_Time      | 0.679         |
| Time/B_Original_Form... | 0.692         |
| Time/Buffer             | 0.0332        |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.38233134    |
| Train/Action_magnitu... | 0.810554      |
| Train/Action_magnitude  | 0.63584006    |
| Train/Action_max        | 0.3076913     |
| Train/Action_std        | 0.17673294    |
| Train/Entropy           | -0.35310978   |
| Train/Entropy_Loss      | 0.000353      |
| Train/Entropy_loss      | 0.000353      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6633156     |
| Train/Loss              | -0.06439877   |
| Train/PolicyClip        | 0.00085847033 |
| Train/Policy_loss       | -0.071131594  |
| Train/Ratio             | 1.0025495     |
| Train/Return            | 2.3316233     |
| Train/V                 | 2.2631247     |
| Train/Value             | 2.2631247     |
| Train/control_penalty   | 0.63797116    |
| Train/policy_loss       | -0.071131594  |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07385       |
-------------------------------------------

 ---------------- Iteration 333 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
------------------------------------------
| Itr                     | 332          |
| Time/Actor_Time         | 0.604        |
| Time/B_Format_Time      | 0.644        |
| Time/B_Original_Form... | 0.657        |
| Time/Buffer             | 0.035        |
| Time/Critic_Time        | 0            |
| Train/Action_abs_mean   | 0.3756409    |
| Train/Action_magnitu... | 0.8046122    |
| Train/Action_magnitude  | 0.63044065   |
| Train/Action_max        | 0.30096558   |
| Train/Action_std        | 0.18157172   |
| Train/Entropy           | -0.3271533   |
| Train/Entropy_Loss      | 0.000327     |
| Train/Entropy_loss      | 0.000327     |
| Train/Grad_norm_actor   | 0.0          |
| Train/LogProb           | 0.67809385   |
| Train/Loss              | 0.031674314  |
| Train/PolicyClip        | 0.0015263481 |
| Train/Policy_loss       | 0.025001664  |
| Train/Ratio             | 0.9982916    |
| Train/Return            | 2.3268688    |
| Train/V                 | 2.354023     |
| Train/Value             | 2.354023     |
| Train/control_penalty   | 0.63454986   |
| Train/policy_loss       | 0.025001664  |
| Train/recon_loss        | 0.0          |
| train/batch_reward      | 0.07155      |
------------------------------------------

 ---------------- Iteration 334 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 333           |
| Time/Actor_Time         | 0.478         |
| Time/B_Format_Time      | 0.48          |
| Time/B_Original_Form... | 0.478         |
| Time/Buffer             | 0.0381        |
| Time/Critic_Time        | 7.15e-07      |
| Train/Action_abs_mean   | 0.38873947    |
| Train/Action_magnitu... | 0.83091503    |
| Train/Action_magnitude  | 0.6494474     |
| Train/Action_max        | 0.31217343    |
| Train/Action_std        | 0.18675087    |
| Train/Entropy           | -0.3064632    |
| Train/Entropy_Loss      | 0.000306      |
| Train/Entropy_loss      | 0.000306      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6462022     |
| Train/Loss              | 0.051864676   |
| Train/PolicyClip        | 0.00024303365 |
| Train/Policy_loss       | 0.04500498    |
| Train/Ratio             | 0.9959796     |
| Train/Return            | 2.2885938     |
| Train/V                 | 2.335864      |
| Train/Value             | 2.335864      |
| Train/control_penalty   | 0.65532327    |
| Train/policy_loss       | 0.04500498    |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.07          |
-------------------------------------------

 ---------------- Iteration 335 ----------------
Obtaining samples...
RL Training...
/Users/1000ber-5078/PycharmProjects/teachable-rl/scripts/logs/persisted_models_distill/claire
-------------------------------------------
| Itr                     | 334           |
| Time/Actor_Time         | 1.51          |
| Time/B_Format_Time      | 1.25          |
| Time/B_Original_Form... | 0.854         |
| Time/Buffer             | 0.042         |
| Time/Critic_Time        | 9.54e-07      |
| Train/Action_abs_mean   | 0.3842151     |
| Train/Action_magnitu... | 0.83451855    |
| Train/Action_magnitude  | 0.6501451     |
| Train/Action_max        | 0.31536937    |
| Train/Action_std        | 0.18813455    |
| Train/Entropy           | -0.29761416   |
| Train/Entropy_Loss      | 0.000298      |
| Train/Entropy_loss      | 0.000298      |
| Train/Grad_norm_actor   | 0.0           |
| Train/LogProb           | 0.6021017     |
| Train/Loss              | 0.037387062   |
| Train/PolicyClip        | 0.00049640296 |
| Train/Policy_loss       | 0.030597143   |
| Train/Ratio             | 0.9949499     |
| Train/Return            | 2.2754545     |
| Train/V                 | 2.3062327     |
| Train/Value             | 2.3062327     |
| Train/control_penalty   | 0.6492306     |
| Train/policy_loss       | 0.030597143   |
| Train/recon_loss        | 0.0           |
| train/batch_reward      | 0.068         |
-------------------------------------------

 ---------------- Iteration 336 ----------------
Obtaining samples...
